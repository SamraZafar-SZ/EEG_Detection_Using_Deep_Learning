{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIP0JOVYLiJ4",
        "outputId": "76c7fe15-b40a-45e8-b71b-7e1121d3044c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting PyWavelets\n",
            "  Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.0 kB)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Downloading pywavelets-1.8.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.5 MB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/4.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/4.5 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/4.5 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m35.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: PyWavelets\n",
            "Successfully installed PyWavelets-1.8.0\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "!pip install PyWavelets\n",
        "import pywt\n",
        "from scipy.io import loadmat, savemat\n",
        "from scipy.signal import butter, filtfilt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.feature_selection import SelectKBest, mutual_info_classif\n",
        "import os\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Band-pass filter function (0-40 Hz as per paper)\n",
        "def bandpass_filter(signal, lowcut=0.5, highcut=40.0, fs=173.61, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, signal)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CmfZ7tHCNR0F",
        "outputId": "fad8551c-b545-41f0-ad93-9164e13be858"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to extract wavelet features using Stationary Wavelet Transform (SWT)\n",
        "def extract_wavelet_features(signal, wavelet='db4', level=4):\n",
        "    if len(signal) % 2 != 0:  # Ensure even length\n",
        "        signal = signal[:-1]\n",
        "\n",
        "    coeffs = pywt.swt(signal, wavelet, level=level)\n",
        "    features = []\n",
        "    for cA, cD in coeffs:\n",
        "        features.append(np.mean(np.abs(cA)))  # Mean absolute value of approximation coefficients\n",
        "        features.append(np.std(cA))  # Standard deviation\n",
        "        features.append(np.mean(np.abs(cD)))  # Mean absolute value of detail coefficients\n",
        "        features.append(np.std(cD))  # Standard deviation of detail coefficients\n",
        "    return np.array(features)\n",
        "\n",
        "\n",
        "# Function to compute statistical features\n",
        "def extract_statistical_features(signal):\n",
        "    features = []\n",
        "    features.append(np.mean(signal))  # Mean absolute value\n",
        "    features.append(np.std(signal))  # Standard deviation\n",
        "    features.append(np.mean((signal - np.mean(signal))**3) / (np.std(signal)**3))  # Skewness\n",
        "    features.append(np.mean((signal - np.mean(signal))**4) / (np.std(signal)**4))  # Kurtosis\n",
        "    features.append(np.sqrt(np.mean(signal**2)))  # RMS power\n",
        "    return np.array(features)\n"
      ],
      "metadata": {
        "id": "S9iuBBYHNZcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/EEG Dataset\"\n",
        "output_folder = os.path.join(input_folder, \"Processed_2\")\n",
        "os.makedirs(output_folder, exist_ok=True)"
      ],
      "metadata": {
        "id": "Q0I0pRArNd45"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Process EEG data\n",
        "label_map = {'F': 0, 'N': 0, 'O': 1, 'Z': 1, 'S': 2}  # Class mapping\n",
        "\n",
        "for folder in ['F', 'N', 'O', 'S', 'Z']:\n",
        "    folder_path = os.path.join(input_folder, folder)\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Warning: {folder_path} not found. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    all_features = []\n",
        "    all_labels = []\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        file_path = os.path.join(folder_path, file)\n",
        "        signal = np.loadtxt(file_path)  # Load EEG signal\n",
        "\n",
        "        # Apply band-pass filter\n",
        "        filtered_signal = bandpass_filter(signal)\n",
        "\n",
        "        # Normalize signal (-1 to 1 as per paper)\n",
        "        scaler = MinMaxScaler(feature_range=(-1, 1))\n",
        "        normalized_signal = scaler.fit_transform(filtered_signal.reshape(-1, 1)).flatten()\n",
        "\n",
        "        # Extract wavelet features\n",
        "        wavelet_features = extract_wavelet_features(normalized_signal)\n",
        "\n",
        "        # Extract statistical features\n",
        "        statistical_features = extract_statistical_features(normalized_signal)\n",
        "\n",
        "        # Combine features\n",
        "        combined_features = np.hstack([wavelet_features, statistical_features])\n",
        "        all_features.append(combined_features)\n",
        "        all_labels.append(label_map[folder])\n",
        "\n",
        "    # Convert to numpy arrays\n",
        "    all_features = np.array(all_features)\n",
        "    all_labels = np.array(all_labels)\n",
        "\n",
        "    # Select best features using Mutual Information & BDFA (Mockup Step)\n",
        "    selector = SelectKBest(mutual_info_classif, k=19)  # Selecting top 19 features\n",
        "    selected_features = selector.fit_transform(all_features, all_labels)\n",
        "\n",
        "    # Save processed features and labels separately for each folder\n",
        "    save_path = os.path.join(output_folder, f\"processed_{folder}.mat\")\n",
        "    savemat(save_path, {\"features\": selected_features, \"labels\": all_labels})\n",
        "    print(f\"Processed and saved: {save_path}\")\n",
        "\n",
        "print(\"Preprocessing complete. Processed data saved.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Juwmb-vNlyK",
        "outputId": "6dbfb38d-8339-41bd-98ed-5ced9001ad64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved: /content/drive/MyDrive/EEG Dataset/Processed_2/processed_F.mat\n",
            "Processed and saved: /content/drive/MyDrive/EEG Dataset/Processed_2/processed_N.mat\n",
            "Processed and saved: /content/drive/MyDrive/EEG Dataset/Processed_2/processed_O.mat\n",
            "Processed and saved: /content/drive/MyDrive/EEG Dataset/Processed_2/processed_S.mat\n",
            "Processed and saved: /content/drive/MyDrive/EEG Dataset/Processed_2/processed_Z.mat\n",
            "Preprocessing complete. Processed data saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
        "from scipy.io import loadmat\n",
        "import os\n",
        "from google.colab import drive\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report, accuracy_score"
      ],
      "metadata": {
        "id": "jMoE20AHPxpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define input folder where processed data is stored\n",
        "processed_folder = \"/content/drive/MyDrive/EEG Dataset/Processed_2\"\n",
        "\n",
        "def load_processed_data():\n",
        "    all_features, all_labels = [], []\n",
        "\n",
        "    for file in os.listdir(processed_folder):\n",
        "        if file.endswith(\".mat\"):\n",
        "            data = loadmat(os.path.join(processed_folder, file))\n",
        "            all_features.append(data[\"features\"])\n",
        "            all_labels.append(data[\"labels\"].flatten())\n",
        "\n",
        "    # Stack all data\n",
        "    X = np.vstack(all_features)\n",
        "    y = np.concatenate(all_labels)\n",
        "    return X, y\n"
      ],
      "metadata": {
        "id": "iNivnAh0P3Fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Load dataset\n",
        "X, y = load_processed_data()\n",
        "\n",
        "# Encode labels\n",
        "label_encoder = LabelEncoder()\n",
        "y = label_encoder.fit_transform(y)\n",
        "\n",
        "# Perform SMOTE to handle imbalance\n",
        "smote = SMOTE(random_state=42)\n",
        "X, y = smote.fit_resample(X, y)\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Split into training (80%) and validation (20%)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
      ],
      "metadata": {
        "id": "GCD57enZP4Ye"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define DNN model based on research paper\n",
        "def create_dnn_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape,)),\n",
        "        Dense(10, activation='sigmoid'),  # First hidden layer\n",
        "        Dense(10, activation='sigmoid'),  # Second hidden layer\n",
        "        Dense(10, activation='sigmoid'),  # Third hidden layer\n",
        "        Dense(num_classes, activation='softmax')  # Output layer\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss=SparseCategoricalCrossentropy(),\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "# Create and train the model\n",
        "model = create_dnn_model(input_shape=X_train.shape[1], num_classes=len(np.unique(y)))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "hHsxlmSPP8O2",
        "outputId": "00abb5ad-e7e6-4586-c333-e6530192b84f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m200\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │             \u001b[38;5;34m110\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │              \u001b[38;5;34m33\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">110</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">33</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m453\u001b[0m (1.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">453</span> (1.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m453\u001b[0m (1.77 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">453</span> (1.77 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform 3 experiments as per the research paper\n",
        "experiments = {\n",
        "    \"Binary Classification (Exp 1: A vs E)\": [0, 2],\n",
        "    \"Binary Classification (Exp 2: A+D vs E)\": [0, 1, 2],\n",
        "    \"Multi-Class Classification (Exp 3: A vs D vs E)\": [0, 1, 2]\n",
        "}\n",
        "\n",
        "for exp_name, selected_classes in experiments.items():\n",
        "    print(f\"\\nRunning Experiment: {exp_name}\")\n",
        "\n",
        "    # Filter selected classes\n",
        "    indices = np.isin(y, selected_classes)\n",
        "    X_exp, y_exp = X[indices], y[indices]\n",
        "\n",
        "    # Re-map labels to 0,1,... for compatibility with SparseCategoricalCrossentropy\n",
        "    class_mapping = {c: i for i, c in enumerate(sorted(selected_classes))}\n",
        "    y_exp = np.array([class_mapping[label] for label in y_exp])\n",
        "\n",
        "    # Split into training/testing\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_exp, y_exp, test_size=0.2, random_state=42, stratify=y_exp)\n",
        "\n",
        "    # Train model\n",
        "    model = create_dnn_model(input_shape=X_train.shape[1], num_classes=len(selected_classes))\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=100,\n",
        "        batch_size=16,\n",
        "        class_weight=class_weight_dict,\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    # Evaluate model\n",
        "    y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"\\nExperiment: {exp_name} - Accuracy: {accuracy:.4f}\")\n",
        "    print(\"Classification Report:\")\n",
        "    print(classification_report(y_test, y_pred))\n",
        "\n",
        "    # Save trained model\n",
        "    model.save(f\"/content/drive/MyDrive/EEG Dataset/EEG_BDFA_DNN_{exp_name.replace(' ', '_')}.keras\")\n",
        "    print(f\"Model for {exp_name} saved successfully!\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LysuJABBSJ8w",
        "outputId": "98ab8a56-4fc7-47fa-f893-122c8687831a"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Running Experiment: Binary Classification (Exp 1: A vs E)\n",
            "Epoch 1/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.5315 - loss: 0.6795 - val_accuracy: 0.6125 - val_loss: 0.6808\n",
            "Epoch 2/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.5842 - loss: 0.6786 - val_accuracy: 0.6250 - val_loss: 0.6774\n",
            "Epoch 3/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6325 - loss: 0.6747 - val_accuracy: 0.6375 - val_loss: 0.6743\n",
            "Epoch 4/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6675 - loss: 0.6644 - val_accuracy: 0.6250 - val_loss: 0.6692\n",
            "Epoch 5/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6609 - loss: 0.6672 - val_accuracy: 0.6375 - val_loss: 0.6608\n",
            "Epoch 6/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7417 - loss: 0.6424 - val_accuracy: 0.6500 - val_loss: 0.6482\n",
            "Epoch 7/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7472 - loss: 0.6285 - val_accuracy: 0.6875 - val_loss: 0.6326\n",
            "Epoch 8/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7249 - loss: 0.6075 - val_accuracy: 0.6875 - val_loss: 0.6176\n",
            "Epoch 9/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6811 - loss: 0.6093 - val_accuracy: 0.6875 - val_loss: 0.6026\n",
            "Epoch 10/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7212 - loss: 0.5715 - val_accuracy: 0.7125 - val_loss: 0.5869\n",
            "Epoch 11/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7323 - loss: 0.5526 - val_accuracy: 0.7500 - val_loss: 0.5710\n",
            "Epoch 12/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7582 - loss: 0.5172 - val_accuracy: 0.7500 - val_loss: 0.5577\n",
            "Epoch 13/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7340 - loss: 0.5154 - val_accuracy: 0.7500 - val_loss: 0.5464\n",
            "Epoch 14/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7506 - loss: 0.5041 - val_accuracy: 0.7250 - val_loss: 0.5384\n",
            "Epoch 15/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7671 - loss: 0.4864 - val_accuracy: 0.7750 - val_loss: 0.5232\n",
            "Epoch 16/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7778 - loss: 0.4836 - val_accuracy: 0.7500 - val_loss: 0.5166\n",
            "Epoch 17/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7991 - loss: 0.4427 - val_accuracy: 0.8000 - val_loss: 0.5001\n",
            "Epoch 18/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8120 - loss: 0.4495 - val_accuracy: 0.8000 - val_loss: 0.4886\n",
            "Epoch 19/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8252 - loss: 0.4416 - val_accuracy: 0.8125 - val_loss: 0.4761\n",
            "Epoch 20/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8392 - loss: 0.4193 - val_accuracy: 0.8000 - val_loss: 0.4695\n",
            "Epoch 21/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8601 - loss: 0.4182 - val_accuracy: 0.8125 - val_loss: 0.4577\n",
            "Epoch 22/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8932 - loss: 0.3762 - val_accuracy: 0.8250 - val_loss: 0.4418\n",
            "Epoch 23/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8539 - loss: 0.3735 - val_accuracy: 0.8125 - val_loss: 0.4345\n",
            "Epoch 24/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8763 - loss: 0.3910 - val_accuracy: 0.8625 - val_loss: 0.4168\n",
            "Epoch 25/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8968 - loss: 0.3333 - val_accuracy: 0.8625 - val_loss: 0.4070\n",
            "Epoch 26/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8879 - loss: 0.3320 - val_accuracy: 0.8875 - val_loss: 0.3898\n",
            "Epoch 27/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9074 - loss: 0.3233 - val_accuracy: 0.8875 - val_loss: 0.3721\n",
            "Epoch 28/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8982 - loss: 0.3175 - val_accuracy: 0.8875 - val_loss: 0.3547\n",
            "Epoch 29/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9219 - loss: 0.2581 - val_accuracy: 0.8750 - val_loss: 0.3481\n",
            "Epoch 30/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9263 - loss: 0.2654 - val_accuracy: 0.8750 - val_loss: 0.3339\n",
            "Epoch 31/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9320 - loss: 0.2632 - val_accuracy: 0.8875 - val_loss: 0.3212\n",
            "Epoch 32/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9087 - loss: 0.2567 - val_accuracy: 0.8875 - val_loss: 0.3128\n",
            "Epoch 33/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9109 - loss: 0.2463 - val_accuracy: 0.8875 - val_loss: 0.3041\n",
            "Epoch 34/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9163 - loss: 0.2398 - val_accuracy: 0.8875 - val_loss: 0.2902\n",
            "Epoch 35/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9422 - loss: 0.2337 - val_accuracy: 0.9000 - val_loss: 0.2980\n",
            "Epoch 36/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.2090 - val_accuracy: 0.8875 - val_loss: 0.2806\n",
            "Epoch 37/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.2149 - val_accuracy: 0.9000 - val_loss: 0.2808\n",
            "Epoch 38/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9137 - loss: 0.2081 - val_accuracy: 0.9000 - val_loss: 0.2672\n",
            "Epoch 39/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9515 - loss: 0.1839 - val_accuracy: 0.9000 - val_loss: 0.2638\n",
            "Epoch 40/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9573 - loss: 0.1893 - val_accuracy: 0.9000 - val_loss: 0.2599\n",
            "Epoch 41/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9328 - loss: 0.1918 - val_accuracy: 0.9000 - val_loss: 0.2552\n",
            "Epoch 42/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9646 - loss: 0.1516 - val_accuracy: 0.9000 - val_loss: 0.2534\n",
            "Epoch 43/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9362 - loss: 0.1886 - val_accuracy: 0.9125 - val_loss: 0.2470\n",
            "Epoch 44/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9598 - loss: 0.1646 - val_accuracy: 0.9125 - val_loss: 0.2495\n",
            "Epoch 45/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9428 - loss: 0.1607 - val_accuracy: 0.9125 - val_loss: 0.2420\n",
            "Epoch 46/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9440 - loss: 0.1782 - val_accuracy: 0.9125 - val_loss: 0.2417\n",
            "Epoch 47/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9413 - loss: 0.1704 - val_accuracy: 0.9125 - val_loss: 0.2381\n",
            "Epoch 48/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9405 - loss: 0.1618 - val_accuracy: 0.9125 - val_loss: 0.2332\n",
            "Epoch 49/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9516 - loss: 0.1528 - val_accuracy: 0.9250 - val_loss: 0.2373\n",
            "Epoch 50/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9665 - loss: 0.1396 - val_accuracy: 0.9125 - val_loss: 0.2339\n",
            "Epoch 51/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9533 - loss: 0.1417 - val_accuracy: 0.9250 - val_loss: 0.2301\n",
            "Epoch 52/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9529 - loss: 0.1483 - val_accuracy: 0.9125 - val_loss: 0.2341\n",
            "Epoch 53/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9346 - loss: 0.1720 - val_accuracy: 0.9250 - val_loss: 0.2301\n",
            "Epoch 54/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9628 - loss: 0.1456 - val_accuracy: 0.9250 - val_loss: 0.2271\n",
            "Epoch 55/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9723 - loss: 0.1230 - val_accuracy: 0.9250 - val_loss: 0.2255\n",
            "Epoch 56/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9460 - loss: 0.1675 - val_accuracy: 0.9125 - val_loss: 0.2321\n",
            "Epoch 57/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9650 - loss: 0.1358 - val_accuracy: 0.9125 - val_loss: 0.2229\n",
            "Epoch 58/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9381 - loss: 0.1583 - val_accuracy: 0.9375 - val_loss: 0.2217\n",
            "Epoch 59/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9425 - loss: 0.1508 - val_accuracy: 0.9125 - val_loss: 0.2231\n",
            "Epoch 60/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9619 - loss: 0.1325 - val_accuracy: 0.9375 - val_loss: 0.2212\n",
            "Epoch 61/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9731 - loss: 0.1104 - val_accuracy: 0.9125 - val_loss: 0.2229\n",
            "Epoch 62/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9475 - loss: 0.1647 - val_accuracy: 0.9125 - val_loss: 0.2202\n",
            "Epoch 63/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9447 - loss: 0.1442 - val_accuracy: 0.9125 - val_loss: 0.2184\n",
            "Epoch 64/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9743 - loss: 0.0998 - val_accuracy: 0.9250 - val_loss: 0.2176\n",
            "Epoch 65/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9392 - loss: 0.1763 - val_accuracy: 0.9125 - val_loss: 0.2224\n",
            "Epoch 66/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9584 - loss: 0.1310 - val_accuracy: 0.9375 - val_loss: 0.2166\n",
            "Epoch 67/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9640 - loss: 0.1078 - val_accuracy: 0.9250 - val_loss: 0.2158\n",
            "Epoch 68/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9717 - loss: 0.1001 - val_accuracy: 0.9250 - val_loss: 0.2162\n",
            "Epoch 69/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9672 - loss: 0.1192 - val_accuracy: 0.9125 - val_loss: 0.2165\n",
            "Epoch 70/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9526 - loss: 0.1293 - val_accuracy: 0.9375 - val_loss: 0.2151\n",
            "Epoch 71/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9631 - loss: 0.1281 - val_accuracy: 0.9125 - val_loss: 0.2177\n",
            "Epoch 72/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9553 - loss: 0.1398 - val_accuracy: 0.9375 - val_loss: 0.2124\n",
            "Epoch 73/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9811 - loss: 0.0931 - val_accuracy: 0.9125 - val_loss: 0.2194\n",
            "Epoch 74/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9568 - loss: 0.1268 - val_accuracy: 0.9375 - val_loss: 0.2102\n",
            "Epoch 75/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9489 - loss: 0.1436 - val_accuracy: 0.9250 - val_loss: 0.2117\n",
            "Epoch 76/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9739 - loss: 0.1107 - val_accuracy: 0.9250 - val_loss: 0.2124\n",
            "Epoch 77/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9638 - loss: 0.1135 - val_accuracy: 0.9250 - val_loss: 0.2108\n",
            "Epoch 78/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9653 - loss: 0.1131 - val_accuracy: 0.9125 - val_loss: 0.2140\n",
            "Epoch 79/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9576 - loss: 0.1138 - val_accuracy: 0.9250 - val_loss: 0.2116\n",
            "Epoch 80/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9558 - loss: 0.1031 - val_accuracy: 0.9250 - val_loss: 0.2077\n",
            "Epoch 81/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9557 - loss: 0.1213 - val_accuracy: 0.9375 - val_loss: 0.2091\n",
            "Epoch 82/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9583 - loss: 0.1039 - val_accuracy: 0.9250 - val_loss: 0.2096\n",
            "Epoch 83/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9803 - loss: 0.0821 - val_accuracy: 0.9250 - val_loss: 0.2112\n",
            "Epoch 84/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9673 - loss: 0.1057 - val_accuracy: 0.9250 - val_loss: 0.2092\n",
            "Epoch 85/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9676 - loss: 0.1048 - val_accuracy: 0.9125 - val_loss: 0.2174\n",
            "Epoch 86/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9578 - loss: 0.1187 - val_accuracy: 0.9375 - val_loss: 0.2091\n",
            "Epoch 87/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9674 - loss: 0.1031 - val_accuracy: 0.9250 - val_loss: 0.2066\n",
            "Epoch 88/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9530 - loss: 0.1302 - val_accuracy: 0.9125 - val_loss: 0.2126\n",
            "Epoch 89/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9804 - loss: 0.0838 - val_accuracy: 0.9250 - val_loss: 0.2095\n",
            "Epoch 90/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9819 - loss: 0.0817 - val_accuracy: 0.9250 - val_loss: 0.2106\n",
            "Epoch 91/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9766 - loss: 0.0853 - val_accuracy: 0.9250 - val_loss: 0.2071\n",
            "Epoch 92/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9743 - loss: 0.0972 - val_accuracy: 0.9250 - val_loss: 0.2076\n",
            "Epoch 93/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9611 - loss: 0.1019 - val_accuracy: 0.9250 - val_loss: 0.2072\n",
            "Epoch 94/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9705 - loss: 0.0944 - val_accuracy: 0.9125 - val_loss: 0.2167\n",
            "Epoch 95/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9499 - loss: 0.1303 - val_accuracy: 0.9250 - val_loss: 0.2072\n",
            "Epoch 96/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9735 - loss: 0.0898 - val_accuracy: 0.9250 - val_loss: 0.2051\n",
            "Epoch 97/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9601 - loss: 0.1162 - val_accuracy: 0.9250 - val_loss: 0.2068\n",
            "Epoch 98/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9621 - loss: 0.1084 - val_accuracy: 0.9250 - val_loss: 0.2097\n",
            "Epoch 99/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9729 - loss: 0.0957 - val_accuracy: 0.9125 - val_loss: 0.2185\n",
            "Epoch 100/100\n",
            "\u001b[1m20/20\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9751 - loss: 0.0909 - val_accuracy: 0.9375 - val_loss: 0.2023\n",
            "\u001b[1m3/3\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
            "\n",
            "Experiment: Binary Classification (Exp 1: A vs E) - Accuracy: 0.9375\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94        40\n",
            "           1       0.97      0.90      0.94        40\n",
            "\n",
            "    accuracy                           0.94        80\n",
            "   macro avg       0.94      0.94      0.94        80\n",
            "weighted avg       0.94      0.94      0.94        80\n",
            "\n",
            "Model for Binary Classification (Exp 1: A vs E) saved successfully!\n",
            "\n",
            "\n",
            "Running Experiment: Binary Classification (Exp 2: A+D vs E)\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3116 - loss: 1.1107 - val_accuracy: 0.3333 - val_loss: 1.0943\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3407 - loss: 1.0958 - val_accuracy: 0.3417 - val_loss: 1.0883\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3720 - loss: 1.0837 - val_accuracy: 0.3667 - val_loss: 1.0828\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3976 - loss: 1.0814 - val_accuracy: 0.4417 - val_loss: 1.0722\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4517 - loss: 1.0640 - val_accuracy: 0.4667 - val_loss: 1.0618\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4635 - loss: 1.0559 - val_accuracy: 0.4583 - val_loss: 1.0509\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4723 - loss: 1.0445 - val_accuracy: 0.4583 - val_loss: 1.0399\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.4435 - loss: 1.0412 - val_accuracy: 0.4583 - val_loss: 1.0287\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.4385 - loss: 1.0282 - val_accuracy: 0.4583 - val_loss: 1.0167\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4616 - loss: 1.0097 - val_accuracy: 0.4583 - val_loss: 1.0026\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.4550 - loss: 1.0045 - val_accuracy: 0.4583 - val_loss: 0.9886\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4924 - loss: 0.9745 - val_accuracy: 0.4583 - val_loss: 0.9743\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.5107 - loss: 0.9318 - val_accuracy: 0.4667 - val_loss: 0.9608\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4836 - loss: 0.9522 - val_accuracy: 0.5000 - val_loss: 0.9466\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5381 - loss: 0.9141 - val_accuracy: 0.5250 - val_loss: 0.9298\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.5816 - loss: 0.9073 - val_accuracy: 0.5167 - val_loss: 0.9123\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.5443 - loss: 0.8897 - val_accuracy: 0.5583 - val_loss: 0.8935\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6155 - loss: 0.8716 - val_accuracy: 0.6083 - val_loss: 0.8757\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6141 - loss: 0.8348 - val_accuracy: 0.6667 - val_loss: 0.8558\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.6580 - loss: 0.8424 - val_accuracy: 0.6417 - val_loss: 0.8349\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.6868 - loss: 0.8071 - val_accuracy: 0.6667 - val_loss: 0.8132\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.7046 - loss: 0.7781 - val_accuracy: 0.7000 - val_loss: 0.7943\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7381 - loss: 0.7644 - val_accuracy: 0.7333 - val_loss: 0.7743\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7642 - loss: 0.7410 - val_accuracy: 0.7333 - val_loss: 0.7512\n",
            "Epoch 25/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7586 - loss: 0.7322 - val_accuracy: 0.7333 - val_loss: 0.7309\n",
            "Epoch 26/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8064 - loss: 0.6628 - val_accuracy: 0.7500 - val_loss: 0.7035\n",
            "Epoch 27/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8048 - loss: 0.6487 - val_accuracy: 0.7583 - val_loss: 0.6854\n",
            "Epoch 28/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8083 - loss: 0.6276 - val_accuracy: 0.7833 - val_loss: 0.6629\n",
            "Epoch 29/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7885 - loss: 0.6506 - val_accuracy: 0.7833 - val_loss: 0.6409\n",
            "Epoch 30/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8523 - loss: 0.5983 - val_accuracy: 0.7917 - val_loss: 0.6222\n",
            "Epoch 31/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8319 - loss: 0.5785 - val_accuracy: 0.8333 - val_loss: 0.6064\n",
            "Epoch 32/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8694 - loss: 0.5425 - val_accuracy: 0.8000 - val_loss: 0.5863\n",
            "Epoch 33/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8507 - loss: 0.5173 - val_accuracy: 0.8250 - val_loss: 0.5713\n",
            "Epoch 34/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8705 - loss: 0.5283 - val_accuracy: 0.8250 - val_loss: 0.5506\n",
            "Epoch 35/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8473 - loss: 0.4954 - val_accuracy: 0.8417 - val_loss: 0.5347\n",
            "Epoch 36/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8580 - loss: 0.4976 - val_accuracy: 0.8333 - val_loss: 0.5261\n",
            "Epoch 37/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8829 - loss: 0.4675 - val_accuracy: 0.8333 - val_loss: 0.5087\n",
            "Epoch 38/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8577 - loss: 0.4658 - val_accuracy: 0.8583 - val_loss: 0.4920\n",
            "Epoch 39/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8796 - loss: 0.4261 - val_accuracy: 0.8583 - val_loss: 0.4795\n",
            "Epoch 40/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8679 - loss: 0.4492 - val_accuracy: 0.8583 - val_loss: 0.4715\n",
            "Epoch 41/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8652 - loss: 0.4412 - val_accuracy: 0.8667 - val_loss: 0.4571\n",
            "Epoch 42/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8857 - loss: 0.3961 - val_accuracy: 0.8667 - val_loss: 0.4434\n",
            "Epoch 43/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8805 - loss: 0.3931 - val_accuracy: 0.8917 - val_loss: 0.4351\n",
            "Epoch 44/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9112 - loss: 0.3564 - val_accuracy: 0.8750 - val_loss: 0.4261\n",
            "Epoch 45/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8728 - loss: 0.3745 - val_accuracy: 0.8833 - val_loss: 0.4245\n",
            "Epoch 46/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8764 - loss: 0.3718 - val_accuracy: 0.8750 - val_loss: 0.4154\n",
            "Epoch 47/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.8953 - loss: 0.3538 - val_accuracy: 0.8833 - val_loss: 0.4025\n",
            "Epoch 48/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8895 - loss: 0.3390 - val_accuracy: 0.8917 - val_loss: 0.3950\n",
            "Epoch 49/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9062 - loss: 0.3238 - val_accuracy: 0.8917 - val_loss: 0.3863\n",
            "Epoch 50/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9178 - loss: 0.3112 - val_accuracy: 0.8833 - val_loss: 0.3823\n",
            "Epoch 51/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8815 - loss: 0.3404 - val_accuracy: 0.8667 - val_loss: 0.3869\n",
            "Epoch 52/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8940 - loss: 0.3391 - val_accuracy: 0.8917 - val_loss: 0.3808\n",
            "Epoch 53/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8886 - loss: 0.3293 - val_accuracy: 0.8833 - val_loss: 0.3704\n",
            "Epoch 54/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8827 - loss: 0.3494 - val_accuracy: 0.9000 - val_loss: 0.3601\n",
            "Epoch 55/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9067 - loss: 0.2855 - val_accuracy: 0.9000 - val_loss: 0.3577\n",
            "Epoch 56/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8898 - loss: 0.3331 - val_accuracy: 0.9083 - val_loss: 0.3498\n",
            "Epoch 57/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9213 - loss: 0.2878 - val_accuracy: 0.9000 - val_loss: 0.3487\n",
            "Epoch 58/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8918 - loss: 0.3329 - val_accuracy: 0.9083 - val_loss: 0.3402\n",
            "Epoch 59/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9094 - loss: 0.2907 - val_accuracy: 0.9083 - val_loss: 0.3392\n",
            "Epoch 60/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9058 - loss: 0.2920 - val_accuracy: 0.8917 - val_loss: 0.3391\n",
            "Epoch 61/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9160 - loss: 0.2888 - val_accuracy: 0.9000 - val_loss: 0.3348\n",
            "Epoch 62/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9183 - loss: 0.2492 - val_accuracy: 0.9083 - val_loss: 0.3268\n",
            "Epoch 63/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9031 - loss: 0.2808 - val_accuracy: 0.9000 - val_loss: 0.3305\n",
            "Epoch 64/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.3016 - val_accuracy: 0.9000 - val_loss: 0.3229\n",
            "Epoch 65/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9143 - loss: 0.2471 - val_accuracy: 0.9083 - val_loss: 0.3178\n",
            "Epoch 66/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8943 - loss: 0.2782 - val_accuracy: 0.9083 - val_loss: 0.3158\n",
            "Epoch 67/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9324 - loss: 0.2563 - val_accuracy: 0.8750 - val_loss: 0.3297\n",
            "Epoch 68/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9078 - loss: 0.2524 - val_accuracy: 0.9083 - val_loss: 0.3135\n",
            "Epoch 69/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8881 - loss: 0.3183 - val_accuracy: 0.9000 - val_loss: 0.3140\n",
            "Epoch 70/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2203 - val_accuracy: 0.9083 - val_loss: 0.3104\n",
            "Epoch 71/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9158 - loss: 0.2452 - val_accuracy: 0.9083 - val_loss: 0.3100\n",
            "Epoch 72/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9157 - loss: 0.2880 - val_accuracy: 0.8917 - val_loss: 0.3106\n",
            "Epoch 73/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9228 - loss: 0.2530 - val_accuracy: 0.9083 - val_loss: 0.3030\n",
            "Epoch 74/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9066 - loss: 0.2786 - val_accuracy: 0.9083 - val_loss: 0.3027\n",
            "Epoch 75/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9126 - loss: 0.2771 - val_accuracy: 0.9083 - val_loss: 0.2960\n",
            "Epoch 76/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9224 - loss: 0.2575 - val_accuracy: 0.9083 - val_loss: 0.3022\n",
            "Epoch 77/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9248 - loss: 0.2401 - val_accuracy: 0.9083 - val_loss: 0.2969\n",
            "Epoch 78/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9442 - loss: 0.1996 - val_accuracy: 0.9083 - val_loss: 0.2959\n",
            "Epoch 79/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8801 - loss: 0.2986 - val_accuracy: 0.8833 - val_loss: 0.2999\n",
            "Epoch 80/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9267 - loss: 0.2349 - val_accuracy: 0.8917 - val_loss: 0.2977\n",
            "Epoch 81/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9183 - loss: 0.2291 - val_accuracy: 0.9000 - val_loss: 0.2920\n",
            "Epoch 82/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9112 - loss: 0.2412 - val_accuracy: 0.9083 - val_loss: 0.2901\n",
            "Epoch 83/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9375 - loss: 0.2027 - val_accuracy: 0.9000 - val_loss: 0.2935\n",
            "Epoch 84/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9252 - loss: 0.2270 - val_accuracy: 0.9083 - val_loss: 0.2876\n",
            "Epoch 85/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9262 - loss: 0.2174 - val_accuracy: 0.9083 - val_loss: 0.2898\n",
            "Epoch 86/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9271 - loss: 0.2086 - val_accuracy: 0.9083 - val_loss: 0.2850\n",
            "Epoch 87/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9198 - loss: 0.2394 - val_accuracy: 0.9083 - val_loss: 0.2838\n",
            "Epoch 88/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9437 - loss: 0.1904 - val_accuracy: 0.9083 - val_loss: 0.2795\n",
            "Epoch 89/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9320 - loss: 0.2245 - val_accuracy: 0.9000 - val_loss: 0.2865\n",
            "Epoch 90/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9354 - loss: 0.2075 - val_accuracy: 0.9000 - val_loss: 0.2889\n",
            "Epoch 91/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9185 - loss: 0.2352 - val_accuracy: 0.9083 - val_loss: 0.2757\n",
            "Epoch 92/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9430 - loss: 0.1973 - val_accuracy: 0.8833 - val_loss: 0.2969\n",
            "Epoch 93/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9300 - loss: 0.2352 - val_accuracy: 0.9083 - val_loss: 0.2795\n",
            "Epoch 94/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9095 - loss: 0.2883 - val_accuracy: 0.9083 - val_loss: 0.2759\n",
            "Epoch 95/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 9ms/step - accuracy: 0.9210 - loss: 0.2445 - val_accuracy: 0.9000 - val_loss: 0.2775\n",
            "Epoch 96/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9373 - loss: 0.2165 - val_accuracy: 0.9083 - val_loss: 0.2746\n",
            "Epoch 97/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9257 - loss: 0.2142 - val_accuracy: 0.9083 - val_loss: 0.2736\n",
            "Epoch 98/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9379 - loss: 0.2099 - val_accuracy: 0.9083 - val_loss: 0.2759\n",
            "Epoch 99/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9206 - loss: 0.2366 - val_accuracy: 0.9083 - val_loss: 0.2687\n",
            "Epoch 100/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9361 - loss: 0.2085 - val_accuracy: 0.9083 - val_loss: 0.2758\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step\n",
            "\n",
            "Experiment: Binary Classification (Exp 2: A+D vs E) - Accuracy: 0.9083\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.97      0.94        40\n",
            "           1       0.88      0.93      0.90        40\n",
            "           2       0.94      0.82      0.88        40\n",
            "\n",
            "    accuracy                           0.91       120\n",
            "   macro avg       0.91      0.91      0.91       120\n",
            "weighted avg       0.91      0.91      0.91       120\n",
            "\n",
            "Model for Binary Classification (Exp 2: A+D vs E) saved successfully!\n",
            "\n",
            "\n",
            "Running Experiment: Multi-Class Classification (Exp 3: A vs D vs E)\n",
            "Epoch 1/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 13ms/step - accuracy: 0.3032 - loss: 1.1649 - val_accuracy: 0.3333 - val_loss: 1.1097\n",
            "Epoch 2/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.3589 - loss: 1.1082 - val_accuracy: 0.5167 - val_loss: 1.0850\n",
            "Epoch 3/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4446 - loss: 1.0730 - val_accuracy: 0.3333 - val_loss: 1.0734\n",
            "Epoch 4/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.3597 - loss: 1.0630 - val_accuracy: 0.4167 - val_loss: 1.0637\n",
            "Epoch 5/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.4503 - loss: 1.0428 - val_accuracy: 0.4500 - val_loss: 1.0513\n",
            "Epoch 6/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.5395 - loss: 1.0325 - val_accuracy: 0.5417 - val_loss: 1.0375\n",
            "Epoch 7/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6483 - loss: 1.0269 - val_accuracy: 0.5500 - val_loss: 1.0216\n",
            "Epoch 8/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6770 - loss: 1.0229 - val_accuracy: 0.5667 - val_loss: 1.0029\n",
            "Epoch 9/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7092 - loss: 0.9758 - val_accuracy: 0.6583 - val_loss: 0.9781\n",
            "Epoch 10/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7421 - loss: 0.9444 - val_accuracy: 0.6750 - val_loss: 0.9458\n",
            "Epoch 11/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7411 - loss: 0.9133 - val_accuracy: 0.6750 - val_loss: 0.9117\n",
            "Epoch 12/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7336 - loss: 0.8762 - val_accuracy: 0.6917 - val_loss: 0.8779\n",
            "Epoch 13/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7697 - loss: 0.8295 - val_accuracy: 0.7250 - val_loss: 0.8438\n",
            "Epoch 14/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8021 - loss: 0.7623 - val_accuracy: 0.7167 - val_loss: 0.8079\n",
            "Epoch 15/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7718 - loss: 0.7684 - val_accuracy: 0.7167 - val_loss: 0.7744\n",
            "Epoch 16/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7819 - loss: 0.7046 - val_accuracy: 0.7167 - val_loss: 0.7419\n",
            "Epoch 17/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.7695 - loss: 0.6830 - val_accuracy: 0.7250 - val_loss: 0.7118\n",
            "Epoch 18/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8211 - loss: 0.6263 - val_accuracy: 0.7333 - val_loss: 0.6820\n",
            "Epoch 19/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8015 - loss: 0.6268 - val_accuracy: 0.7333 - val_loss: 0.6572\n",
            "Epoch 20/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8088 - loss: 0.5953 - val_accuracy: 0.8000 - val_loss: 0.6431\n",
            "Epoch 21/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7812 - loss: 0.5897 - val_accuracy: 0.7500 - val_loss: 0.6114\n",
            "Epoch 22/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8222 - loss: 0.5441 - val_accuracy: 0.7833 - val_loss: 0.5926\n",
            "Epoch 23/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8200 - loss: 0.5252 - val_accuracy: 0.7583 - val_loss: 0.5786\n",
            "Epoch 24/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8210 - loss: 0.5316 - val_accuracy: 0.7917 - val_loss: 0.5592\n",
            "Epoch 25/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8662 - loss: 0.4787 - val_accuracy: 0.7917 - val_loss: 0.5427\n",
            "Epoch 26/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8387 - loss: 0.4753 - val_accuracy: 0.8000 - val_loss: 0.5281\n",
            "Epoch 27/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8269 - loss: 0.4953 - val_accuracy: 0.8083 - val_loss: 0.5194\n",
            "Epoch 28/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8167 - loss: 0.4747 - val_accuracy: 0.8167 - val_loss: 0.5055\n",
            "Epoch 29/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8554 - loss: 0.4472 - val_accuracy: 0.8083 - val_loss: 0.4977\n",
            "Epoch 30/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8237 - loss: 0.4756 - val_accuracy: 0.8000 - val_loss: 0.4833\n",
            "Epoch 31/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8679 - loss: 0.4102 - val_accuracy: 0.8167 - val_loss: 0.4730\n",
            "Epoch 32/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.8616 - loss: 0.4111 - val_accuracy: 0.8083 - val_loss: 0.4722\n",
            "Epoch 33/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8893 - loss: 0.4016 - val_accuracy: 0.8250 - val_loss: 0.4629\n",
            "Epoch 34/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.8363 - loss: 0.4349 - val_accuracy: 0.8250 - val_loss: 0.4525\n",
            "Epoch 35/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8327 - loss: 0.4124 - val_accuracy: 0.8167 - val_loss: 0.4434\n",
            "Epoch 36/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8364 - loss: 0.4205 - val_accuracy: 0.8167 - val_loss: 0.4385\n",
            "Epoch 37/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8727 - loss: 0.3700 - val_accuracy: 0.8167 - val_loss: 0.4401\n",
            "Epoch 38/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8460 - loss: 0.4143 - val_accuracy: 0.8417 - val_loss: 0.4276\n",
            "Epoch 39/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8611 - loss: 0.3845 - val_accuracy: 0.8417 - val_loss: 0.4180\n",
            "Epoch 40/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8715 - loss: 0.3569 - val_accuracy: 0.8417 - val_loss: 0.4163\n",
            "Epoch 41/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8667 - loss: 0.4019 - val_accuracy: 0.8500 - val_loss: 0.4096\n",
            "Epoch 42/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8547 - loss: 0.3870 - val_accuracy: 0.8583 - val_loss: 0.4007\n",
            "Epoch 43/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8594 - loss: 0.3683 - val_accuracy: 0.8500 - val_loss: 0.3960\n",
            "Epoch 44/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8755 - loss: 0.3465 - val_accuracy: 0.8583 - val_loss: 0.3875\n",
            "Epoch 45/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8807 - loss: 0.3321 - val_accuracy: 0.8583 - val_loss: 0.3812\n",
            "Epoch 46/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8572 - loss: 0.3623 - val_accuracy: 0.8750 - val_loss: 0.3790\n",
            "Epoch 47/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8841 - loss: 0.3278 - val_accuracy: 0.8750 - val_loss: 0.3753\n",
            "Epoch 48/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8849 - loss: 0.3381 - val_accuracy: 0.8667 - val_loss: 0.3713\n",
            "Epoch 49/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8713 - loss: 0.3545 - val_accuracy: 0.8667 - val_loss: 0.3633\n",
            "Epoch 50/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9273 - loss: 0.2829 - val_accuracy: 0.8833 - val_loss: 0.3588\n",
            "Epoch 51/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8808 - loss: 0.3118 - val_accuracy: 0.8833 - val_loss: 0.3557\n",
            "Epoch 52/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8681 - loss: 0.3291 - val_accuracy: 0.8917 - val_loss: 0.3508\n",
            "Epoch 53/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8725 - loss: 0.3190 - val_accuracy: 0.8750 - val_loss: 0.3449\n",
            "Epoch 54/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8647 - loss: 0.3409 - val_accuracy: 0.9000 - val_loss: 0.3413\n",
            "Epoch 55/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8773 - loss: 0.3202 - val_accuracy: 0.9000 - val_loss: 0.3397\n",
            "Epoch 56/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9140 - loss: 0.2764 - val_accuracy: 0.8917 - val_loss: 0.3317\n",
            "Epoch 57/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8988 - loss: 0.2863 - val_accuracy: 0.8917 - val_loss: 0.3334\n",
            "Epoch 58/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8809 - loss: 0.3324 - val_accuracy: 0.8917 - val_loss: 0.3333\n",
            "Epoch 59/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8970 - loss: 0.3125 - val_accuracy: 0.8917 - val_loss: 0.3368\n",
            "Epoch 60/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9091 - loss: 0.2931 - val_accuracy: 0.8917 - val_loss: 0.3255\n",
            "Epoch 61/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8955 - loss: 0.2876 - val_accuracy: 0.9000 - val_loss: 0.3254\n",
            "Epoch 62/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.8983 - loss: 0.2839 - val_accuracy: 0.8917 - val_loss: 0.3192\n",
            "Epoch 63/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8974 - loss: 0.2771 - val_accuracy: 0.9000 - val_loss: 0.3161\n",
            "Epoch 64/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9147 - loss: 0.2707 - val_accuracy: 0.8917 - val_loss: 0.3142\n",
            "Epoch 65/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9148 - loss: 0.2734 - val_accuracy: 0.9000 - val_loss: 0.3254\n",
            "Epoch 66/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9083 - loss: 0.2755 - val_accuracy: 0.9083 - val_loss: 0.3098\n",
            "Epoch 67/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9315 - loss: 0.2593 - val_accuracy: 0.8917 - val_loss: 0.3122\n",
            "Epoch 68/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9171 - loss: 0.2561 - val_accuracy: 0.9167 - val_loss: 0.3126\n",
            "Epoch 69/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8874 - loss: 0.3003 - val_accuracy: 0.9000 - val_loss: 0.3098\n",
            "Epoch 70/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9001 - loss: 0.3149 - val_accuracy: 0.9000 - val_loss: 0.3029\n",
            "Epoch 71/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9127 - loss: 0.2868 - val_accuracy: 0.9000 - val_loss: 0.2997\n",
            "Epoch 72/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9070 - loss: 0.2709 - val_accuracy: 0.9000 - val_loss: 0.2955\n",
            "Epoch 73/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8871 - loss: 0.3102 - val_accuracy: 0.8917 - val_loss: 0.2979\n",
            "Epoch 74/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9071 - loss: 0.3039 - val_accuracy: 0.8917 - val_loss: 0.2989\n",
            "Epoch 75/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9335 - loss: 0.2062 - val_accuracy: 0.8917 - val_loss: 0.2896\n",
            "Epoch 76/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9080 - loss: 0.2441 - val_accuracy: 0.9250 - val_loss: 0.2895\n",
            "Epoch 77/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9161 - loss: 0.2531 - val_accuracy: 0.9000 - val_loss: 0.2848\n",
            "Epoch 78/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.9059 - loss: 0.2650 - val_accuracy: 0.9000 - val_loss: 0.2924\n",
            "Epoch 79/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9176 - loss: 0.2441 - val_accuracy: 0.9000 - val_loss: 0.2855\n",
            "Epoch 80/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 8ms/step - accuracy: 0.9133 - loss: 0.2513 - val_accuracy: 0.9083 - val_loss: 0.2888\n",
            "Epoch 81/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9132 - loss: 0.2402 - val_accuracy: 0.9000 - val_loss: 0.2853\n",
            "Epoch 82/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step - accuracy: 0.9078 - loss: 0.2648 - val_accuracy: 0.9167 - val_loss: 0.2758\n",
            "Epoch 83/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9116 - loss: 0.2539 - val_accuracy: 0.9083 - val_loss: 0.2828\n",
            "Epoch 84/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8961 - loss: 0.2811 - val_accuracy: 0.9167 - val_loss: 0.2711\n",
            "Epoch 85/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9060 - loss: 0.2680 - val_accuracy: 0.9167 - val_loss: 0.2765\n",
            "Epoch 86/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9256 - loss: 0.2559 - val_accuracy: 0.9250 - val_loss: 0.2694\n",
            "Epoch 87/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9383 - loss: 0.2190 - val_accuracy: 0.9167 - val_loss: 0.2649\n",
            "Epoch 88/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9077 - loss: 0.2496 - val_accuracy: 0.9000 - val_loss: 0.2695\n",
            "Epoch 89/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9361 - loss: 0.2356 - val_accuracy: 0.9167 - val_loss: 0.2691\n",
            "Epoch 90/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2612 - val_accuracy: 0.9333 - val_loss: 0.2670\n",
            "Epoch 91/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9264 - loss: 0.2157 - val_accuracy: 0.9167 - val_loss: 0.2647\n",
            "Epoch 92/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9100 - loss: 0.2609 - val_accuracy: 0.9333 - val_loss: 0.2603\n",
            "Epoch 93/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9348 - loss: 0.2413 - val_accuracy: 0.9250 - val_loss: 0.2645\n",
            "Epoch 94/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9257 - loss: 0.2311 - val_accuracy: 0.9167 - val_loss: 0.2660\n",
            "Epoch 95/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.8972 - loss: 0.2690 - val_accuracy: 0.9083 - val_loss: 0.2631\n",
            "Epoch 96/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9167 - loss: 0.2403 - val_accuracy: 0.9333 - val_loss: 0.2583\n",
            "Epoch 97/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9157 - loss: 0.2562 - val_accuracy: 0.9000 - val_loss: 0.2604\n",
            "Epoch 98/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9189 - loss: 0.2346 - val_accuracy: 0.9167 - val_loss: 0.2644\n",
            "Epoch 99/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9097 - loss: 0.2511 - val_accuracy: 0.9000 - val_loss: 0.2632\n",
            "Epoch 100/100\n",
            "\u001b[1m30/30\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.9151 - loss: 0.2598 - val_accuracy: 0.9083 - val_loss: 0.2641\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\n",
            "Experiment: Multi-Class Classification (Exp 3: A vs D vs E) - Accuracy: 0.9083\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.97      0.93        40\n",
            "           1       0.89      0.97      0.93        40\n",
            "           2       0.97      0.78      0.86        40\n",
            "\n",
            "    accuracy                           0.91       120\n",
            "   macro avg       0.91      0.91      0.91       120\n",
            "weighted avg       0.91      0.91      0.91       120\n",
            "\n",
            "Model for Multi-Class Classification (Exp 3: A vs D vs E) saved successfully!\n",
            "\n"
          ]
        }
      ]
    }
  ]
}