{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPUcKgI6v_hw",
        "outputId": "3d87fc8d-e2f9-4d9a-d2a9-bee52859041a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: PyWavelets in /usr/local/lib/python3.11/dist-packages (1.8.0)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.11/dist-packages (from PyWavelets) (2.0.2)\n",
            "Requirement already satisfied: antropy in /usr/local/lib/python3.11/dist-packages (0.1.9)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from antropy) (2.0.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from antropy) (1.14.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from antropy) (1.6.1)\n",
            "Requirement already satisfied: numba>=0.57 in /usr/local/lib/python3.11/dist-packages (from antropy) (0.60.0)\n",
            "Requirement already satisfied: llvmlite<0.44,>=0.43.0dev0 in /usr/local/lib/python3.11/dist-packages (from numba>=0.57->antropy) (0.43.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->antropy) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->antropy) (3.6.0)\n",
            "Collecting hurst\n",
            "  Downloading hurst-0.0.5-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: pandas>=0.18 in /usr/local/lib/python3.11/dist-packages (from hurst) (2.2.2)\n",
            "Requirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.11/dist-packages (from hurst) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->hurst) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->hurst) (2025.1)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.18->hurst) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=0.18->hurst) (1.17.0)\n",
            "Downloading hurst-0.0.5-py3-none-any.whl (5.9 kB)\n",
            "Installing collected packages: hurst\n",
            "Successfully installed hurst-0.0.5\n"
          ]
        }
      ],
      "source": [
        "!pip install PyWavelets\n",
        "from google.colab import drive\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, Flatten, Bidirectional, LSTM, Dense, Dropout, BatchNormalization\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
        "from sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pywt  # For Discrete Wavelet Transform (DWT)\n",
        "from sklearn.feature_selection import RFE\n",
        "from sklearn.svm import SVC\n",
        "!pip install antropy\n",
        "import antropy as ant  # For Approximate and Fuzzy Entropy\n",
        "!pip install hurst\n",
        "from hurst import compute_Hc  # For Hurst Exponent\n",
        "from scipy.io import savemat\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define input and output folders\n",
        "input_folder = \"/content/drive/MyDrive/EEG Dataset\"\n",
        "processed_folder = os.path.join(input_folder, \"Processed_CNN_BiLSTM\")\n",
        "model_save_folder = os.path.join(input_folder, \"Models_CNN_BiLSTM\")\n",
        "os.makedirs(processed_folder, exist_ok=True)\n",
        "os.makedirs(model_save_folder, exist_ok=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o6tStPWXwYUw",
        "outputId": "b4519fa0-4029-467d-8821-7f7c38b068e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define label mapping for 3-class classification\n",
        "label_map = {\"F\": 0, \"N\": 0, \"O\": 1, \"Z\": 1, \"S\": 2}  # Three-class classification\n",
        "\n",
        "# Function to apply band-pass filter\n",
        "def bandpass_filter(signal, lowcut=0.5, highcut=50, fs=173.61, order=4):\n",
        "    from scipy.signal import butter, filtfilt\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = butter(order, [low, high], btype='band')\n",
        "    return filtfilt(b, a, signal)\n",
        "\n",
        "# Feature Extraction Function\n",
        "def extract_features(signal):\n",
        "    coeffs = pywt.wavedec(signal, wavelet='db4', level=4)\n",
        "    dwt_features = [np.mean(c) for c in coeffs] + [np.std(c) for c in coeffs]\n",
        "    apen = ant.app_entropy(signal)\n",
        "    fuen = ant.perm_entropy(signal, order=2, normalize=True)\n",
        "    rms = np.sqrt(np.mean(signal**2))\n",
        "    hurst_exp, _, _ = compute_Hc(signal, kind='random_walk')\n",
        "    return np.array(dwt_features + [apen, fuen, rms, hurst_exp])"
      ],
      "metadata": {
        "id": "jZTZ1MyNwj8r"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess data\n",
        "all_features, all_labels = [], []\n",
        "for folder in label_map.keys():\n",
        "    folder_path = os.path.join(input_folder, folder)\n",
        "    if not os.path.exists(folder_path):\n",
        "        print(f\"Warning: {folder_path} not found. Skipping...\")\n",
        "        continue\n",
        "\n",
        "    for file in os.listdir(folder_path):\n",
        "        if file.endswith(\".txt\") or file.endswith(\".TXT\"):\n",
        "            file_path = os.path.join(folder_path, file)\n",
        "            signal = np.loadtxt(file_path)\n",
        "            filtered_signal = bandpass_filter(signal)\n",
        "            scaler = StandardScaler()\n",
        "            normalized_signal = scaler.fit_transform(filtered_signal.reshape(-1, 1)).flatten()\n",
        "            features = extract_features(normalized_signal)\n",
        "            all_features.append(features)\n",
        "            all_labels.append(label_map[folder])\n",
        "\n",
        "# Convert to numpy arrays\n",
        "X = np.array(all_features)\n",
        "y = np.array(all_labels)\n",
        "y = LabelEncoder().fit_transform(y)\n",
        "num_classes = len(np.unique(y))\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "2GNLPve_wmcM"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "# Define CNN-BiLSTM model (following the exact architecture from the paper)\n",
        "def create_cnn_bilstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Input(shape=(input_shape, 1)),\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Conv1D(filters=256, kernel_size=3, activation='relu', padding='same'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "        Bidirectional(LSTM(64, return_sequences=True)),\n",
        "        Bidirectional(LSTM(32, return_sequences=False)),\n",
        "        Flatten(),\n",
        "        Dense(128, activation='relu', kernel_regularizer=tf.keras.regularizers.l2(0.0001)),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train model\n",
        "model = create_cnn_bilstm_model(input_shape=X.shape[1], num_classes=num_classes)\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "APTXc-ipyXe3",
        "outputId": "3d81cbb7-56c5-4f4e-dcbb-377a406c35ed"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_10\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_10\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_30 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_30               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m14\u001b[0m, \u001b[38;5;34m64\u001b[0m)              │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_30 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m64\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_31 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │          \u001b[38;5;34m24,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_31               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_31 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │          \u001b[38;5;34m98,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_32               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_32 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m256\u001b[0m)              │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_20 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m128\u001b[0m)              │         \u001b[38;5;34m164,352\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_21 (\u001b[38;5;33mBidirectional\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m41,216\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (\u001b[38;5;33mFlatten\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │           \u001b[38;5;34m8,320\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m387\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_30               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">14</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_30 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_31               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_31 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_32               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)              │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">164,352</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ bidirectional_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">41,216</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_20 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,320</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_21 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">387</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m339,587\u001b[0m (1.30 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">339,587</span> (1.30 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m338,691\u001b[0m (1.29 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">338,691</span> (1.29 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train-Test Split Before Feature Selection\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
        "\n",
        "# Apply Feature Selection After Splitting\n",
        "svm = SVC(kernel='linear')\n",
        "rfe = RFE(svm, n_features_to_select=30)  # Keep more features to avoid losing useful information\n",
        "X_train_selected = rfe.fit_transform(X_train, np.argmax(y_train, axis=1))\n",
        "X_test_selected = rfe.transform(X_test)  # Apply the same transformation\n",
        "\n",
        "# Reshape for CNN-BiLSTM\n",
        "X_train_selected = X_train_selected.reshape(X_train_selected.shape[0], X_train_selected.shape[1], 1)\n",
        "X_test_selected = X_test_selected.reshape(X_test_selected.shape[0], X_test_selected.shape[1], 1)\n",
        "\n",
        "# Learning Rate Scheduler\n",
        "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
        "    initial_learning_rate=0.001,\n",
        "    decay_steps=100,\n",
        "    decay_rate=0.9\n",
        ")\n",
        "optimizer = Adam(learning_rate=lr_schedule)\n",
        "\n",
        "# Train BiLSTM Model\n",
        "model = create_cnn_bilstm_model(input_shape=X_train_selected.shape[1], num_classes=num_classes)\n",
        "history = model.fit(X_train_selected, y_train, epochs=100, batch_size=64, validation_data=(X_test_selected, y_test), verbose=1)\n",
        "\n",
        "# Evaluate the Model\n",
        "y_pred = model.predict(X_test_selected)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "# Print Classification Report\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes))\n",
        "\n",
        "# Plot Confusion Matrix\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for 3-Class Classification')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "7SRVz02Y0Lsy",
        "outputId": "88dad93a-af84-4193-cd71-a2bb100c019d"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/feature_selection/_rfe.py:300: UserWarning: Found n_features_to_select=30 > n_features=14. There will be no feature selection and all features will be kept.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 189ms/step - accuracy: 0.5594 - loss: 1.0299 - val_accuracy: 0.5000 - val_loss: 1.0867\n",
            "Epoch 2/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.7912 - loss: 0.6945 - val_accuracy: 0.7800 - val_loss: 1.0615\n",
            "Epoch 3/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.8088 - loss: 0.5174 - val_accuracy: 0.4200 - val_loss: 1.0606\n",
            "Epoch 4/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8534 - loss: 0.3866 - val_accuracy: 0.4000 - val_loss: 1.0618\n",
            "Epoch 5/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9097 - loss: 0.2883 - val_accuracy: 0.4000 - val_loss: 1.0747\n",
            "Epoch 6/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9510 - loss: 0.1903 - val_accuracy: 0.4000 - val_loss: 1.0767\n",
            "Epoch 7/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9331 - loss: 0.2139 - val_accuracy: 0.4000 - val_loss: 1.0976\n",
            "Epoch 8/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9511 - loss: 0.1664 - val_accuracy: 0.4000 - val_loss: 1.0837\n",
            "Epoch 9/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9237 - loss: 0.1756 - val_accuracy: 0.4000 - val_loss: 1.0933\n",
            "Epoch 10/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9419 - loss: 0.1402 - val_accuracy: 0.4000 - val_loss: 1.0878\n",
            "Epoch 11/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9608 - loss: 0.1418 - val_accuracy: 0.4000 - val_loss: 1.1101\n",
            "Epoch 12/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9215 - loss: 0.2460 - val_accuracy: 0.4000 - val_loss: 1.1080\n",
            "Epoch 13/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9563 - loss: 0.1560 - val_accuracy: 0.4000 - val_loss: 1.1091\n",
            "Epoch 14/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9669 - loss: 0.1192 - val_accuracy: 0.4000 - val_loss: 1.1197\n",
            "Epoch 15/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9649 - loss: 0.1173 - val_accuracy: 0.4000 - val_loss: 1.1088\n",
            "Epoch 16/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9451 - loss: 0.1541 - val_accuracy: 0.4000 - val_loss: 1.1172\n",
            "Epoch 17/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9682 - loss: 0.1091 - val_accuracy: 0.4000 - val_loss: 1.1193\n",
            "Epoch 18/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9828 - loss: 0.0789 - val_accuracy: 0.4000 - val_loss: 1.1196\n",
            "Epoch 19/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9777 - loss: 0.0770 - val_accuracy: 0.4000 - val_loss: 1.1145\n",
            "Epoch 20/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9581 - loss: 0.1136 - val_accuracy: 0.4000 - val_loss: 1.1101\n",
            "Epoch 21/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9581 - loss: 0.1144 - val_accuracy: 0.4000 - val_loss: 1.0875\n",
            "Epoch 22/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9659 - loss: 0.0993 - val_accuracy: 0.4000 - val_loss: 1.0921\n",
            "Epoch 23/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9588 - loss: 0.1233 - val_accuracy: 0.4000 - val_loss: 1.0904\n",
            "Epoch 24/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9729 - loss: 0.1105 - val_accuracy: 0.4000 - val_loss: 1.1195\n",
            "Epoch 25/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 56ms/step - accuracy: 0.9398 - loss: 0.2202 - val_accuracy: 0.4000 - val_loss: 1.1251\n",
            "Epoch 26/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9359 - loss: 0.1916 - val_accuracy: 0.4000 - val_loss: 1.1856\n",
            "Epoch 27/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9480 - loss: 0.1757 - val_accuracy: 0.4000 - val_loss: 1.1063\n",
            "Epoch 28/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9375 - loss: 0.1834 - val_accuracy: 0.4000 - val_loss: 1.1638\n",
            "Epoch 29/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9687 - loss: 0.1085 - val_accuracy: 0.4000 - val_loss: 1.1860\n",
            "Epoch 30/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9713 - loss: 0.1015 - val_accuracy: 0.4000 - val_loss: 1.1632\n",
            "Epoch 31/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9757 - loss: 0.0909 - val_accuracy: 0.4000 - val_loss: 1.2786\n",
            "Epoch 32/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9451 - loss: 0.1351 - val_accuracy: 0.4000 - val_loss: 1.2315\n",
            "Epoch 33/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9671 - loss: 0.1033 - val_accuracy: 0.4000 - val_loss: 1.2367\n",
            "Epoch 34/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9563 - loss: 0.1229 - val_accuracy: 0.5600 - val_loss: 0.9179\n",
            "Epoch 35/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9411 - loss: 0.1501 - val_accuracy: 0.4900 - val_loss: 0.9606\n",
            "Epoch 36/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9570 - loss: 0.1332 - val_accuracy: 0.7800 - val_loss: 0.6507\n",
            "Epoch 37/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9701 - loss: 0.1031 - val_accuracy: 0.5500 - val_loss: 0.8824\n",
            "Epoch 38/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9624 - loss: 0.1020 - val_accuracy: 0.7400 - val_loss: 0.6584\n",
            "Epoch 39/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9652 - loss: 0.1045 - val_accuracy: 0.5600 - val_loss: 0.8593\n",
            "Epoch 40/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9576 - loss: 0.1193 - val_accuracy: 0.7600 - val_loss: 0.6528\n",
            "Epoch 41/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9287 - loss: 0.1687 - val_accuracy: 0.7200 - val_loss: 0.7472\n",
            "Epoch 42/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9632 - loss: 0.1278 - val_accuracy: 0.5500 - val_loss: 0.9197\n",
            "Epoch 43/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9504 - loss: 0.1338 - val_accuracy: 0.7400 - val_loss: 0.6839\n",
            "Epoch 44/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9625 - loss: 0.0877 - val_accuracy: 0.6800 - val_loss: 0.7858\n",
            "Epoch 45/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9692 - loss: 0.0890 - val_accuracy: 0.7000 - val_loss: 0.7988\n",
            "Epoch 46/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9814 - loss: 0.0711 - val_accuracy: 0.6300 - val_loss: 0.8276\n",
            "Epoch 47/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9736 - loss: 0.0744 - val_accuracy: 0.7300 - val_loss: 0.6973\n",
            "Epoch 48/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9674 - loss: 0.1135 - val_accuracy: 0.6300 - val_loss: 0.8400\n",
            "Epoch 49/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9596 - loss: 0.0828 - val_accuracy: 0.7700 - val_loss: 0.6942\n",
            "Epoch 50/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9892 - loss: 0.0503 - val_accuracy: 0.7700 - val_loss: 0.6800\n",
            "Epoch 51/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9679 - loss: 0.0704 - val_accuracy: 0.8100 - val_loss: 0.5380\n",
            "Epoch 52/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9569 - loss: 0.1162 - val_accuracy: 0.7900 - val_loss: 0.5915\n",
            "Epoch 53/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9298 - loss: 0.1984 - val_accuracy: 0.7300 - val_loss: 1.0399\n",
            "Epoch 54/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9362 - loss: 0.2022 - val_accuracy: 0.7300 - val_loss: 0.6393\n",
            "Epoch 55/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9486 - loss: 0.1429 - val_accuracy: 0.8300 - val_loss: 0.4620\n",
            "Epoch 56/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.9766 - loss: 0.0806 - val_accuracy: 0.7700 - val_loss: 0.5729\n",
            "Epoch 57/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9676 - loss: 0.0785 - val_accuracy: 0.8600 - val_loss: 0.3850\n",
            "Epoch 58/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9707 - loss: 0.0731 - val_accuracy: 0.8500 - val_loss: 0.3436\n",
            "Epoch 59/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9797 - loss: 0.0702 - val_accuracy: 0.8300 - val_loss: 0.4554\n",
            "Epoch 60/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9648 - loss: 0.0889 - val_accuracy: 0.8300 - val_loss: 0.4152\n",
            "Epoch 61/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9774 - loss: 0.0701 - val_accuracy: 0.7600 - val_loss: 0.7856\n",
            "Epoch 62/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9544 - loss: 0.1140 - val_accuracy: 0.7500 - val_loss: 1.0466\n",
            "Epoch 63/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9643 - loss: 0.0859 - val_accuracy: 0.8700 - val_loss: 0.3546\n",
            "Epoch 64/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 52ms/step - accuracy: 0.9592 - loss: 0.1050 - val_accuracy: 0.8700 - val_loss: 0.3921\n",
            "Epoch 65/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9762 - loss: 0.0787 - val_accuracy: 0.7900 - val_loss: 0.7687\n",
            "Epoch 66/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 55ms/step - accuracy: 0.9578 - loss: 0.1036 - val_accuracy: 0.7600 - val_loss: 0.8625\n",
            "Epoch 67/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9660 - loss: 0.1204 - val_accuracy: 0.7900 - val_loss: 0.9653\n",
            "Epoch 68/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9598 - loss: 0.1037 - val_accuracy: 0.7500 - val_loss: 0.8518\n",
            "Epoch 69/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9584 - loss: 0.1050 - val_accuracy: 0.8900 - val_loss: 0.4365\n",
            "Epoch 70/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9758 - loss: 0.0663 - val_accuracy: 0.8300 - val_loss: 0.6764\n",
            "Epoch 71/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9791 - loss: 0.0532 - val_accuracy: 0.8400 - val_loss: 0.5440\n",
            "Epoch 72/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9718 - loss: 0.0629 - val_accuracy: 0.8600 - val_loss: 0.5386\n",
            "Epoch 73/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9837 - loss: 0.0563 - val_accuracy: 0.7700 - val_loss: 0.9752\n",
            "Epoch 74/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9729 - loss: 0.0724 - val_accuracy: 0.8300 - val_loss: 0.7172\n",
            "Epoch 75/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9596 - loss: 0.0827 - val_accuracy: 0.7800 - val_loss: 0.9198\n",
            "Epoch 76/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9546 - loss: 0.1468 - val_accuracy: 0.8400 - val_loss: 0.5218\n",
            "Epoch 77/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9661 - loss: 0.0731 - val_accuracy: 0.9600 - val_loss: 0.1393\n",
            "Epoch 78/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9524 - loss: 0.0955 - val_accuracy: 0.9000 - val_loss: 0.3564\n",
            "Epoch 79/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9564 - loss: 0.0910 - val_accuracy: 0.9000 - val_loss: 0.4419\n",
            "Epoch 80/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9710 - loss: 0.0648 - val_accuracy: 0.9800 - val_loss: 0.1018\n",
            "Epoch 81/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9574 - loss: 0.0996 - val_accuracy: 0.8200 - val_loss: 0.4420\n",
            "Epoch 82/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9477 - loss: 0.1997 - val_accuracy: 0.8100 - val_loss: 0.6994\n",
            "Epoch 83/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9501 - loss: 0.1478 - val_accuracy: 0.8700 - val_loss: 0.2976\n",
            "Epoch 84/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9821 - loss: 0.0840 - val_accuracy: 0.9300 - val_loss: 0.2101\n",
            "Epoch 85/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9752 - loss: 0.0833 - val_accuracy: 0.9100 - val_loss: 0.2963\n",
            "Epoch 86/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9730 - loss: 0.0796 - val_accuracy: 0.9100 - val_loss: 0.3191\n",
            "Epoch 87/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9844 - loss: 0.0565 - val_accuracy: 0.8700 - val_loss: 0.3041\n",
            "Epoch 88/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9811 - loss: 0.0694 - val_accuracy: 0.9100 - val_loss: 0.3318\n",
            "Epoch 89/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9816 - loss: 0.0717 - val_accuracy: 0.9400 - val_loss: 0.2383\n",
            "Epoch 90/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 0.9647 - loss: 0.1058 - val_accuracy: 0.9300 - val_loss: 0.2456\n",
            "Epoch 91/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9677 - loss: 0.0810 - val_accuracy: 0.9200 - val_loss: 0.2218\n",
            "Epoch 92/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9797 - loss: 0.0748 - val_accuracy: 0.9000 - val_loss: 0.4157\n",
            "Epoch 93/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9749 - loss: 0.0791 - val_accuracy: 0.9100 - val_loss: 0.2268\n",
            "Epoch 94/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.9850 - loss: 0.0543 - val_accuracy: 0.8900 - val_loss: 0.4044\n",
            "Epoch 95/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9757 - loss: 0.0594 - val_accuracy: 0.9100 - val_loss: 0.4047\n",
            "Epoch 96/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9696 - loss: 0.0577 - val_accuracy: 0.9400 - val_loss: 0.1983\n",
            "Epoch 97/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.9747 - loss: 0.0630 - val_accuracy: 0.9100 - val_loss: 0.3928\n",
            "Epoch 98/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 0.9629 - loss: 0.0841 - val_accuracy: 0.9300 - val_loss: 0.2281\n",
            "Epoch 99/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 0.9824 - loss: 0.0525 - val_accuracy: 0.9000 - val_loss: 0.3586\n",
            "Epoch 100/100\n",
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9891 - loss: 0.0440 - val_accuracy: 0.9100 - val_loss: 0.2594\n",
            "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 309ms/step\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.95      0.97      0.96        40\n",
            "           1       0.85      0.97      0.91        40\n",
            "           2       1.00      0.65      0.79        20\n",
            "\n",
            "    accuracy                           0.91       100\n",
            "   macro avg       0.93      0.87      0.89       100\n",
            "weighted avg       0.92      0.91      0.91       100\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Save model\n",
        "model.save(os.path.join(model_save_folder, \"cnn_bilstm_3class.h5\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Ilk4MBR6bBa",
        "outputId": "8db76f56-f064-4ecc-bda4-3c2fe116a513"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ]
    }
  ]
}