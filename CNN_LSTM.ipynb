{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ptiip3mtN4VB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.signal as signal\n",
        "import os\n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.io import savemat\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Define constants\n",
        "sampling_rate = 173.61  # Hz\n",
        "low_cutoff = 0.5  # Hz\n",
        "high_cutoff = 50  # Hz\n",
        "order = 5  # Filter order"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mYM7-UnQos9",
        "outputId": "a7f7fea0-3b74-444a-96ac-94a915a31537"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Bandpass filter design\n",
        "def butter_bandpass_filter(data, lowcut, highcut, fs, order=5):\n",
        "    nyquist = 0.5 * fs\n",
        "    low = lowcut / nyquist\n",
        "    high = highcut / nyquist\n",
        "    b, a = signal.butter(order, [low, high], btype='band')\n",
        "    return signal.filtfilt(b, a, data)"
      ],
      "metadata": {
        "id": "nTKfMhWDQ3oA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load and preprocess EEG data\n",
        "def preprocess_eeg(folder_path):\n",
        "    file_paths = sorted(glob.glob(os.path.join(folder_path, \"*.txt\")) + glob.glob(os.path.join(folder_path, \"*.TXT\")))\n",
        "    processed_data = []\n",
        "\n",
        "    for file_path in file_paths:\n",
        "        data = np.loadtxt(file_path)  # Load EEG signal\n",
        "        data = butter_bandpass_filter(data, low_cutoff, high_cutoff, sampling_rate, order)  # Apply filtering\n",
        "        data = (data - np.mean(data)) / np.std(data)  # Normalize to zero mean, unit variance\n",
        "        processed_data.append(data)\n",
        "\n",
        "    return np.array(processed_data)"
      ],
      "metadata": {
        "id": "FC50EiOjQ7ds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Google Drive base path where EEG folders (A-E) are stored\n",
        "data_base_folder = \"/content/drive/MyDrive/EEG Dataset\"\n",
        "data_folders = ['F', 'N', 'O', 'S', 'Z']  # List of folders\n",
        "\n",
        "# Create the 'Processed' directory if it doesn't exist\n",
        "processed_dir = os.path.join(data_base_folder, \"Processed\")\n",
        "os.makedirs(processed_dir, exist_ok=True) # This will create 'Processed' if it's not there\n",
        "\n",
        "# Process each folder and save separately\n",
        "for folder in data_folders:\n",
        "    folder_path = os.path.join(data_base_folder, folder)\n",
        "    processed_eeg = preprocess_eeg(folder_path)\n",
        "\n",
        "    # Save processed data\n",
        "    save_path = os.path.join(processed_dir, f\"processed_{folder}.mat\") # Changed to use os.path.join\n",
        "    savemat(save_path, {\"eeg_data\": processed_eeg})\n",
        "\n",
        "    print(f\"Processed and saved {folder} dataset at {save_path}\")\n",
        "\n",
        "# Plot an example signal from one dataset (e.g., A)\n",
        "plt.figure(figsize=(10, 4))\n",
        "plt.plot(processed_eeg[0], label=\"Filtered & Normalized EEG\")\n",
        "plt.xlabel(\"Time (samples)\")\n",
        "plt.ylabel(\"Amplitude (normalized)\")\n",
        "plt.title(\"Preprocessed EEG Signal from Dataset S\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "c49ALjN6Q-Dp",
        "outputId": "749e480d-c42f-49ac-b72a-5aab45308185"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processed and saved F dataset at /content/drive/MyDrive/EEG Dataset/Processed/processed_F.mat\n",
            "Processed and saved N dataset at /content/drive/MyDrive/EEG Dataset/Processed/processed_N.mat\n",
            "Processed and saved O dataset at /content/drive/MyDrive/EEG Dataset/Processed/processed_O.mat\n",
            "Processed and saved S dataset at /content/drive/MyDrive/EEG Dataset/Processed/processed_S.mat\n",
            "Processed and saved Z dataset at /content/drive/MyDrive/EEG Dataset/Processed/processed_Z.mat\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x400 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "processed_eeg_N = preprocess_eeg(\"/content/drive/MyDrive/EEG Dataset/N\")\n",
        "savemat(\"/content/drive/MyDrive/EEG Dataset/Processed/processed_N.mat\", {\"eeg_data\": processed_eeg_N})\n"
      ],
      "metadata": {
        "id": "rqIfSITfpyFP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv1D, MaxPooling1D, LSTM, Dense, Dropout, BatchNormalization\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from scipy.io import loadmat\n",
        "import os\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "from sklearn.metrics import classification_report"
      ],
      "metadata": {
        "id": "sAxouBTKUZ4r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load preprocessed EEG data from Google Drive\n",
        "data_base_folder = \"/content/drive/MyDrive/EEG Dataset/Processed\"\n",
        "data_folders = ['F', 'N', 'O', 'S', 'Z']\n",
        "\n",
        "# Map EEG classes to three categories\n",
        "label_map = {\"F\": 0, \"N\": 0, \"O\": 1, \"Z\": 1, \"S\": 2}  # Three-class classification\n",
        "\n",
        "def load_data():\n",
        "    X, y = [], []\n",
        "\n",
        "    for folder in data_folders:\n",
        "        file_path = os.path.join(data_base_folder, f\"processed_{folder}.mat\")\n",
        "\n",
        "        if not os.path.exists(file_path):\n",
        "            print(f\"Warning: {file_path} not found. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        mat_data = loadmat(file_path)\n",
        "        if 'eeg_data' not in mat_data:\n",
        "            print(f\"Warning: 'eeg_data' key missing in {file_path}. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        eeg_signals = mat_data['eeg_data']\n",
        "        if eeg_signals.size == 0:\n",
        "            print(f\"Warning: {file_path} contains no data. Skipping...\")\n",
        "            continue\n",
        "\n",
        "        X.append(eeg_signals)\n",
        "        y.append(np.full((eeg_signals.shape[0],), label_map[folder]))\n",
        "\n",
        "    if not X:\n",
        "        raise ValueError(\"No valid EEG data found. Please check the dataset.\")\n",
        "\n",
        "    X = np.vstack(X)\n",
        "    y = np.concatenate(y)\n",
        "\n",
        "    return X, y"
      ],
      "metadata": {
        "id": "6yYfnz_JUcLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load dataset\n",
        "X, y = load_data()\n",
        "\n",
        "# Normalize dataset (zero mean, unit variance as per paper)\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "X = X.reshape((X.shape[0], X.shape[1], 1))  # Reshape for LSTM\n",
        "\n",
        "# Compute class weights to handle imbalance\n",
        "class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
        "class_weight_dict = {i: class_weights[i] for i in range(len(class_weights))}\n",
        "\n",
        "# Define CNN-LSTM model based on research paper\n",
        "def create_cnn_lstm_model(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        Conv1D(filters=256, kernel_size=3, activation='relu'),  # Additional conv layer\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        LSTM(64, return_sequences=True),  # First LSTM layer\n",
        "        LSTM(32, return_sequences=False),  # Second LSTM layer\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001),\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 397
        },
        "id": "G1Ua-P57UixF",
        "outputId": "234ace62-c1a9-46ab-9682-70e85491e48f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_16\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_16\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_32 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4095\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_32 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2047\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_33 (\u001b[38;5;33mConv1D\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2045\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m24,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_33 (\u001b[38;5;33mMaxPooling1D\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1022\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_16 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │          \u001b[38;5;34m49,408\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m4,160\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m195\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4095</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2047</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2045</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1022</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">49,408</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_16 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_32 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_33 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m236,171\u001b[0m (922.55 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">236,171</span> (922.55 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m78,723\u001b[0m (307.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">78,723</span> (307.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m157,448\u001b[0m (615.04 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">157,448</span> (615.04 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "all_y_true, all_y_pred = [], []\n",
        "\n",
        "fold = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f\"\\nTraining Fold {fold}/10...\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_cnn_lstm_model(input_shape=X_train.shape[1:], num_classes=3)\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=50,  # Now fixed to 50 per fold\n",
        "        batch_size=16,  # Smaller batch size per research paper\n",
        "        class_weight=class_weight_dict  # Balance class weights\n",
        "    )\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_test).astype(np.float32), axis=1)\n",
        "    accuracies.append(model.evaluate(X_test, y_test, verbose=0)[1])\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "    print(f\"Fold {fold} Accuracy: {accuracies[-1]:.4f}\")\n",
        "    fold += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gNmFnvw-ty_8",
        "outputId": "b0f627d9-60fd-465d-b3c2-6b6cb564af3b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 1/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.5786 - loss: 0.9925 - val_accuracy: 0.4400 - val_loss: 1.0930\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7205 - loss: 0.8156 - val_accuracy: 0.4400 - val_loss: 1.3126\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7748 - loss: 0.7033 - val_accuracy: 0.4400 - val_loss: 1.5762\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8111 - loss: 0.5339 - val_accuracy: 0.4400 - val_loss: 1.6989\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8265 - loss: 0.5121 - val_accuracy: 0.4400 - val_loss: 2.0545\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8810 - loss: 0.4558 - val_accuracy: 0.4400 - val_loss: 2.1992\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9397 - loss: 0.2963 - val_accuracy: 0.4600 - val_loss: 2.1027\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.8373 - loss: 0.4324 - val_accuracy: 0.4400 - val_loss: 2.6070\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9744 - loss: 0.1649 - val_accuracy: 0.4400 - val_loss: 2.6702\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8829 - loss: 0.3433 - val_accuracy: 0.4800 - val_loss: 2.0411\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9228 - loss: 0.3142 - val_accuracy: 0.5200 - val_loss: 2.0311\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9182 - loss: 0.2176 - val_accuracy: 0.5600 - val_loss: 1.7863\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9336 - loss: 0.2089 - val_accuracy: 0.6400 - val_loss: 1.3503\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8786 - loss: 0.3495 - val_accuracy: 0.6200 - val_loss: 1.3146\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9242 - loss: 0.2696 - val_accuracy: 0.6000 - val_loss: 1.4044\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9560 - loss: 0.1491 - val_accuracy: 0.7400 - val_loss: 0.9874\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9030 - loss: 0.2674 - val_accuracy: 0.7400 - val_loss: 1.0012\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9624 - loss: 0.1751 - val_accuracy: 0.8600 - val_loss: 0.4384\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9071 - loss: 0.2334 - val_accuracy: 0.9000 - val_loss: 0.2967\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9434 - loss: 0.1499 - val_accuracy: 0.9600 - val_loss: 0.1694\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9858 - loss: 0.0808 - val_accuracy: 0.9000 - val_loss: 0.2434\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9627 - loss: 0.1241 - val_accuracy: 0.9600 - val_loss: 0.1321\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9819 - loss: 0.0915 - val_accuracy: 0.9000 - val_loss: 0.3049\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9522 - loss: 0.1444 - val_accuracy: 0.8800 - val_loss: 0.3735\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9852 - loss: 0.0579 - val_accuracy: 0.9200 - val_loss: 0.2177\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9867 - loss: 0.0582 - val_accuracy: 0.9400 - val_loss: 0.1601\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9940 - loss: 0.0353 - val_accuracy: 0.9600 - val_loss: 0.1153\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9938 - loss: 0.0261 - val_accuracy: 0.9800 - val_loss: 0.1080\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9822 - loss: 0.0367 - val_accuracy: 0.9800 - val_loss: 0.0821\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9970 - loss: 0.0231 - val_accuracy: 0.9400 - val_loss: 0.1521\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9539 - loss: 0.1737 - val_accuracy: 0.9200 - val_loss: 0.3941\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9415 - loss: 0.1897 - val_accuracy: 0.9000 - val_loss: 0.4145\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9359 - loss: 0.2128 - val_accuracy: 0.8000 - val_loss: 0.8193\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9575 - loss: 0.1387 - val_accuracy: 0.9000 - val_loss: 0.3526\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.9776 - loss: 0.0773 - val_accuracy: 0.8800 - val_loss: 0.3236\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9847 - loss: 0.0616 - val_accuracy: 0.9400 - val_loss: 0.1005\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9908 - loss: 0.0586 - val_accuracy: 0.9200 - val_loss: 0.2117\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9852 - loss: 0.0497 - val_accuracy: 0.9200 - val_loss: 0.2914\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9062 - loss: 0.3220 - val_accuracy: 0.9200 - val_loss: 0.1661\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9649 - loss: 0.1178 - val_accuracy: 0.8600 - val_loss: 0.3752\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 44ms/step - accuracy: 0.9645 - loss: 0.1041 - val_accuracy: 0.9000 - val_loss: 0.3626\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9821 - loss: 0.0512 - val_accuracy: 0.9400 - val_loss: 0.1896\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9265 - loss: 0.1634 - val_accuracy: 0.9000 - val_loss: 0.4148\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9751 - loss: 0.1373 - val_accuracy: 0.9400 - val_loss: 0.3091\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9454 - loss: 0.1583 - val_accuracy: 0.8000 - val_loss: 0.8735\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9093 - loss: 0.3548 - val_accuracy: 0.9000 - val_loss: 0.2684\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9827 - loss: 0.0819 - val_accuracy: 0.9000 - val_loss: 0.2804\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9878 - loss: 0.0688 - val_accuracy: 0.9600 - val_loss: 0.0499\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9881 - loss: 0.0618 - val_accuracy: 0.9600 - val_loss: 0.0679\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9885 - loss: 0.0480 - val_accuracy: 0.9400 - val_loss: 0.1912\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 337ms/step\n",
            "Fold 1 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 2/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 67ms/step - accuracy: 0.5517 - loss: 0.9921 - val_accuracy: 0.2400 - val_loss: 1.1841\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.6777 - loss: 0.6810 - val_accuracy: 0.4000 - val_loss: 1.3592\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.8190 - loss: 0.5476 - val_accuracy: 0.4000 - val_loss: 1.4888\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8496 - loss: 0.4748 - val_accuracy: 0.4000 - val_loss: 1.7317\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7706 - loss: 0.6190 - val_accuracy: 0.4000 - val_loss: 1.9533\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8827 - loss: 0.3900 - val_accuracy: 0.4000 - val_loss: 2.2612\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9405 - loss: 0.2293 - val_accuracy: 0.4000 - val_loss: 2.3247\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9388 - loss: 0.2483 - val_accuracy: 0.4000 - val_loss: 2.8481\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9366 - loss: 0.2280 - val_accuracy: 0.4000 - val_loss: 2.7418\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8022 - loss: 0.5332 - val_accuracy: 0.4200 - val_loss: 2.3557\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8525 - loss: 0.3599 - val_accuracy: 0.4800 - val_loss: 2.2665\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9518 - loss: 0.1526 - val_accuracy: 0.4800 - val_loss: 2.5489\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9485 - loss: 0.1813 - val_accuracy: 0.5000 - val_loss: 2.4070\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9212 - loss: 0.3201 - val_accuracy: 0.5800 - val_loss: 1.6206\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8652 - loss: 0.3299 - val_accuracy: 0.6000 - val_loss: 1.5622\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9166 - loss: 0.2212 - val_accuracy: 0.7600 - val_loss: 0.9180\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9297 - loss: 0.2301 - val_accuracy: 0.7600 - val_loss: 0.9401\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9384 - loss: 0.1707 - val_accuracy: 0.8200 - val_loss: 0.6594\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9655 - loss: 0.1244 - val_accuracy: 0.7400 - val_loss: 0.8876\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9514 - loss: 0.1446 - val_accuracy: 0.8800 - val_loss: 0.2872\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9699 - loss: 0.1141 - val_accuracy: 0.9600 - val_loss: 0.1454\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9430 - loss: 0.1660 - val_accuracy: 0.9200 - val_loss: 0.2988\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9406 - loss: 0.2185 - val_accuracy: 0.9400 - val_loss: 0.2033\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9411 - loss: 0.1884 - val_accuracy: 0.8400 - val_loss: 0.5841\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9542 - loss: 0.1260 - val_accuracy: 0.9600 - val_loss: 0.1118\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9879 - loss: 0.0464 - val_accuracy: 0.8400 - val_loss: 0.3533\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8799 - loss: 0.3254 - val_accuracy: 0.9200 - val_loss: 0.2813\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9551 - loss: 0.1803 - val_accuracy: 0.9400 - val_loss: 0.1339\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9601 - loss: 0.1169 - val_accuracy: 0.9400 - val_loss: 0.1250\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9866 - loss: 0.0448 - val_accuracy: 0.9400 - val_loss: 0.1365\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9609 - loss: 0.1024 - val_accuracy: 0.9200 - val_loss: 0.1336\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9682 - loss: 0.0747 - val_accuracy: 0.9600 - val_loss: 0.1750\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9687 - loss: 0.1233 - val_accuracy: 0.9400 - val_loss: 0.1334\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9908 - loss: 0.0494 - val_accuracy: 0.9600 - val_loss: 0.1148\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9942 - loss: 0.0234 - val_accuracy: 0.9600 - val_loss: 0.1013\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9948 - loss: 0.0188 - val_accuracy: 0.9400 - val_loss: 0.1334\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9998 - loss: 0.0157 - val_accuracy: 0.9600 - val_loss: 0.0567\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9926 - loss: 0.0260 - val_accuracy: 0.8800 - val_loss: 0.4108\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9941 - loss: 0.0252 - val_accuracy: 0.9600 - val_loss: 0.1717\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9921 - loss: 0.0321 - val_accuracy: 0.9600 - val_loss: 0.2220\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9738 - loss: 0.0602 - val_accuracy: 0.9800 - val_loss: 0.1267\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9767 - loss: 0.0669 - val_accuracy: 1.0000 - val_loss: 0.0284\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9875 - loss: 0.0326 - val_accuracy: 0.8800 - val_loss: 0.4600\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8345 - loss: 0.5414 - val_accuracy: 0.9000 - val_loss: 0.3811\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9247 - loss: 0.2238 - val_accuracy: 0.9600 - val_loss: 0.1685\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9637 - loss: 0.1303 - val_accuracy: 0.9800 - val_loss: 0.1163\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9378 - loss: 0.1588 - val_accuracy: 0.9200 - val_loss: 0.3113\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9705 - loss: 0.1059 - val_accuracy: 0.9400 - val_loss: 0.2041\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9794 - loss: 0.0527 - val_accuracy: 0.9200 - val_loss: 0.1919\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9768 - loss: 0.0600 - val_accuracy: 0.9400 - val_loss: 0.2573\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step\n",
            "Fold 2 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 3/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 69ms/step - accuracy: 0.5077 - loss: 0.9896 - val_accuracy: 0.4000 - val_loss: 1.1691\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7243 - loss: 0.8014 - val_accuracy: 0.4000 - val_loss: 1.6323\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8247 - loss: 0.6100 - val_accuracy: 0.4000 - val_loss: 1.7784\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7993 - loss: 0.6203 - val_accuracy: 0.4000 - val_loss: 1.9366\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8245 - loss: 0.4751 - val_accuracy: 0.4000 - val_loss: 2.4043\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8758 - loss: 0.4974 - val_accuracy: 0.4000 - val_loss: 2.3225\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8855 - loss: 0.3833 - val_accuracy: 0.4000 - val_loss: 2.2275\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.8502 - loss: 0.4056 - val_accuracy: 0.4000 - val_loss: 2.5610\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8957 - loss: 0.3757 - val_accuracy: 0.4000 - val_loss: 2.4674\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8979 - loss: 0.2801 - val_accuracy: 0.4000 - val_loss: 2.8922\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9089 - loss: 0.2775 - val_accuracy: 0.4000 - val_loss: 2.7042\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9501 - loss: 0.2012 - val_accuracy: 0.5000 - val_loss: 1.8170\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8745 - loss: 0.4464 - val_accuracy: 0.5200 - val_loss: 1.8548\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8851 - loss: 0.3665 - val_accuracy: 0.6000 - val_loss: 1.4444\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9330 - loss: 0.2066 - val_accuracy: 0.5600 - val_loss: 1.6641\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9474 - loss: 0.2056 - val_accuracy: 0.8800 - val_loss: 0.4882\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9067 - loss: 0.3098 - val_accuracy: 0.8600 - val_loss: 0.3796\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9667 - loss: 0.1435 - val_accuracy: 0.8400 - val_loss: 0.4288\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9630 - loss: 0.1570 - val_accuracy: 0.8800 - val_loss: 0.3710\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8712 - loss: 0.5080 - val_accuracy: 0.9000 - val_loss: 0.2464\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9243 - loss: 0.2624 - val_accuracy: 0.8600 - val_loss: 0.4235\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9724 - loss: 0.1314 - val_accuracy: 0.9200 - val_loss: 0.2614\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9727 - loss: 0.0984 - val_accuracy: 0.8800 - val_loss: 0.3458\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9215 - loss: 0.2919 - val_accuracy: 0.9800 - val_loss: 0.1060\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9525 - loss: 0.1872 - val_accuracy: 0.8600 - val_loss: 0.2737\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.8857 - loss: 0.4390 - val_accuracy: 0.9000 - val_loss: 0.2958\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8810 - loss: 0.3062 - val_accuracy: 0.9800 - val_loss: 0.1259\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9655 - loss: 0.1290 - val_accuracy: 0.9800 - val_loss: 0.0800\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9660 - loss: 0.1069 - val_accuracy: 0.9800 - val_loss: 0.0738\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9972 - loss: 0.0359 - val_accuracy: 0.9800 - val_loss: 0.0601\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9796 - loss: 0.0637 - val_accuracy: 0.9800 - val_loss: 0.0693\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9806 - loss: 0.0569 - val_accuracy: 0.9800 - val_loss: 0.0713\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9830 - loss: 0.0640 - val_accuracy: 0.9600 - val_loss: 0.1141\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9691 - loss: 0.0862 - val_accuracy: 0.8800 - val_loss: 0.5299\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9401 - loss: 0.2072 - val_accuracy: 0.9000 - val_loss: 0.2087\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.8629 - loss: 0.4584 - val_accuracy: 0.9800 - val_loss: 0.1166\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9078 - loss: 0.3717 - val_accuracy: 0.9200 - val_loss: 0.2115\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9447 - loss: 0.1852 - val_accuracy: 0.9600 - val_loss: 0.0823\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9619 - loss: 0.1110 - val_accuracy: 0.9800 - val_loss: 0.0891\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9659 - loss: 0.1446 - val_accuracy: 0.9600 - val_loss: 0.0692\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9827 - loss: 0.1139 - val_accuracy: 0.9800 - val_loss: 0.0312\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9804 - loss: 0.0807 - val_accuracy: 0.9600 - val_loss: 0.1195\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9476 - loss: 0.1773 - val_accuracy: 1.0000 - val_loss: 0.0140\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9897 - loss: 0.0585 - val_accuracy: 0.9800 - val_loss: 0.0561\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9815 - loss: 0.0654 - val_accuracy: 1.0000 - val_loss: 0.0060\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9795 - loss: 0.1021 - val_accuracy: 0.9800 - val_loss: 0.0535\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9823 - loss: 0.0395 - val_accuracy: 0.9800 - val_loss: 0.0306\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9649 - loss: 0.0982 - val_accuracy: 0.9600 - val_loss: 0.0457\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9790 - loss: 0.0619 - val_accuracy: 1.0000 - val_loss: 0.0134\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9852 - loss: 0.0720 - val_accuracy: 1.0000 - val_loss: 0.0138\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n",
            "Fold 3 Accuracy: 1.0000\n",
            "\n",
            "Training Fold 4/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 66ms/step - accuracy: 0.6337 - loss: 0.9472 - val_accuracy: 0.5200 - val_loss: 1.0363\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7482 - loss: 0.7496 - val_accuracy: 0.5200 - val_loss: 1.3697\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7851 - loss: 0.6279 - val_accuracy: 0.5200 - val_loss: 1.5455\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8330 - loss: 0.4632 - val_accuracy: 0.5200 - val_loss: 1.7757\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.8719 - loss: 0.4167 - val_accuracy: 0.5200 - val_loss: 1.9192\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.8888 - loss: 0.3898 - val_accuracy: 0.5200 - val_loss: 2.3144\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8845 - loss: 0.5348 - val_accuracy: 0.5200 - val_loss: 1.7871\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9194 - loss: 0.2417 - val_accuracy: 0.5200 - val_loss: 2.1992\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9482 - loss: 0.2094 - val_accuracy: 0.5200 - val_loss: 2.2114\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9338 - loss: 0.2435 - val_accuracy: 0.5600 - val_loss: 2.0524\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9370 - loss: 0.2219 - val_accuracy: 0.2400 - val_loss: 2.0565\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8478 - loss: 0.5183 - val_accuracy: 0.5000 - val_loss: 1.0751\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8160 - loss: 0.5508 - val_accuracy: 0.6200 - val_loss: 1.2750\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8590 - loss: 0.4718 - val_accuracy: 0.7000 - val_loss: 1.0031\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8731 - loss: 0.4003 - val_accuracy: 0.7400 - val_loss: 0.9512\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9379 - loss: 0.2630 - val_accuracy: 0.8200 - val_loss: 0.7483\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8729 - loss: 0.4238 - val_accuracy: 0.7800 - val_loss: 0.8245\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9036 - loss: 0.3538 - val_accuracy: 0.8600 - val_loss: 0.4898\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 47ms/step - accuracy: 0.9460 - loss: 0.1937 - val_accuracy: 0.9200 - val_loss: 0.2631\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9378 - loss: 0.2323 - val_accuracy: 0.9400 - val_loss: 0.1857\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9335 - loss: 0.2387 - val_accuracy: 0.9000 - val_loss: 0.2422\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9082 - loss: 0.2438 - val_accuracy: 0.9800 - val_loss: 0.1449\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9641 - loss: 0.1315 - val_accuracy: 0.9400 - val_loss: 0.1381\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9879 - loss: 0.0678 - val_accuracy: 0.9200 - val_loss: 0.1999\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9861 - loss: 0.0701 - val_accuracy: 0.9600 - val_loss: 0.1496\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9832 - loss: 0.0903 - val_accuracy: 0.9600 - val_loss: 0.2043\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9726 - loss: 0.1299 - val_accuracy: 0.9000 - val_loss: 0.3350\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9656 - loss: 0.1509 - val_accuracy: 0.9600 - val_loss: 0.1265\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9286 - loss: 0.2002 - val_accuracy: 0.9800 - val_loss: 0.0734\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9887 - loss: 0.0589 - val_accuracy: 0.9200 - val_loss: 0.3993\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9294 - loss: 0.2707 - val_accuracy: 0.9400 - val_loss: 0.1621\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.8583 - loss: 0.4909 - val_accuracy: 0.9400 - val_loss: 0.2026\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9471 - loss: 0.1525 - val_accuracy: 0.9200 - val_loss: 0.2085\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9414 - loss: 0.1567 - val_accuracy: 0.9600 - val_loss: 0.1834\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9634 - loss: 0.1485 - val_accuracy: 0.9400 - val_loss: 0.2857\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9318 - loss: 0.2214 - val_accuracy: 0.9400 - val_loss: 0.1997\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9569 - loss: 0.1360 - val_accuracy: 0.9000 - val_loss: 0.2561\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9523 - loss: 0.1842 - val_accuracy: 0.9200 - val_loss: 0.2139\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9273 - loss: 0.1727 - val_accuracy: 0.9400 - val_loss: 0.1316\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9715 - loss: 0.1109 - val_accuracy: 0.9600 - val_loss: 0.1002\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9467 - loss: 0.1434 - val_accuracy: 0.9600 - val_loss: 0.0773\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9853 - loss: 0.0701 - val_accuracy: 0.9400 - val_loss: 0.1325\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9764 - loss: 0.0976 - val_accuracy: 0.9600 - val_loss: 0.1319\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9917 - loss: 0.0396 - val_accuracy: 0.9600 - val_loss: 0.1053\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9978 - loss: 0.0297 - val_accuracy: 0.9000 - val_loss: 0.3305\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9100 - loss: 0.4542 - val_accuracy: 0.9400 - val_loss: 0.1360\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9492 - loss: 0.2087 - val_accuracy: 0.9600 - val_loss: 0.1746\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9753 - loss: 0.1162 - val_accuracy: 0.9800 - val_loss: 0.0783\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9561 - loss: 0.1267 - val_accuracy: 0.9600 - val_loss: 0.1615\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9866 - loss: 0.0652 - val_accuracy: 0.9800 - val_loss: 0.0677\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 309ms/step\n",
            "Fold 4 Accuracy: 0.9800\n",
            "\n",
            "Training Fold 5/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5145 - loss: 0.9473 - val_accuracy: 0.4800 - val_loss: 1.0675\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.6936 - loss: 0.7033 - val_accuracy: 0.4400 - val_loss: 1.1102\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.7771 - loss: 0.6652 - val_accuracy: 0.4400 - val_loss: 1.3520\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8019 - loss: 0.5710 - val_accuracy: 0.4400 - val_loss: 1.5120\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8870 - loss: 0.3993 - val_accuracy: 0.4400 - val_loss: 1.7531\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8998 - loss: 0.3522 - val_accuracy: 0.4400 - val_loss: 1.6384\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8347 - loss: 0.4921 - val_accuracy: 0.4400 - val_loss: 1.8645\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9002 - loss: 0.3267 - val_accuracy: 0.4400 - val_loss: 1.9880\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9074 - loss: 0.3143 - val_accuracy: 0.4400 - val_loss: 2.0171\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9349 - loss: 0.2766 - val_accuracy: 0.4400 - val_loss: 1.9293\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8460 - loss: 0.4339 - val_accuracy: 0.4800 - val_loss: 1.7500\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8894 - loss: 0.3335 - val_accuracy: 0.4800 - val_loss: 1.8120\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9320 - loss: 0.2146 - val_accuracy: 0.5400 - val_loss: 1.8909\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9599 - loss: 0.1234 - val_accuracy: 0.7400 - val_loss: 0.7739\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8694 - loss: 0.3464 - val_accuracy: 0.7400 - val_loss: 0.6575\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9297 - loss: 0.2164 - val_accuracy: 0.9000 - val_loss: 0.3425\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8269 - loss: 0.3997 - val_accuracy: 0.8800 - val_loss: 0.4254\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8983 - loss: 0.2428 - val_accuracy: 0.9400 - val_loss: 0.1922\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8785 - loss: 0.5694 - val_accuracy: 0.8400 - val_loss: 0.4491\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9011 - loss: 0.3231 - val_accuracy: 0.8800 - val_loss: 0.2342\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9437 - loss: 0.2192 - val_accuracy: 0.9000 - val_loss: 0.1808\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9633 - loss: 0.1289 - val_accuracy: 0.9400 - val_loss: 0.1053\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9447 - loss: 0.1419 - val_accuracy: 0.9400 - val_loss: 0.1340\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9814 - loss: 0.0883 - val_accuracy: 0.9200 - val_loss: 0.1245\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9823 - loss: 0.0663 - val_accuracy: 0.9200 - val_loss: 0.1586\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9786 - loss: 0.0634 - val_accuracy: 0.8800 - val_loss: 0.5223\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9481 - loss: 0.1547 - val_accuracy: 0.9400 - val_loss: 0.2014\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9912 - loss: 0.0448 - val_accuracy: 0.8800 - val_loss: 0.3323\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9832 - loss: 0.0422 - val_accuracy: 0.9400 - val_loss: 0.1518\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9950 - loss: 0.0275 - val_accuracy: 0.9800 - val_loss: 0.1123\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9692 - loss: 0.1024 - val_accuracy: 0.9200 - val_loss: 0.3077\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9926 - loss: 0.0290 - val_accuracy: 0.9600 - val_loss: 0.1149\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9557 - loss: 0.1222 - val_accuracy: 0.8800 - val_loss: 0.3524\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9158 - loss: 0.2125 - val_accuracy: 0.9600 - val_loss: 0.2188\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9939 - loss: 0.0543 - val_accuracy: 0.9400 - val_loss: 0.3332\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9901 - loss: 0.0292 - val_accuracy: 0.9600 - val_loss: 0.2087\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9904 - loss: 0.0503 - val_accuracy: 0.9800 - val_loss: 0.1789\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9826 - loss: 0.0636 - val_accuracy: 0.9200 - val_loss: 0.4412\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9209 - loss: 0.2209 - val_accuracy: 0.8600 - val_loss: 0.3782\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9359 - loss: 0.2908 - val_accuracy: 0.8600 - val_loss: 0.4871\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9888 - loss: 0.0634 - val_accuracy: 0.8800 - val_loss: 0.5544\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9709 - loss: 0.0796 - val_accuracy: 0.8600 - val_loss: 0.5352\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9811 - loss: 0.0630 - val_accuracy: 0.8600 - val_loss: 0.7061\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9493 - loss: 0.1441 - val_accuracy: 0.9000 - val_loss: 0.2175\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9901 - loss: 0.0309 - val_accuracy: 0.9600 - val_loss: 0.1554\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9993 - loss: 0.0156 - val_accuracy: 0.9400 - val_loss: 0.2312\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9995 - loss: 0.0079 - val_accuracy: 0.9600 - val_loss: 0.1200\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9974 - loss: 0.0408 - val_accuracy: 0.9200 - val_loss: 0.3611\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9296 - loss: 0.4076 - val_accuracy: 0.9400 - val_loss: 0.2272\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9520 - loss: 0.1755 - val_accuracy: 0.9200 - val_loss: 0.2226\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 298ms/step\n",
            "Fold 5 Accuracy: 0.9200\n",
            "\n",
            "Training Fold 6/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 68ms/step - accuracy: 0.6116 - loss: 0.9460 - val_accuracy: 0.2600 - val_loss: 1.2618\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7460 - loss: 0.7402 - val_accuracy: 0.2600 - val_loss: 1.6928\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7702 - loss: 0.6593 - val_accuracy: 0.2600 - val_loss: 2.2728\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.7981 - loss: 0.5536 - val_accuracy: 0.2600 - val_loss: 2.4924\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9155 - loss: 0.3093 - val_accuracy: 0.2600 - val_loss: 2.6505\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9319 - loss: 0.2765 - val_accuracy: 0.2600 - val_loss: 2.6061\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.8910 - loss: 0.3762 - val_accuracy: 0.2800 - val_loss: 2.9655\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.7967 - loss: 0.5400 - val_accuracy: 0.2600 - val_loss: 2.5564\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8791 - loss: 0.3699 - val_accuracy: 0.2800 - val_loss: 3.0507\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9327 - loss: 0.2815 - val_accuracy: 0.3000 - val_loss: 3.0669\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9401 - loss: 0.2387 - val_accuracy: 0.2600 - val_loss: 3.1586\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.8779 - loss: 0.4067 - val_accuracy: 0.3200 - val_loss: 2.3557\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9362 - loss: 0.2021 - val_accuracy: 0.3400 - val_loss: 2.3904\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9559 - loss: 0.1512 - val_accuracy: 0.4800 - val_loss: 1.8532\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9701 - loss: 0.1158 - val_accuracy: 0.4200 - val_loss: 2.2682\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9612 - loss: 0.1630 - val_accuracy: 0.6000 - val_loss: 1.3705\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9770 - loss: 0.0946 - val_accuracy: 0.7000 - val_loss: 1.1385\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9625 - loss: 0.1739 - val_accuracy: 0.8200 - val_loss: 0.6044\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9596 - loss: 0.1415 - val_accuracy: 0.8000 - val_loss: 0.7109\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9590 - loss: 0.1576 - val_accuracy: 0.8800 - val_loss: 0.4370\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9675 - loss: 0.1155 - val_accuracy: 0.8800 - val_loss: 0.3670\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9849 - loss: 0.0483 - val_accuracy: 0.8600 - val_loss: 0.4671\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9779 - loss: 0.0489 - val_accuracy: 0.8600 - val_loss: 0.5220\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9893 - loss: 0.0463 - val_accuracy: 0.8400 - val_loss: 0.5941\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9646 - loss: 0.0779 - val_accuracy: 0.8800 - val_loss: 0.4840\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9837 - loss: 0.0589 - val_accuracy: 0.8800 - val_loss: 0.5625\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9800 - loss: 0.0790 - val_accuracy: 0.8400 - val_loss: 0.6097\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9260 - loss: 0.2704 - val_accuracy: 0.9000 - val_loss: 0.2705\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9670 - loss: 0.1121 - val_accuracy: 0.9400 - val_loss: 0.2380\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9950 - loss: 0.0325 - val_accuracy: 0.9200 - val_loss: 0.2807\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9865 - loss: 0.0340 - val_accuracy: 0.9400 - val_loss: 0.2677\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9400 - val_loss: 0.2950\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 1.0000 - loss: 0.0061 - val_accuracy: 0.9600 - val_loss: 0.2899\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9997 - loss: 0.0066 - val_accuracy: 0.9200 - val_loss: 0.3663\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9962 - loss: 0.0340 - val_accuracy: 0.9400 - val_loss: 0.4233\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9802 - loss: 0.0828 - val_accuracy: 0.7800 - val_loss: 0.9461\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9108 - loss: 0.3692 - val_accuracy: 0.9000 - val_loss: 0.3902\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9488 - loss: 0.1691 - val_accuracy: 0.9000 - val_loss: 0.5205\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9733 - loss: 0.0706 - val_accuracy: 0.8800 - val_loss: 0.3088\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9857 - loss: 0.0369 - val_accuracy: 0.8800 - val_loss: 0.3151\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.9981 - loss: 0.0147 - val_accuracy: 0.9000 - val_loss: 0.3201\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9277 - loss: 0.1569 - val_accuracy: 0.9600 - val_loss: 0.1847\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9272 - loss: 0.3699 - val_accuracy: 0.8800 - val_loss: 0.3883\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9381 - loss: 0.1651 - val_accuracy: 0.8800 - val_loss: 0.2945\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9673 - loss: 0.1132 - val_accuracy: 0.9200 - val_loss: 0.3466\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9867 - loss: 0.0518 - val_accuracy: 0.9200 - val_loss: 0.2385\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9992 - loss: 0.0142 - val_accuracy: 0.9400 - val_loss: 0.2392\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9980 - loss: 0.0134 - val_accuracy: 0.8600 - val_loss: 0.4494\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9932 - loss: 0.0394 - val_accuracy: 0.8800 - val_loss: 0.4835\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8736 - loss: 0.3389 - val_accuracy: 0.9400 - val_loss: 0.2181\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 304ms/step\n",
            "Fold 6 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 7/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 79ms/step - accuracy: 0.5101 - loss: 1.0059 - val_accuracy: 0.4400 - val_loss: 1.1485\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8082 - loss: 0.6407 - val_accuracy: 0.4400 - val_loss: 1.4636\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8617 - loss: 0.5314 - val_accuracy: 0.4400 - val_loss: 1.9068\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8106 - loss: 0.4912 - val_accuracy: 0.4400 - val_loss: 2.2475\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8903 - loss: 0.3814 - val_accuracy: 0.4400 - val_loss: 2.6709\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8804 - loss: 0.3723 - val_accuracy: 0.4400 - val_loss: 2.4915\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8753 - loss: 0.4245 - val_accuracy: 0.4400 - val_loss: 2.5699\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8725 - loss: 0.3643 - val_accuracy: 0.4400 - val_loss: 2.3227\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 51ms/step - accuracy: 0.8828 - loss: 0.4083 - val_accuracy: 0.4400 - val_loss: 2.4685\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8349 - loss: 0.3973 - val_accuracy: 0.4600 - val_loss: 2.2496\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8108 - loss: 0.4581 - val_accuracy: 0.4400 - val_loss: 2.9195\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9274 - loss: 0.2614 - val_accuracy: 0.4600 - val_loss: 2.5464\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8422 - loss: 0.4243 - val_accuracy: 0.4600 - val_loss: 2.2559\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9235 - loss: 0.2838 - val_accuracy: 0.5000 - val_loss: 2.4146\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9504 - loss: 0.1581 - val_accuracy: 0.6200 - val_loss: 1.6252\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9597 - loss: 0.1554 - val_accuracy: 0.6400 - val_loss: 1.2048\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9263 - loss: 0.2024 - val_accuracy: 0.7400 - val_loss: 0.8441\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8861 - loss: 0.3495 - val_accuracy: 0.8600 - val_loss: 0.5359\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9668 - loss: 0.1699 - val_accuracy: 0.9200 - val_loss: 0.2902\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8434 - loss: 0.3375 - val_accuracy: 0.8800 - val_loss: 0.4044\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9385 - loss: 0.2624 - val_accuracy: 0.9600 - val_loss: 0.1265\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 58ms/step - accuracy: 0.9479 - loss: 0.1681 - val_accuracy: 0.8600 - val_loss: 0.3609\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9721 - loss: 0.1296 - val_accuracy: 0.9200 - val_loss: 0.2164\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9908 - loss: 0.0632 - val_accuracy: 0.9000 - val_loss: 0.2610\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9612 - loss: 0.0931 - val_accuracy: 0.9000 - val_loss: 0.2702\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9769 - loss: 0.0833 - val_accuracy: 0.9400 - val_loss: 0.2106\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9891 - loss: 0.0635 - val_accuracy: 0.9600 - val_loss: 0.1166\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9579 - loss: 0.1293 - val_accuracy: 0.9200 - val_loss: 0.1492\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 56ms/step - accuracy: 0.9446 - loss: 0.1279 - val_accuracy: 0.9000 - val_loss: 0.1900\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9301 - loss: 0.2272 - val_accuracy: 0.9400 - val_loss: 0.2499\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.8542 - loss: 0.3793 - val_accuracy: 0.9200 - val_loss: 0.1867\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8860 - loss: 0.3493 - val_accuracy: 0.9400 - val_loss: 0.1909\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8972 - loss: 0.3483 - val_accuracy: 0.9600 - val_loss: 0.1517\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9138 - loss: 0.2862 - val_accuracy: 0.9800 - val_loss: 0.0973\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9416 - loss: 0.1716 - val_accuracy: 0.9800 - val_loss: 0.0795\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.9812 - loss: 0.0770 - val_accuracy: 0.9600 - val_loss: 0.1415\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9748 - loss: 0.1170 - val_accuracy: 0.9400 - val_loss: 0.1914\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9830 - loss: 0.0728 - val_accuracy: 0.9400 - val_loss: 0.1807\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9856 - loss: 0.0824 - val_accuracy: 0.8400 - val_loss: 0.3873\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9137 - loss: 0.2388 - val_accuracy: 0.9800 - val_loss: 0.0789\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9804 - loss: 0.1211 - val_accuracy: 0.9400 - val_loss: 0.1271\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9913 - loss: 0.0875 - val_accuracy: 0.9400 - val_loss: 0.1143\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9676 - loss: 0.1393 - val_accuracy: 0.9800 - val_loss: 0.1230\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9768 - loss: 0.0815 - val_accuracy: 0.9800 - val_loss: 0.0663\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9888 - loss: 0.0509 - val_accuracy: 0.9800 - val_loss: 0.0326\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9971 - loss: 0.0370 - val_accuracy: 0.9400 - val_loss: 0.1681\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.9407 - loss: 0.2557 - val_accuracy: 0.7600 - val_loss: 0.6106\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.6743 - loss: 1.1983 - val_accuracy: 0.9400 - val_loss: 0.2400\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.8620 - loss: 0.5327 - val_accuracy: 0.7400 - val_loss: 0.5673\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.8755 - loss: 0.3944 - val_accuracy: 0.9400 - val_loss: 0.2333\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 315ms/step\n",
            "Fold 7 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 8/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 88ms/step - accuracy: 0.6293 - loss: 1.0112 - val_accuracy: 0.3600 - val_loss: 1.3365\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 51ms/step - accuracy: 0.7706 - loss: 0.7426 - val_accuracy: 0.3600 - val_loss: 1.9480\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8053 - loss: 0.5905 - val_accuracy: 0.3600 - val_loss: 2.3453\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8263 - loss: 0.5585 - val_accuracy: 0.3600 - val_loss: 2.5960\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8785 - loss: 0.5124 - val_accuracy: 0.3600 - val_loss: 3.1550\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.7639 - loss: 0.6065 - val_accuracy: 0.3600 - val_loss: 2.9211\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8411 - loss: 0.4327 - val_accuracy: 0.3600 - val_loss: 3.0823\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8755 - loss: 0.4340 - val_accuracy: 0.3600 - val_loss: 3.3554\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8930 - loss: 0.3996 - val_accuracy: 0.3600 - val_loss: 3.3125\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9105 - loss: 0.3498 - val_accuracy: 0.3600 - val_loss: 2.8278\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9273 - loss: 0.2757 - val_accuracy: 0.3600 - val_loss: 3.1229\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9558 - loss: 0.1915 - val_accuracy: 0.3600 - val_loss: 3.4562\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9387 - loss: 0.1943 - val_accuracy: 0.4200 - val_loss: 3.4219\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7952 - loss: 0.6523 - val_accuracy: 0.4400 - val_loss: 1.7901\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9138 - loss: 0.3224 - val_accuracy: 0.5000 - val_loss: 2.0817\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9391 - loss: 0.1970 - val_accuracy: 0.6000 - val_loss: 1.7426\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7751 - loss: 0.7146 - val_accuracy: 0.5800 - val_loss: 0.8436\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8213 - loss: 0.4563 - val_accuracy: 0.8800 - val_loss: 0.3258\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9458 - loss: 0.2360 - val_accuracy: 0.8200 - val_loss: 0.4778\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9307 - loss: 0.1687 - val_accuracy: 0.8600 - val_loss: 0.3674\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9671 - loss: 0.1260 - val_accuracy: 0.8400 - val_loss: 0.4013\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9507 - loss: 0.1447 - val_accuracy: 0.8800 - val_loss: 0.3953\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9763 - loss: 0.0842 - val_accuracy: 0.9600 - val_loss: 0.1691\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9842 - loss: 0.0756 - val_accuracy: 0.9200 - val_loss: 0.3875\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9220 - loss: 0.2012 - val_accuracy: 0.9200 - val_loss: 0.2062\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9422 - loss: 0.1486 - val_accuracy: 0.9400 - val_loss: 0.1070\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9623 - loss: 0.1133 - val_accuracy: 0.9800 - val_loss: 0.0933\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9813 - loss: 0.0597 - val_accuracy: 0.9400 - val_loss: 0.1071\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9625 - loss: 0.1368 - val_accuracy: 0.9800 - val_loss: 0.0849\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 61ms/step - accuracy: 0.9814 - loss: 0.0514 - val_accuracy: 0.9800 - val_loss: 0.0619\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.9827 - loss: 0.0527 - val_accuracy: 0.9600 - val_loss: 0.0622\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 45ms/step - accuracy: 0.9961 - loss: 0.0289 - val_accuracy: 0.9600 - val_loss: 0.0578\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9763 - loss: 0.0743 - val_accuracy: 0.9600 - val_loss: 0.0638\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9883 - loss: 0.0417 - val_accuracy: 0.9800 - val_loss: 0.0404\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9829 - loss: 0.0679 - val_accuracy: 0.7400 - val_loss: 0.7537\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.6150 - loss: 1.7151 - val_accuracy: 0.4400 - val_loss: 1.0602\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.8653 - loss: 0.4667 - val_accuracy: 0.7800 - val_loss: 0.5611\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 62ms/step - accuracy: 0.8610 - loss: 0.4298 - val_accuracy: 0.9200 - val_loss: 0.2142\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9196 - loss: 0.3124 - val_accuracy: 0.9400 - val_loss: 0.1369\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9507 - loss: 0.1957 - val_accuracy: 0.9000 - val_loss: 0.2316\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9176 - loss: 0.2095 - val_accuracy: 0.9800 - val_loss: 0.0744\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9771 - loss: 0.1095 - val_accuracy: 0.9800 - val_loss: 0.0680\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9874 - loss: 0.0454 - val_accuracy: 0.9800 - val_loss: 0.0706\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9838 - loss: 0.0642 - val_accuracy: 0.9600 - val_loss: 0.1329\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9911 - loss: 0.0547 - val_accuracy: 0.9800 - val_loss: 0.1044\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9836 - loss: 0.0500 - val_accuracy: 0.9600 - val_loss: 0.1593\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9784 - loss: 0.0645 - val_accuracy: 0.9800 - val_loss: 0.0637\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9874 - loss: 0.0559 - val_accuracy: 0.9600 - val_loss: 0.1269\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9978 - loss: 0.0262 - val_accuracy: 1.0000 - val_loss: 0.0232\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9963 - loss: 0.0215 - val_accuracy: 0.9400 - val_loss: 0.1027\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step\n",
            "Fold 8 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 9/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 100ms/step - accuracy: 0.5757 - loss: 0.9584 - val_accuracy: 0.3000 - val_loss: 1.1377\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 63ms/step - accuracy: 0.7914 - loss: 0.7035 - val_accuracy: 0.3000 - val_loss: 1.3371\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8061 - loss: 0.6068 - val_accuracy: 0.3000 - val_loss: 1.6789\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.8007 - loss: 0.5498 - val_accuracy: 0.3000 - val_loss: 2.2534\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8826 - loss: 0.4899 - val_accuracy: 0.3000 - val_loss: 2.2757\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.7917 - loss: 0.5619 - val_accuracy: 0.3000 - val_loss: 1.6872\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8606 - loss: 0.4615 - val_accuracy: 0.3000 - val_loss: 2.5400\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.8806 - loss: 0.4171 - val_accuracy: 0.3400 - val_loss: 2.8515\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 52ms/step - accuracy: 0.9092 - loss: 0.3215 - val_accuracy: 0.3800 - val_loss: 2.3991\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9310 - loss: 0.2193 - val_accuracy: 0.3400 - val_loss: 2.9963\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8719 - loss: 0.4243 - val_accuracy: 0.4200 - val_loss: 2.4791\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8968 - loss: 0.3154 - val_accuracy: 0.4600 - val_loss: 2.4615\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9150 - loss: 0.2946 - val_accuracy: 0.6000 - val_loss: 1.5823\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8622 - loss: 0.3912 - val_accuracy: 0.5200 - val_loss: 1.5932\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.9104 - loss: 0.2903 - val_accuracy: 0.7400 - val_loss: 0.8985\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 50ms/step - accuracy: 0.8934 - loss: 0.3325 - val_accuracy: 0.7400 - val_loss: 0.8858\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8740 - loss: 0.3378 - val_accuracy: 0.7800 - val_loss: 0.7595\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9450 - loss: 0.1816 - val_accuracy: 0.8000 - val_loss: 0.7515\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9437 - loss: 0.1568 - val_accuracy: 0.9200 - val_loss: 0.3382\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9239 - loss: 0.2013 - val_accuracy: 0.8800 - val_loss: 0.4746\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9280 - loss: 0.2609 - val_accuracy: 0.8800 - val_loss: 0.3744\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9330 - loss: 0.1903 - val_accuracy: 0.9200 - val_loss: 0.2779\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 59ms/step - accuracy: 0.9776 - loss: 0.0939 - val_accuracy: 0.9000 - val_loss: 0.3252\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 55ms/step - accuracy: 0.9606 - loss: 0.1104 - val_accuracy: 0.9400 - val_loss: 0.2406\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9351 - loss: 0.2206 - val_accuracy: 0.7200 - val_loss: 0.9433\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8039 - loss: 0.7546 - val_accuracy: 0.7800 - val_loss: 0.5634\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9032 - loss: 0.4410 - val_accuracy: 0.8400 - val_loss: 0.4049\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9080 - loss: 0.3285 - val_accuracy: 0.8400 - val_loss: 0.4332\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9082 - loss: 0.3368 - val_accuracy: 0.9000 - val_loss: 0.3352\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9470 - loss: 0.1963 - val_accuracy: 0.9200 - val_loss: 0.3401\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9714 - loss: 0.1262 - val_accuracy: 0.9200 - val_loss: 0.3359\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9694 - loss: 0.1209 - val_accuracy: 0.9200 - val_loss: 0.2634\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9672 - loss: 0.1177 - val_accuracy: 0.9400 - val_loss: 0.1776\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9898 - loss: 0.0508 - val_accuracy: 0.9600 - val_loss: 0.1802\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9854 - loss: 0.0619 - val_accuracy: 0.8800 - val_loss: 0.3682\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9843 - loss: 0.0525 - val_accuracy: 0.8400 - val_loss: 0.3471\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9854 - loss: 0.0714 - val_accuracy: 0.8800 - val_loss: 0.2963\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9929 - loss: 0.0295 - val_accuracy: 0.9200 - val_loss: 0.4119\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9861 - loss: 0.0527 - val_accuracy: 0.9000 - val_loss: 0.2777\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9885 - loss: 0.0416 - val_accuracy: 0.9000 - val_loss: 0.2646\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9922 - loss: 0.0219 - val_accuracy: 0.9400 - val_loss: 0.2312\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9813 - loss: 0.0569 - val_accuracy: 0.8600 - val_loss: 0.4244\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9754 - loss: 0.0687 - val_accuracy: 0.9600 - val_loss: 0.2343\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 57ms/step - accuracy: 0.9526 - loss: 0.1364 - val_accuracy: 0.9200 - val_loss: 0.4201\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9147 - loss: 0.2464 - val_accuracy: 0.9400 - val_loss: 0.3104\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8936 - loss: 0.5276 - val_accuracy: 0.8000 - val_loss: 0.4132\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8677 - loss: 0.3916 - val_accuracy: 0.9200 - val_loss: 0.2264\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9822 - loss: 0.1281 - val_accuracy: 0.9200 - val_loss: 0.2015\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9950 - loss: 0.0589 - val_accuracy: 0.9000 - val_loss: 0.3391\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9853 - loss: 0.0715 - val_accuracy: 0.9600 - val_loss: 0.2148\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 469ms/step\n",
            "Fold 9 Accuracy: 0.9600\n",
            "\n",
            "Training Fold 10/10...\n",
            "Epoch 1/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.5827 - loss: 0.9891 - val_accuracy: 0.4400 - val_loss: 1.1210\n",
            "Epoch 2/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.7707 - loss: 0.7391 - val_accuracy: 0.4400 - val_loss: 1.3813\n",
            "Epoch 3/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7817 - loss: 0.6873 - val_accuracy: 0.4400 - val_loss: 1.7192\n",
            "Epoch 4/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.8374 - loss: 0.4774 - val_accuracy: 0.4400 - val_loss: 2.2424\n",
            "Epoch 5/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.8709 - loss: 0.4798 - val_accuracy: 0.4400 - val_loss: 2.3126\n",
            "Epoch 6/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 63ms/step - accuracy: 0.8870 - loss: 0.3619 - val_accuracy: 0.4400 - val_loss: 2.6998\n",
            "Epoch 7/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.8848 - loss: 0.3787 - val_accuracy: 0.4400 - val_loss: 2.5171\n",
            "Epoch 8/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9366 - loss: 0.2969 - val_accuracy: 0.4600 - val_loss: 2.2115\n",
            "Epoch 9/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9157 - loss: 0.2811 - val_accuracy: 0.4600 - val_loss: 2.2691\n",
            "Epoch 10/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8476 - loss: 0.4816 - val_accuracy: 0.5000 - val_loss: 2.1268\n",
            "Epoch 11/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8838 - loss: 0.3298 - val_accuracy: 0.5800 - val_loss: 1.7932\n",
            "Epoch 12/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9508 - loss: 0.2145 - val_accuracy: 0.5400 - val_loss: 1.6910\n",
            "Epoch 13/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 50ms/step - accuracy: 0.9425 - loss: 0.1762 - val_accuracy: 0.6200 - val_loss: 1.4919\n",
            "Epoch 14/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8733 - loss: 0.3896 - val_accuracy: 0.6400 - val_loss: 1.1149\n",
            "Epoch 15/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8837 - loss: 0.3366 - val_accuracy: 0.6400 - val_loss: 1.3257\n",
            "Epoch 16/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8919 - loss: 0.3772 - val_accuracy: 0.7200 - val_loss: 1.0278\n",
            "Epoch 17/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9541 - loss: 0.1670 - val_accuracy: 0.8200 - val_loss: 0.6603\n",
            "Epoch 18/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9489 - loss: 0.1702 - val_accuracy: 0.6200 - val_loss: 1.6027\n",
            "Epoch 19/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9169 - loss: 0.2735 - val_accuracy: 0.7800 - val_loss: 0.7342\n",
            "Epoch 20/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9453 - loss: 0.1797 - val_accuracy: 0.9200 - val_loss: 0.3249\n",
            "Epoch 21/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9628 - loss: 0.1144 - val_accuracy: 0.9200 - val_loss: 0.2450\n",
            "Epoch 22/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9765 - loss: 0.0880 - val_accuracy: 0.9200 - val_loss: 0.2101\n",
            "Epoch 23/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9696 - loss: 0.1201 - val_accuracy: 0.9000 - val_loss: 0.3108\n",
            "Epoch 24/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9384 - loss: 0.1884 - val_accuracy: 0.9200 - val_loss: 0.2890\n",
            "Epoch 25/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9553 - loss: 0.2128 - val_accuracy: 0.9200 - val_loss: 0.2566\n",
            "Epoch 26/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 53ms/step - accuracy: 0.9756 - loss: 0.0888 - val_accuracy: 0.9400 - val_loss: 0.1974\n",
            "Epoch 27/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9592 - loss: 0.1122 - val_accuracy: 0.9200 - val_loss: 0.2132\n",
            "Epoch 28/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9775 - loss: 0.0698 - val_accuracy: 0.9600 - val_loss: 0.1829\n",
            "Epoch 29/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9611 - loss: 0.1097 - val_accuracy: 0.9200 - val_loss: 0.2302\n",
            "Epoch 30/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9766 - loss: 0.0635 - val_accuracy: 0.9200 - val_loss: 0.3185\n",
            "Epoch 31/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 51ms/step - accuracy: 0.9824 - loss: 0.0600 - val_accuracy: 0.9400 - val_loss: 0.2180\n",
            "Epoch 32/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9980 - loss: 0.0198 - val_accuracy: 0.9400 - val_loss: 0.2667\n",
            "Epoch 33/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 49ms/step - accuracy: 0.9972 - loss: 0.0220 - val_accuracy: 0.9200 - val_loss: 0.2797\n",
            "Epoch 34/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9947 - loss: 0.0219 - val_accuracy: 0.8800 - val_loss: 0.3627\n",
            "Epoch 35/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9707 - loss: 0.1142 - val_accuracy: 0.8800 - val_loss: 0.4351\n",
            "Epoch 36/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8572 - loss: 0.6184 - val_accuracy: 0.8600 - val_loss: 0.3485\n",
            "Epoch 37/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 54ms/step - accuracy: 0.8416 - loss: 0.3392 - val_accuracy: 0.9000 - val_loss: 0.2598\n",
            "Epoch 38/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9682 - loss: 0.1242 - val_accuracy: 0.9200 - val_loss: 0.3576\n",
            "Epoch 39/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 48ms/step - accuracy: 0.9509 - loss: 0.1393 - val_accuracy: 0.9400 - val_loss: 0.2453\n",
            "Epoch 40/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9546 - loss: 0.1512 - val_accuracy: 0.9400 - val_loss: 0.3257\n",
            "Epoch 41/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 46ms/step - accuracy: 0.9772 - loss: 0.1028 - val_accuracy: 0.9400 - val_loss: 0.2889\n",
            "Epoch 42/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9968 - loss: 0.0314 - val_accuracy: 0.9400 - val_loss: 0.3177\n",
            "Epoch 43/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9914 - loss: 0.0458 - val_accuracy: 0.9200 - val_loss: 0.3735\n",
            "Epoch 44/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9934 - loss: 0.0266 - val_accuracy: 0.9000 - val_loss: 0.3158\n",
            "Epoch 45/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 48ms/step - accuracy: 0.9923 - loss: 0.0432 - val_accuracy: 0.9400 - val_loss: 0.3470\n",
            "Epoch 46/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 47ms/step - accuracy: 0.9758 - loss: 0.0800 - val_accuracy: 0.8600 - val_loss: 0.7292\n",
            "Epoch 47/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.8678 - loss: 0.5355 - val_accuracy: 0.7800 - val_loss: 0.9856\n",
            "Epoch 48/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 49ms/step - accuracy: 0.9194 - loss: 0.2885 - val_accuracy: 0.9000 - val_loss: 0.2948\n",
            "Epoch 49/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9489 - loss: 0.1818 - val_accuracy: 0.9000 - val_loss: 0.3794\n",
            "Epoch 50/50\n",
            "\u001b[1m29/29\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 60ms/step - accuracy: 0.9881 - loss: 0.0595 - val_accuracy: 0.8800 - val_loss: 0.4982\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 317ms/step\n",
            "Fold 10 Accuracy: 0.8800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Get predicted probabilities instead of class labels\n",
        "y_probs = model.predict(X)  # Get probabilities for each class\n",
        "\n",
        "# Calculate AUC using predicted probabilities\n",
        "auc = roc_auc_score(y, y_probs, multi_class='ovr')\n",
        "print(f\"\\nAUC Score: {auc:.4f}\")\n",
        "# Print final classification report\n",
        "print(\"\\nFinal Classification Report:\")\n",
        "print(classification_report(all_y_true, all_y_pred, target_names=[\"Intermittent Epilepsy\", \"Healthy\", \"Continuous Epilepsy\"]))\n",
        "\n",
        "# Save trained model\n",
        "model.save(\"/content/drive/MyDrive/cnn_lstm_trained_model.h5\")\n",
        "print(\"CNN-LSTM model trained, evaluated, and saved with 10-fold cross-validation.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Cqk0a6Xuwu_",
        "outputId": "4961fc52-0331-4de9-f8a2-48a42abf8a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "AUC Score: 0.9978\n",
            "\n",
            "Final Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "Intermittent Epilepsy       0.97      0.93      0.95       200\n",
            "              Healthy       0.93      0.97      0.95       200\n",
            "  Continuous Epilepsy       0.92      0.92      0.92       100\n",
            "\n",
            "             accuracy                           0.94       500\n",
            "            macro avg       0.94      0.94      0.94       500\n",
            "         weighted avg       0.94      0.94      0.94       500\n",
            "\n",
            "CNN-LSTM model trained, evaluated, and saved with 10-fold cross-validation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define CNN-LSTM model based on research paper\n",
        "def create_cnn_lstm_model_2(input_shape, num_classes):\n",
        "    model = Sequential([\n",
        "        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        Conv1D(filters=128, kernel_size=3, activation='relu'),\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        Conv1D(filters=256, kernel_size=3, activation='relu'),  # Additional conv layer\n",
        "        BatchNormalization(),\n",
        "        MaxPooling1D(pool_size=2),\n",
        "\n",
        "        LSTM(128, return_sequences=True, dropout=0.2),  # First LSTM layer\n",
        "        LSTM(64, return_sequences=False, dropout=0.2),  # Second LSTM layer\n",
        "        Dropout(0.5),\n",
        "\n",
        "        Dense(64, activation='relu'),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(optimizer=Adam(learning_rate=0.0005),  # Reduced learning rate\n",
        "                  loss='sparse_categorical_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "    return model\n",
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 634
        },
        "id": "OiBcRxNiC4jV",
        "outputId": "817d08d7-c4c9-4ec1-c34e-550e1f51e150"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_42\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_42\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_109 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4095\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_75               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4095\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_109 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2047\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_110 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2045\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │          \u001b[38;5;34m24,704\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_76               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2045\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_110 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1022\u001b[0m, \u001b[38;5;34m128\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_111 (\u001b[38;5;33mConv1D\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1020\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │          \u001b[38;5;34m98,560\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_77               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1020\u001b[0m, \u001b[38;5;34m256\u001b[0m)           │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_111 (\u001b[38;5;33mMaxPooling1D\u001b[0m)     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m256\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_67 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m510\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │          \u001b[38;5;34m82,176\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_68 (\u001b[38;5;33mLSTM\u001b[0m)                       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │          \u001b[38;5;34m12,416\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_42 (\u001b[38;5;33mDropout\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_84 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m2,112\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_85 (\u001b[38;5;33mDense\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)                   │             \u001b[38;5;34m195\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv1d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4095</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_75               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4095</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_109 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2047</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2045</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_76               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2045</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_110 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1022</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv1d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │          <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_77               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1020</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling1d_111 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_67 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">510</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │          <span style=\"color: #00af00; text-decoration-color: #00af00\">82,176</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ lstm_68 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │          <span style=\"color: #00af00; text-decoration-color: #00af00\">12,416</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_42 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_84 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,112</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_85 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                   │             <span style=\"color: #00af00; text-decoration-color: #00af00\">195</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m664,843\u001b[0m (2.54 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">664,843</span> (2.54 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m221,315\u001b[0m (864.51 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">221,315</span> (864.51 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m442,632\u001b[0m (1.69 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">442,632</span> (1.69 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Rate Scheduler\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=10, min_lr=1e-6)\n",
        "\n",
        "# Perform 10-fold cross-validation\n",
        "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "accuracies = []\n",
        "all_y_true, all_y_pred = [], []\n",
        "\n",
        "fold = 1\n",
        "for train_index, test_index in kf.split(X):\n",
        "    print(f\"\\nTraining Fold {fold}/10...\")\n",
        "\n",
        "    X_train, X_test = X[train_index], X[test_index]\n",
        "    y_train, y_test = y[train_index], y[test_index]\n",
        "\n",
        "    model = create_cnn_lstm_model(input_shape=X_train.shape[1:], num_classes=3)\n",
        "\n",
        "    model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_test, y_test),\n",
        "        epochs=100,  # Increased from 80 to 100\n",
        "        batch_size=32,  # Adjusted batch size as per research paper\n",
        "        class_weight=class_weight_dict,  # Balance class weights\n",
        "        callbacks=[lr_scheduler]  # Added learning rate decay\n",
        "    )\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_test).astype(np.float32), axis=1)\n",
        "    accuracies.append(model.evaluate(X_test, y_test, verbose=0)[1])\n",
        "    all_y_true.extend(y_test)\n",
        "    all_y_pred.extend(y_pred)\n",
        "\n",
        "    print(f\"Fold {fold} Accuracy: {accuracies[-1]:.4f}\")\n",
        "    fold += 1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i9Gv_qVsDAPr",
        "outputId": "25aaca74-949e-4ae1-8134-280cc6fd49ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Fold 1/10...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - accuracy: 0.5710 - loss: 0.9385 - val_accuracy: 0.4600 - val_loss: 1.0480 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 67ms/step - accuracy: 0.7283 - loss: 0.7605 - val_accuracy: 0.4400 - val_loss: 1.1489 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.7862 - loss: 0.6120 - val_accuracy: 0.4400 - val_loss: 1.4665 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.8349 - loss: 0.5021 - val_accuracy: 0.4400 - val_loss: 1.8331 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8996 - loss: 0.3728 - val_accuracy: 0.4400 - val_loss: 2.1370 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9079 - loss: 0.3508 - val_accuracy: 0.4400 - val_loss: 2.2405 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9113 - loss: 0.3302 - val_accuracy: 0.4400 - val_loss: 2.3583 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.8655 - loss: 0.3694 - val_accuracy: 0.4400 - val_loss: 2.1276 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9304 - loss: 0.2309 - val_accuracy: 0.4400 - val_loss: 2.3590 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8944 - loss: 0.3346 - val_accuracy: 0.4400 - val_loss: 2.5293 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.8704 - loss: 0.3056 - val_accuracy: 0.4400 - val_loss: 2.6695 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9424 - loss: 0.1821 - val_accuracy: 0.4400 - val_loss: 2.7249 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9498 - loss: 0.1365 - val_accuracy: 0.4400 - val_loss: 2.9410 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step - accuracy: 0.9733 - loss: 0.1460 - val_accuracy: 0.4400 - val_loss: 2.9594 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 132ms/step - accuracy: 0.9657 - loss: 0.1409 - val_accuracy: 0.4400 - val_loss: 3.0737 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step - accuracy: 0.9632 - loss: 0.0960 - val_accuracy: 0.4400 - val_loss: 3.1867 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 104ms/step - accuracy: 0.9288 - loss: 0.3268 - val_accuracy: 0.4400 - val_loss: 3.0528 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9424 - loss: 0.1863 - val_accuracy: 0.4400 - val_loss: 3.1723 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 70ms/step - accuracy: 0.9750 - loss: 0.1231 - val_accuracy: 0.4600 - val_loss: 3.0430 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9609 - loss: 0.1641 - val_accuracy: 0.4600 - val_loss: 2.5544 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9597 - loss: 0.1374 - val_accuracy: 0.4800 - val_loss: 2.5388 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9774 - loss: 0.1279 - val_accuracy: 0.5200 - val_loss: 2.4643 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9703 - loss: 0.1259 - val_accuracy: 0.5400 - val_loss: 2.4347 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.9428 - loss: 0.1611 - val_accuracy: 0.5400 - val_loss: 2.3280 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9122 - loss: 0.2160 - val_accuracy: 0.5600 - val_loss: 2.2458 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9735 - loss: 0.0950 - val_accuracy: 0.5800 - val_loss: 2.1135 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9768 - loss: 0.0929 - val_accuracy: 0.5800 - val_loss: 2.1447 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9812 - loss: 0.0958 - val_accuracy: 0.6000 - val_loss: 1.6943 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9797 - loss: 0.0697 - val_accuracy: 0.6800 - val_loss: 1.4022 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 67ms/step - accuracy: 0.9956 - loss: 0.0598 - val_accuracy: 0.7000 - val_loss: 1.3847 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9941 - loss: 0.0549 - val_accuracy: 0.7600 - val_loss: 1.1385 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9928 - loss: 0.0582 - val_accuracy: 0.8000 - val_loss: 0.9700 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9900 - loss: 0.0555 - val_accuracy: 0.8200 - val_loss: 0.7828 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9984 - loss: 0.0459 - val_accuracy: 0.8600 - val_loss: 0.6764 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9945 - loss: 0.0462 - val_accuracy: 0.8200 - val_loss: 0.7227 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9932 - loss: 0.0486 - val_accuracy: 0.8400 - val_loss: 0.5798 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9962 - loss: 0.0426 - val_accuracy: 0.9000 - val_loss: 0.4408 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9925 - loss: 0.0426 - val_accuracy: 0.8600 - val_loss: 0.5428 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9852 - loss: 0.0793 - val_accuracy: 0.8800 - val_loss: 0.3845 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9794 - loss: 0.0854 - val_accuracy: 0.9000 - val_loss: 0.3888 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9675 - loss: 0.0726 - val_accuracy: 0.9200 - val_loss: 0.2300 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9701 - loss: 0.0710 - val_accuracy: 0.9400 - val_loss: 0.1171 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9894 - loss: 0.0438 - val_accuracy: 0.9400 - val_loss: 0.0963 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9915 - loss: 0.0318 - val_accuracy: 0.9400 - val_loss: 0.0923 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9969 - loss: 0.0315 - val_accuracy: 0.9800 - val_loss: 0.0739 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 68ms/step - accuracy: 0.9959 - loss: 0.0405 - val_accuracy: 0.9800 - val_loss: 0.0727 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9965 - loss: 0.0332 - val_accuracy: 0.9600 - val_loss: 0.0702 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9984 - loss: 0.0254 - val_accuracy: 0.9600 - val_loss: 0.0653 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9939 - loss: 0.0421 - val_accuracy: 0.9600 - val_loss: 0.0639 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9982 - loss: 0.0232 - val_accuracy: 0.9600 - val_loss: 0.0673 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9975 - loss: 0.0424 - val_accuracy: 0.9600 - val_loss: 0.0696 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0291 - val_accuracy: 0.9600 - val_loss: 0.0809 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9973 - loss: 0.0272 - val_accuracy: 0.9600 - val_loss: 0.0804 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9997 - loss: 0.0295 - val_accuracy: 0.9600 - val_loss: 0.0748 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9775 - loss: 0.0602 - val_accuracy: 0.9400 - val_loss: 0.1785 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9799 - loss: 0.0555 - val_accuracy: 0.9600 - val_loss: 0.0880 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9897 - loss: 0.0457 - val_accuracy: 0.9800 - val_loss: 0.0664 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 0.9904 - loss: 0.0450 - val_accuracy: 0.9800 - val_loss: 0.0464 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9953 - loss: 0.0346 - val_accuracy: 0.9800 - val_loss: 0.0446 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9991 - loss: 0.0256 - val_accuracy: 0.9800 - val_loss: 0.0642 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9993 - loss: 0.0273 - val_accuracy: 0.9800 - val_loss: 0.1084 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9886 - loss: 0.0424 - val_accuracy: 0.9800 - val_loss: 0.0672 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9940 - loss: 0.0525 - val_accuracy: 0.9800 - val_loss: 0.0372 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9945 - loss: 0.0363 - val_accuracy: 1.0000 - val_loss: 0.0363 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9984 - loss: 0.0270 - val_accuracy: 1.0000 - val_loss: 0.0395 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0197 - val_accuracy: 1.0000 - val_loss: 0.0393 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9970 - loss: 0.0229 - val_accuracy: 1.0000 - val_loss: 0.0401 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - accuracy: 0.9963 - loss: 0.0229 - val_accuracy: 0.9800 - val_loss: 0.0393 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9985 - loss: 0.0176 - val_accuracy: 0.9800 - val_loss: 0.0325 - learning_rate: 1.2500e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 1.0000 - val_loss: 0.0291 - learning_rate: 1.2500e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 0.9997 - loss: 0.0212 - val_accuracy: 1.0000 - val_loss: 0.0300 - learning_rate: 1.2500e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9949 - loss: 0.0192 - val_accuracy: 0.9600 - val_loss: 0.0851 - learning_rate: 1.2500e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 0.9400 - val_loss: 0.1152 - learning_rate: 1.2500e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9982 - loss: 0.0320 - val_accuracy: 1.0000 - val_loss: 0.0404 - learning_rate: 1.2500e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9982 - loss: 0.0236 - val_accuracy: 1.0000 - val_loss: 0.0361 - learning_rate: 1.2500e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9976 - loss: 0.0209 - val_accuracy: 1.0000 - val_loss: 0.0306 - learning_rate: 1.2500e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9984 - loss: 0.0203 - val_accuracy: 0.9800 - val_loss: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9844 - loss: 0.0570 - val_accuracy: 0.9800 - val_loss: 0.0501 - learning_rate: 1.2500e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9991 - loss: 0.0256 - val_accuracy: 0.9600 - val_loss: 0.0603 - learning_rate: 1.2500e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9932 - loss: 0.0316 - val_accuracy: 0.9600 - val_loss: 0.0750 - learning_rate: 1.2500e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9975 - loss: 0.0189 - val_accuracy: 0.9600 - val_loss: 0.0722 - learning_rate: 6.2500e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0174 - val_accuracy: 0.9800 - val_loss: 0.0394 - learning_rate: 6.2500e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0187 - val_accuracy: 0.9800 - val_loss: 0.0378 - learning_rate: 6.2500e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9989 - loss: 0.0186 - val_accuracy: 0.9800 - val_loss: 0.0406 - learning_rate: 6.2500e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9994 - loss: 0.0147 - val_accuracy: 0.9800 - val_loss: 0.0552 - learning_rate: 6.2500e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0157 - val_accuracy: 0.9800 - val_loss: 0.0581 - learning_rate: 6.2500e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9975 - loss: 0.0219 - val_accuracy: 0.9600 - val_loss: 0.0582 - learning_rate: 6.2500e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9987 - loss: 0.0174 - val_accuracy: 0.9600 - val_loss: 0.0664 - learning_rate: 6.2500e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9978 - loss: 0.0165 - val_accuracy: 0.9600 - val_loss: 0.0718 - learning_rate: 6.2500e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9600 - val_loss: 0.0741 - learning_rate: 6.2500e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9997 - loss: 0.0147 - val_accuracy: 0.9600 - val_loss: 0.0745 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 69ms/step - accuracy: 1.0000 - loss: 0.0142 - val_accuracy: 0.9600 - val_loss: 0.0857 - learning_rate: 3.1250e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9600 - val_loss: 0.0870 - learning_rate: 3.1250e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9600 - val_loss: 0.0893 - learning_rate: 3.1250e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 1.0000 - loss: 0.0155 - val_accuracy: 0.9600 - val_loss: 0.0880 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0235 - val_accuracy: 0.9600 - val_loss: 0.0875 - learning_rate: 3.1250e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 1.0000 - loss: 0.0167 - val_accuracy: 0.9600 - val_loss: 0.0879 - learning_rate: 3.1250e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9997 - loss: 0.0117 - val_accuracy: 0.9600 - val_loss: 0.0858 - learning_rate: 3.1250e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 1.0000 - loss: 0.0147 - val_accuracy: 0.9800 - val_loss: 0.0879 - learning_rate: 3.1250e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9984 - loss: 0.0193 - val_accuracy: 0.9800 - val_loss: 0.0874 - learning_rate: 3.1250e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 339ms/step\n",
            "Fold 1 Accuracy: 0.9800\n",
            "\n",
            "Training Fold 2/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.4985 - loss: 0.9964 - val_accuracy: 0.5200 - val_loss: 1.0504 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 116ms/step - accuracy: 0.7492 - loss: 0.7341 - val_accuracy: 0.4000 - val_loss: 1.1711 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.7958 - loss: 0.6598 - val_accuracy: 0.4000 - val_loss: 1.3938 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7370 - loss: 0.5686 - val_accuracy: 0.4000 - val_loss: 1.5530 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9046 - loss: 0.3854 - val_accuracy: 0.4000 - val_loss: 1.8052 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9306 - loss: 0.2764 - val_accuracy: 0.4000 - val_loss: 2.1133 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9004 - loss: 0.3241 - val_accuracy: 0.4000 - val_loss: 2.2862 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8570 - loss: 0.4848 - val_accuracy: 0.4000 - val_loss: 2.4229 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8209 - loss: 0.5170 - val_accuracy: 0.4000 - val_loss: 2.4083 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8980 - loss: 0.3453 - val_accuracy: 0.4000 - val_loss: 2.4843 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9343 - loss: 0.2646 - val_accuracy: 0.4000 - val_loss: 2.4988 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9485 - loss: 0.2114 - val_accuracy: 0.4000 - val_loss: 2.6475 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9287 - loss: 0.2698 - val_accuracy: 0.4000 - val_loss: 2.7034 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9333 - loss: 0.2195 - val_accuracy: 0.4000 - val_loss: 2.7651 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9341 - loss: 0.2168 - val_accuracy: 0.4000 - val_loss: 2.8006 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9588 - loss: 0.1624 - val_accuracy: 0.4000 - val_loss: 2.9458 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9881 - loss: 0.0980 - val_accuracy: 0.4000 - val_loss: 2.9948 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9661 - loss: 0.1116 - val_accuracy: 0.4000 - val_loss: 3.1278 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9554 - loss: 0.1742 - val_accuracy: 0.4000 - val_loss: 2.9916 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9725 - loss: 0.0829 - val_accuracy: 0.4400 - val_loss: 2.9417 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9858 - loss: 0.0668 - val_accuracy: 0.4200 - val_loss: 3.0653 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9652 - loss: 0.1305 - val_accuracy: 0.4400 - val_loss: 2.8931 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9580 - loss: 0.1050 - val_accuracy: 0.4400 - val_loss: 2.8333 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9879 - loss: 0.0838 - val_accuracy: 0.4400 - val_loss: 2.7377 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9886 - loss: 0.0653 - val_accuracy: 0.4800 - val_loss: 2.6190 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9818 - loss: 0.1062 - val_accuracy: 0.5000 - val_loss: 2.4347 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9857 - loss: 0.0690 - val_accuracy: 0.5400 - val_loss: 2.3787 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9875 - loss: 0.0820 - val_accuracy: 0.5600 - val_loss: 2.2062 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9828 - loss: 0.0750 - val_accuracy: 0.5800 - val_loss: 1.8537 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9224 - loss: 0.2155 - val_accuracy: 0.6800 - val_loss: 1.5490 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9561 - loss: 0.1341 - val_accuracy: 0.7000 - val_loss: 1.4024 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9555 - loss: 0.1447 - val_accuracy: 0.6600 - val_loss: 1.3792 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9752 - loss: 0.0934 - val_accuracy: 0.7600 - val_loss: 1.0794 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9862 - loss: 0.0712 - val_accuracy: 0.7800 - val_loss: 0.8721 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9762 - loss: 0.0757 - val_accuracy: 0.8000 - val_loss: 0.8252 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9894 - loss: 0.0761 - val_accuracy: 0.7600 - val_loss: 0.9421 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9789 - loss: 0.1263 - val_accuracy: 0.8200 - val_loss: 0.6589 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9760 - loss: 0.1445 - val_accuracy: 0.8200 - val_loss: 0.5801 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9829 - loss: 0.0771 - val_accuracy: 0.8600 - val_loss: 0.3652 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9921 - loss: 0.0616 - val_accuracy: 0.8800 - val_loss: 0.3093 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9887 - loss: 0.0753 - val_accuracy: 0.8800 - val_loss: 0.2663 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9808 - loss: 0.0968 - val_accuracy: 0.8800 - val_loss: 0.2852 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9868 - loss: 0.0614 - val_accuracy: 0.9000 - val_loss: 0.2675 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9674 - loss: 0.1104 - val_accuracy: 0.9000 - val_loss: 0.2206 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9771 - loss: 0.1028 - val_accuracy: 0.9200 - val_loss: 0.1699 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9874 - loss: 0.0555 - val_accuracy: 0.9400 - val_loss: 0.1919 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9959 - loss: 0.0370 - val_accuracy: 0.9400 - val_loss: 0.1545 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9841 - loss: 0.0539 - val_accuracy: 0.9400 - val_loss: 0.1226 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9966 - loss: 0.0381 - val_accuracy: 0.9200 - val_loss: 0.1558 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9970 - loss: 0.0371 - val_accuracy: 0.9600 - val_loss: 0.0993 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9979 - loss: 0.0423 - val_accuracy: 0.9800 - val_loss: 0.0870 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0327 - val_accuracy: 1.0000 - val_loss: 0.0601 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9958 - loss: 0.0484 - val_accuracy: 0.9800 - val_loss: 0.0560 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9971 - loss: 0.0359 - val_accuracy: 0.9800 - val_loss: 0.0523 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9950 - loss: 0.0342 - val_accuracy: 0.9800 - val_loss: 0.0520 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9979 - loss: 0.0353 - val_accuracy: 0.9800 - val_loss: 0.0476 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9966 - loss: 0.0263 - val_accuracy: 0.9400 - val_loss: 0.1298 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9979 - loss: 0.0351 - val_accuracy: 0.9600 - val_loss: 0.0840 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9993 - loss: 0.0306 - val_accuracy: 0.9600 - val_loss: 0.0741 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9949 - loss: 0.0455 - val_accuracy: 0.9600 - val_loss: 0.1025 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9982 - loss: 0.0283 - val_accuracy: 0.9600 - val_loss: 0.1151 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9975 - loss: 0.0277 - val_accuracy: 0.9400 - val_loss: 0.1124 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9808 - loss: 0.0866 - val_accuracy: 0.9000 - val_loss: 0.3064 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9321 - loss: 0.2091 - val_accuracy: 0.9800 - val_loss: 0.0615 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9867 - loss: 0.0579 - val_accuracy: 0.9800 - val_loss: 0.0589 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9881 - loss: 0.0550 - val_accuracy: 0.9800 - val_loss: 0.0585 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9857 - loss: 0.0611 - val_accuracy: 0.9800 - val_loss: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9935 - loss: 0.0390 - val_accuracy: 0.9800 - val_loss: 0.0610 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9989 - loss: 0.0336 - val_accuracy: 0.9800 - val_loss: 0.0619 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9956 - loss: 0.0414 - val_accuracy: 0.9800 - val_loss: 0.0622 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9832 - loss: 0.0635 - val_accuracy: 0.9800 - val_loss: 0.0633 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0240 - val_accuracy: 0.9800 - val_loss: 0.0627 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9970 - loss: 0.0320 - val_accuracy: 0.9800 - val_loss: 0.0636 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9993 - loss: 0.0281 - val_accuracy: 0.9800 - val_loss: 0.0643 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9903 - loss: 0.0282 - val_accuracy: 0.9800 - val_loss: 0.0703 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9934 - loss: 0.0291 - val_accuracy: 0.9800 - val_loss: 0.0717 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9970 - loss: 0.0274 - val_accuracy: 0.9800 - val_loss: 0.0713 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9930 - loss: 0.0294 - val_accuracy: 0.9800 - val_loss: 0.0703 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9970 - loss: 0.0268 - val_accuracy: 0.9800 - val_loss: 0.0631 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9903 - loss: 0.0399 - val_accuracy: 0.9800 - val_loss: 0.0610 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9993 - loss: 0.0247 - val_accuracy: 0.9800 - val_loss: 0.0600 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9982 - loss: 0.0274 - val_accuracy: 0.9800 - val_loss: 0.0587 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9935 - loss: 0.0266 - val_accuracy: 0.9800 - val_loss: 0.0582 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9935 - loss: 0.0320 - val_accuracy: 0.9800 - val_loss: 0.0550 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9960 - loss: 0.0242 - val_accuracy: 0.9800 - val_loss: 0.0505 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9982 - loss: 0.0276 - val_accuracy: 0.9800 - val_loss: 0.0494 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9914 - loss: 0.0353 - val_accuracy: 0.9800 - val_loss: 0.0496 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9997 - loss: 0.0230 - val_accuracy: 0.9800 - val_loss: 0.0487 - learning_rate: 1.5625e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9852 - loss: 0.0371 - val_accuracy: 0.9800 - val_loss: 0.0507 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9922 - loss: 0.0338 - val_accuracy: 0.9800 - val_loss: 0.0512 - learning_rate: 1.5625e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9960 - loss: 0.0278 - val_accuracy: 0.9800 - val_loss: 0.0508 - learning_rate: 1.5625e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0241 - val_accuracy: 0.9800 - val_loss: 0.0501 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.9800 - val_loss: 0.0505 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9974 - loss: 0.0219 - val_accuracy: 0.9800 - val_loss: 0.0520 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9982 - loss: 0.0259 - val_accuracy: 0.9800 - val_loss: 0.0527 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9946 - loss: 0.0310 - val_accuracy: 0.9800 - val_loss: 0.0522 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9934 - loss: 0.0360 - val_accuracy: 0.9800 - val_loss: 0.0521 - learning_rate: 7.8125e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9923 - loss: 0.0250 - val_accuracy: 0.9800 - val_loss: 0.0530 - learning_rate: 7.8125e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9976 - loss: 0.0325 - val_accuracy: 0.9800 - val_loss: 0.0525 - learning_rate: 7.8125e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9963 - loss: 0.0332 - val_accuracy: 0.9800 - val_loss: 0.0522 - learning_rate: 7.8125e-06\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 327ms/step\n",
            "Fold 2 Accuracy: 0.9800\n",
            "\n",
            "Training Fold 3/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 114ms/step - accuracy: 0.5945 - loss: 0.9855 - val_accuracy: 0.4600 - val_loss: 1.0666 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.7814 - loss: 0.7255 - val_accuracy: 0.4000 - val_loss: 1.2083 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7775 - loss: 0.6505 - val_accuracy: 0.4000 - val_loss: 1.3563 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8623 - loss: 0.5515 - val_accuracy: 0.4000 - val_loss: 1.6391 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8549 - loss: 0.4639 - val_accuracy: 0.4000 - val_loss: 1.7959 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8964 - loss: 0.3927 - val_accuracy: 0.4000 - val_loss: 2.0961 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9346 - loss: 0.3047 - val_accuracy: 0.4000 - val_loss: 2.3409 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9144 - loss: 0.3201 - val_accuracy: 0.4000 - val_loss: 2.5057 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9595 - loss: 0.1987 - val_accuracy: 0.4000 - val_loss: 2.8664 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8815 - loss: 0.2986 - val_accuracy: 0.4000 - val_loss: 3.0314 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9569 - loss: 0.2091 - val_accuracy: 0.4000 - val_loss: 3.4383 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6377 - loss: 1.3166 - val_accuracy: 0.1400 - val_loss: 2.7874 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.6748 - loss: 0.6442 - val_accuracy: 0.4000 - val_loss: 2.8207 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8969 - loss: 0.4185 - val_accuracy: 0.4000 - val_loss: 2.9754 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9345 - loss: 0.2903 - val_accuracy: 0.4000 - val_loss: 2.9813 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9276 - loss: 0.2487 - val_accuracy: 0.4000 - val_loss: 3.0030 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9279 - loss: 0.2336 - val_accuracy: 0.4000 - val_loss: 2.8864 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9481 - loss: 0.1901 - val_accuracy: 0.4000 - val_loss: 2.9258 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9346 - loss: 0.1965 - val_accuracy: 0.4000 - val_loss: 3.2114 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8719 - loss: 0.5216 - val_accuracy: 0.4800 - val_loss: 2.4759 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.7490 - loss: 0.5241 - val_accuracy: 0.4600 - val_loss: 2.4007 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9315 - loss: 0.2061 - val_accuracy: 0.4400 - val_loss: 2.7715 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9692 - loss: 0.1952 - val_accuracy: 0.4400 - val_loss: 2.5351 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9595 - loss: 0.1788 - val_accuracy: 0.4600 - val_loss: 2.3788 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9422 - loss: 0.1881 - val_accuracy: 0.5000 - val_loss: 2.2658 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9634 - loss: 0.1416 - val_accuracy: 0.4800 - val_loss: 2.2407 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9615 - loss: 0.1439 - val_accuracy: 0.4800 - val_loss: 2.0730 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9849 - loss: 0.0944 - val_accuracy: 0.5400 - val_loss: 1.8301 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9737 - loss: 0.1078 - val_accuracy: 0.5800 - val_loss: 1.5857 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9846 - loss: 0.0964 - val_accuracy: 0.6600 - val_loss: 1.2028 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9856 - loss: 0.0781 - val_accuracy: 0.7200 - val_loss: 1.0333 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9808 - loss: 0.0936 - val_accuracy: 0.8000 - val_loss: 0.9562 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9688 - loss: 0.1240 - val_accuracy: 0.7800 - val_loss: 1.0337 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9718 - loss: 0.1180 - val_accuracy: 0.8200 - val_loss: 0.7677 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9767 - loss: 0.0781 - val_accuracy: 0.8600 - val_loss: 0.6622 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9985 - loss: 0.0400 - val_accuracy: 0.8600 - val_loss: 0.5509 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9723 - loss: 0.0945 - val_accuracy: 0.8800 - val_loss: 0.4572 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9752 - loss: 0.0846 - val_accuracy: 0.9000 - val_loss: 0.4145 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9608 - loss: 0.0993 - val_accuracy: 0.8800 - val_loss: 0.4291 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9741 - loss: 0.1095 - val_accuracy: 0.8600 - val_loss: 0.4535 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9396 - loss: 0.2609 - val_accuracy: 0.9200 - val_loss: 0.2039 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9059 - loss: 0.3806 - val_accuracy: 0.9200 - val_loss: 0.2280 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9822 - loss: 0.1276 - val_accuracy: 0.9600 - val_loss: 0.1231 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9846 - loss: 0.0805 - val_accuracy: 0.9600 - val_loss: 0.1096 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9866 - loss: 0.0730 - val_accuracy: 0.9600 - val_loss: 0.0975 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9945 - loss: 0.0710 - val_accuracy: 0.9800 - val_loss: 0.0888 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9904 - loss: 0.0617 - val_accuracy: 0.9800 - val_loss: 0.0812 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9750 - loss: 0.0916 - val_accuracy: 0.9600 - val_loss: 0.1757 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9733 - loss: 0.1171 - val_accuracy: 0.9400 - val_loss: 0.2514 - learning_rate: 2.5000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9516 - loss: 0.1152 - val_accuracy: 0.9800 - val_loss: 0.0842 - learning_rate: 2.5000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9730 - loss: 0.0916 - val_accuracy: 0.9800 - val_loss: 0.0763 - learning_rate: 2.5000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9823 - loss: 0.0757 - val_accuracy: 0.9800 - val_loss: 0.0749 - learning_rate: 2.5000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9787 - loss: 0.0865 - val_accuracy: 0.9800 - val_loss: 0.0799 - learning_rate: 2.5000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9752 - loss: 0.0894 - val_accuracy: 0.9800 - val_loss: 0.0755 - learning_rate: 2.5000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9757 - loss: 0.0954 - val_accuracy: 0.9800 - val_loss: 0.0756 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9892 - loss: 0.0491 - val_accuracy: 0.9800 - val_loss: 0.0739 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9962 - loss: 0.0463 - val_accuracy: 0.9800 - val_loss: 0.0711 - learning_rate: 2.5000e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9928 - loss: 0.0432 - val_accuracy: 0.9800 - val_loss: 0.0729 - learning_rate: 2.5000e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9954 - loss: 0.0395 - val_accuracy: 0.9800 - val_loss: 0.0788 - learning_rate: 2.5000e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9945 - loss: 0.0378 - val_accuracy: 0.9600 - val_loss: 0.1014 - learning_rate: 2.5000e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9888 - loss: 0.0494 - val_accuracy: 0.9800 - val_loss: 0.0746 - learning_rate: 2.5000e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9944 - loss: 0.0406 - val_accuracy: 0.9800 - val_loss: 0.0622 - learning_rate: 2.5000e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9865 - loss: 0.0398 - val_accuracy: 0.9800 - val_loss: 0.0588 - learning_rate: 2.5000e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9976 - loss: 0.0286 - val_accuracy: 0.9800 - val_loss: 0.0496 - learning_rate: 2.5000e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9667 - loss: 0.1389 - val_accuracy: 0.9600 - val_loss: 0.0843 - learning_rate: 2.5000e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9492 - loss: 0.1225 - val_accuracy: 0.9400 - val_loss: 0.2694 - learning_rate: 2.5000e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9650 - loss: 0.1081 - val_accuracy: 0.9800 - val_loss: 0.1072 - learning_rate: 2.5000e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9837 - loss: 0.0687 - val_accuracy: 0.9800 - val_loss: 0.0937 - learning_rate: 2.5000e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9747 - loss: 0.0860 - val_accuracy: 0.9800 - val_loss: 0.0732 - learning_rate: 2.5000e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9984 - loss: 0.0330 - val_accuracy: 0.9800 - val_loss: 0.0721 - learning_rate: 2.5000e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9860 - loss: 0.0600 - val_accuracy: 0.9800 - val_loss: 0.0692 - learning_rate: 2.5000e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9906 - loss: 0.0443 - val_accuracy: 0.9800 - val_loss: 0.0596 - learning_rate: 2.5000e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9897 - loss: 0.0392 - val_accuracy: 0.9800 - val_loss: 0.0586 - learning_rate: 2.5000e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9821 - loss: 0.0459 - val_accuracy: 0.9800 - val_loss: 0.0594 - learning_rate: 2.5000e-04\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9871 - loss: 0.0421 - val_accuracy: 0.9800 - val_loss: 0.0604 - learning_rate: 1.2500e-04\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0296 - val_accuracy: 0.9800 - val_loss: 0.0634 - learning_rate: 1.2500e-04\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9983 - loss: 0.0250 - val_accuracy: 0.9800 - val_loss: 0.0644 - learning_rate: 1.2500e-04\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9937 - loss: 0.0362 - val_accuracy: 0.9800 - val_loss: 0.0641 - learning_rate: 1.2500e-04\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9904 - loss: 0.0421 - val_accuracy: 0.9800 - val_loss: 0.0625 - learning_rate: 1.2500e-04\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9947 - loss: 0.0280 - val_accuracy: 0.9800 - val_loss: 0.0624 - learning_rate: 1.2500e-04\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9940 - loss: 0.0312 - val_accuracy: 0.9800 - val_loss: 0.0667 - learning_rate: 1.2500e-04\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9966 - loss: 0.0258 - val_accuracy: 0.9800 - val_loss: 0.0618 - learning_rate: 1.2500e-04\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9977 - loss: 0.0259 - val_accuracy: 0.9800 - val_loss: 0.0787 - learning_rate: 1.2500e-04\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9903 - loss: 0.0373 - val_accuracy: 0.9800 - val_loss: 0.0700 - learning_rate: 1.2500e-04\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9910 - loss: 0.0369 - val_accuracy: 0.9800 - val_loss: 0.0593 - learning_rate: 6.2500e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9943 - loss: 0.0343 - val_accuracy: 0.9800 - val_loss: 0.0540 - learning_rate: 6.2500e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9997 - loss: 0.0253 - val_accuracy: 0.9800 - val_loss: 0.0548 - learning_rate: 6.2500e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9963 - loss: 0.0267 - val_accuracy: 0.9800 - val_loss: 0.0638 - learning_rate: 6.2500e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9964 - loss: 0.0271 - val_accuracy: 0.9800 - val_loss: 0.0658 - learning_rate: 6.2500e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9977 - loss: 0.0240 - val_accuracy: 0.9800 - val_loss: 0.0669 - learning_rate: 6.2500e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9966 - loss: 0.0229 - val_accuracy: 0.9800 - val_loss: 0.0659 - learning_rate: 6.2500e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9958 - loss: 0.0336 - val_accuracy: 0.9800 - val_loss: 0.0603 - learning_rate: 6.2500e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9981 - loss: 0.0322 - val_accuracy: 0.9800 - val_loss: 0.0579 - learning_rate: 6.2500e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9973 - loss: 0.0253 - val_accuracy: 0.9800 - val_loss: 0.0598 - learning_rate: 6.2500e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.9941 - loss: 0.0256 - val_accuracy: 0.9800 - val_loss: 0.0595 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9929 - loss: 0.0320 - val_accuracy: 0.9800 - val_loss: 0.0623 - learning_rate: 3.1250e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9923 - loss: 0.0313 - val_accuracy: 0.9800 - val_loss: 0.0618 - learning_rate: 3.1250e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9985 - loss: 0.0231 - val_accuracy: 0.9800 - val_loss: 0.0645 - learning_rate: 3.1250e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9956 - loss: 0.0269 - val_accuracy: 0.9800 - val_loss: 0.0644 - learning_rate: 3.1250e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9990 - loss: 0.0214 - val_accuracy: 0.9800 - val_loss: 0.0652 - learning_rate: 3.1250e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 382ms/step\n",
            "Fold 3 Accuracy: 0.9800\n",
            "\n",
            "Training Fold 4/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 120ms/step - accuracy: 0.4842 - loss: 1.0452 - val_accuracy: 0.5600 - val_loss: 1.0418 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.6766 - loss: 0.8731 - val_accuracy: 0.5200 - val_loss: 1.1504 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.7640 - loss: 0.7072 - val_accuracy: 0.5200 - val_loss: 1.3613 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.8160 - loss: 0.6381 - val_accuracy: 0.5200 - val_loss: 1.5899 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.8561 - loss: 0.5011 - val_accuracy: 0.5200 - val_loss: 1.8148 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8935 - loss: 0.4513 - val_accuracy: 0.5200 - val_loss: 2.0364 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9146 - loss: 0.3835 - val_accuracy: 0.5200 - val_loss: 2.2267 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9024 - loss: 0.4012 - val_accuracy: 0.5200 - val_loss: 2.4550 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9117 - loss: 0.3404 - val_accuracy: 0.5200 - val_loss: 2.4783 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9289 - loss: 0.2709 - val_accuracy: 0.5200 - val_loss: 2.4848 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8793 - loss: 0.4494 - val_accuracy: 0.5200 - val_loss: 2.3863 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9409 - loss: 0.2552 - val_accuracy: 0.5200 - val_loss: 2.4248 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9409 - loss: 0.2145 - val_accuracy: 0.5400 - val_loss: 2.2290 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9402 - loss: 0.2242 - val_accuracy: 0.5200 - val_loss: 2.4424 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9626 - loss: 0.1609 - val_accuracy: 0.5200 - val_loss: 2.3470 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9244 - loss: 0.2865 - val_accuracy: 0.5200 - val_loss: 2.5185 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9250 - loss: 0.2973 - val_accuracy: 0.5600 - val_loss: 2.4441 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8876 - loss: 0.3496 - val_accuracy: 0.5600 - val_loss: 2.3566 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9517 - loss: 0.1964 - val_accuracy: 0.5600 - val_loss: 2.2915 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9552 - loss: 0.1788 - val_accuracy: 0.5600 - val_loss: 2.2637 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9368 - loss: 0.1820 - val_accuracy: 0.5600 - val_loss: 2.3212 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9696 - loss: 0.1350 - val_accuracy: 0.5800 - val_loss: 2.1252 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9548 - loss: 0.1605 - val_accuracy: 0.6000 - val_loss: 2.0810 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9533 - loss: 0.1505 - val_accuracy: 0.6000 - val_loss: 2.0750 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9782 - loss: 0.1143 - val_accuracy: 0.6000 - val_loss: 1.9399 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9282 - loss: 0.1741 - val_accuracy: 0.6000 - val_loss: 1.8713 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9670 - loss: 0.1148 - val_accuracy: 0.6000 - val_loss: 1.8328 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9481 - loss: 0.1606 - val_accuracy: 0.6000 - val_loss: 1.7685 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9648 - loss: 0.1195 - val_accuracy: 0.6600 - val_loss: 1.4976 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9800 - loss: 0.0854 - val_accuracy: 0.6600 - val_loss: 1.3414 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9844 - loss: 0.0729 - val_accuracy: 0.7200 - val_loss: 1.2238 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9813 - loss: 0.0990 - val_accuracy: 0.7400 - val_loss: 1.1206 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9815 - loss: 0.0856 - val_accuracy: 0.7400 - val_loss: 0.9861 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9863 - loss: 0.0681 - val_accuracy: 0.7800 - val_loss: 0.9193 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9885 - loss: 0.0637 - val_accuracy: 0.8200 - val_loss: 0.7410 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9831 - loss: 0.0669 - val_accuracy: 0.8600 - val_loss: 0.5392 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9814 - loss: 0.0901 - val_accuracy: 0.8800 - val_loss: 0.4816 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9867 - loss: 0.0634 - val_accuracy: 0.9000 - val_loss: 0.4274 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9873 - loss: 0.0646 - val_accuracy: 0.9000 - val_loss: 0.3960 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9918 - loss: 0.0519 - val_accuracy: 0.9000 - val_loss: 0.3600 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9879 - loss: 0.0563 - val_accuracy: 0.9200 - val_loss: 0.3093 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9802 - loss: 0.0589 - val_accuracy: 0.9200 - val_loss: 0.2617 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9860 - loss: 0.0631 - val_accuracy: 0.9200 - val_loss: 0.2500 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9463 - loss: 0.2722 - val_accuracy: 0.8600 - val_loss: 0.4143 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8429 - loss: 0.8368 - val_accuracy: 0.9400 - val_loss: 0.1550 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9150 - loss: 0.3834 - val_accuracy: 0.9600 - val_loss: 0.0897 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9503 - loss: 0.2138 - val_accuracy: 0.9800 - val_loss: 0.0891 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9704 - loss: 0.1163 - val_accuracy: 0.9800 - val_loss: 0.0864 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9578 - loss: 0.1272 - val_accuracy: 0.9800 - val_loss: 0.0901 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9829 - loss: 0.0873 - val_accuracy: 0.9800 - val_loss: 0.0938 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9743 - loss: 0.1022 - val_accuracy: 0.9800 - val_loss: 0.0895 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9788 - loss: 0.0926 - val_accuracy: 0.9800 - val_loss: 0.0864 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9825 - loss: 0.0848 - val_accuracy: 0.9600 - val_loss: 0.0856 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9879 - loss: 0.0720 - val_accuracy: 0.9600 - val_loss: 0.0842 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9960 - loss: 0.0577 - val_accuracy: 0.9600 - val_loss: 0.0844 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9907 - loss: 0.0629 - val_accuracy: 0.9600 - val_loss: 0.0859 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9826 - loss: 0.0751 - val_accuracy: 0.9600 - val_loss: 0.0883 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9782 - loss: 0.0715 - val_accuracy: 0.9400 - val_loss: 0.0958 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9956 - loss: 0.0419 - val_accuracy: 0.9400 - val_loss: 0.0992 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9963 - loss: 0.0482 - val_accuracy: 0.9400 - val_loss: 0.1086 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9816 - loss: 0.0618 - val_accuracy: 0.9400 - val_loss: 0.0983 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9632 - loss: 0.0784 - val_accuracy: 0.9400 - val_loss: 0.1262 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9731 - loss: 0.0679 - val_accuracy: 0.9600 - val_loss: 0.1974 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9908 - loss: 0.0649 - val_accuracy: 0.9600 - val_loss: 0.1597 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9894 - loss: 0.0466 - val_accuracy: 0.9600 - val_loss: 0.1378 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9905 - loss: 0.0426 - val_accuracy: 0.9800 - val_loss: 0.1200 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9831 - loss: 0.0606 - val_accuracy: 0.9600 - val_loss: 0.1189 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9876 - loss: 0.0496 - val_accuracy: 0.9600 - val_loss: 0.1262 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9881 - loss: 0.0526 - val_accuracy: 0.9400 - val_loss: 0.1933 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9836 - loss: 0.0541 - val_accuracy: 0.9400 - val_loss: 0.1881 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9880 - loss: 0.0533 - val_accuracy: 0.9200 - val_loss: 0.1411 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9853 - loss: 0.0423 - val_accuracy: 0.9200 - val_loss: 0.1269 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9869 - loss: 0.0476 - val_accuracy: 0.9200 - val_loss: 0.1151 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9942 - loss: 0.0438 - val_accuracy: 0.9600 - val_loss: 0.1018 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9952 - loss: 0.0419 - val_accuracy: 0.9400 - val_loss: 0.0935 - learning_rate: 3.1250e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9928 - loss: 0.0412 - val_accuracy: 0.9600 - val_loss: 0.0982 - learning_rate: 3.1250e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9915 - loss: 0.0484 - val_accuracy: 0.9600 - val_loss: 0.1003 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9911 - loss: 0.0468 - val_accuracy: 0.9400 - val_loss: 0.1019 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9945 - loss: 0.0392 - val_accuracy: 0.9400 - val_loss: 0.1023 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9889 - loss: 0.0543 - val_accuracy: 0.9400 - val_loss: 0.1065 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9906 - loss: 0.0413 - val_accuracy: 0.9600 - val_loss: 0.0988 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9964 - loss: 0.0384 - val_accuracy: 0.9600 - val_loss: 0.0967 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9874 - loss: 0.0484 - val_accuracy: 0.9600 - val_loss: 0.0855 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9980 - loss: 0.0433 - val_accuracy: 0.9600 - val_loss: 0.0840 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9906 - loss: 0.0413 - val_accuracy: 0.9600 - val_loss: 0.0833 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9970 - loss: 0.0379 - val_accuracy: 0.9600 - val_loss: 0.0850 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9869 - loss: 0.0484 - val_accuracy: 0.9600 - val_loss: 0.0950 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9825 - loss: 0.0593 - val_accuracy: 0.9400 - val_loss: 0.1073 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9894 - loss: 0.0414 - val_accuracy: 0.9400 - val_loss: 0.1099 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9871 - loss: 0.0550 - val_accuracy: 0.9400 - val_loss: 0.1132 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9961 - loss: 0.0318 - val_accuracy: 0.9600 - val_loss: 0.1011 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9941 - loss: 0.0421 - val_accuracy: 0.9600 - val_loss: 0.1007 - learning_rate: 3.1250e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9942 - loss: 0.0359 - val_accuracy: 0.9600 - val_loss: 0.1093 - learning_rate: 3.1250e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9955 - loss: 0.0497 - val_accuracy: 0.9400 - val_loss: 0.1691 - learning_rate: 3.1250e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9952 - loss: 0.0406 - val_accuracy: 0.9400 - val_loss: 0.1796 - learning_rate: 3.1250e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9895 - loss: 0.0566 - val_accuracy: 0.9400 - val_loss: 0.1747 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9940 - loss: 0.0357 - val_accuracy: 0.9400 - val_loss: 0.1795 - learning_rate: 1.5625e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9828 - loss: 0.0485 - val_accuracy: 0.9600 - val_loss: 0.1726 - learning_rate: 1.5625e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9872 - loss: 0.0546 - val_accuracy: 0.9600 - val_loss: 0.1588 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9735 - loss: 0.0695 - val_accuracy: 0.9400 - val_loss: 0.1387 - learning_rate: 1.5625e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step\n",
            "Fold 4 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 5/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 123ms/step - accuracy: 0.5556 - loss: 0.9910 - val_accuracy: 0.6600 - val_loss: 1.0260 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.8116 - loss: 0.6613 - val_accuracy: 0.4400 - val_loss: 1.0703 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8202 - loss: 0.6464 - val_accuracy: 0.4400 - val_loss: 1.2676 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8290 - loss: 0.4835 - val_accuracy: 0.4400 - val_loss: 1.5456 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8733 - loss: 0.4498 - val_accuracy: 0.4400 - val_loss: 1.8853 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9423 - loss: 0.3390 - val_accuracy: 0.4400 - val_loss: 2.0149 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9133 - loss: 0.3639 - val_accuracy: 0.4400 - val_loss: 2.1687 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.8389 - loss: 0.4885 - val_accuracy: 0.4400 - val_loss: 2.0798 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.8988 - loss: 0.4791 - val_accuracy: 0.4400 - val_loss: 1.9275 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9059 - loss: 0.3470 - val_accuracy: 0.4400 - val_loss: 2.0318 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9194 - loss: 0.2917 - val_accuracy: 0.4400 - val_loss: 2.3415 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9070 - loss: 0.3468 - val_accuracy: 0.4400 - val_loss: 2.2842 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9506 - loss: 0.2208 - val_accuracy: 0.4600 - val_loss: 2.3162 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9241 - loss: 0.2737 - val_accuracy: 0.4400 - val_loss: 2.5649 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9215 - loss: 0.2950 - val_accuracy: 0.4400 - val_loss: 2.5110 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9644 - loss: 0.1402 - val_accuracy: 0.4600 - val_loss: 2.4149 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9784 - loss: 0.1379 - val_accuracy: 0.4800 - val_loss: 2.4368 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9685 - loss: 0.1517 - val_accuracy: 0.4800 - val_loss: 2.4482 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.7515 - loss: 0.6235 - val_accuracy: 0.4800 - val_loss: 2.4890 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9088 - loss: 0.3422 - val_accuracy: 0.4800 - val_loss: 2.3018 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9307 - loss: 0.2610 - val_accuracy: 0.5000 - val_loss: 2.3496 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9547 - loss: 0.1866 - val_accuracy: 0.5200 - val_loss: 2.2389 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9515 - loss: 0.1812 - val_accuracy: 0.5400 - val_loss: 2.1874 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9588 - loss: 0.1751 - val_accuracy: 0.5400 - val_loss: 2.1749 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9514 - loss: 0.1649 - val_accuracy: 0.5400 - val_loss: 2.0838 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9722 - loss: 0.1159 - val_accuracy: 0.5600 - val_loss: 1.8932 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9440 - loss: 0.2060 - val_accuracy: 0.7000 - val_loss: 1.2040 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9240 - loss: 0.2727 - val_accuracy: 0.6400 - val_loss: 1.2661 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9677 - loss: 0.1865 - val_accuracy: 0.6800 - val_loss: 1.0373 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9499 - loss: 0.1624 - val_accuracy: 0.7200 - val_loss: 0.8477 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9675 - loss: 0.1313 - val_accuracy: 0.7200 - val_loss: 0.9255 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9768 - loss: 0.1193 - val_accuracy: 0.7600 - val_loss: 0.8477 - learning_rate: 2.5000e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9804 - loss: 0.0817 - val_accuracy: 0.8200 - val_loss: 0.6320 - learning_rate: 2.5000e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9679 - loss: 0.1354 - val_accuracy: 0.7600 - val_loss: 0.8242 - learning_rate: 2.5000e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9774 - loss: 0.1349 - val_accuracy: 0.8200 - val_loss: 0.5647 - learning_rate: 2.5000e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9873 - loss: 0.0807 - val_accuracy: 0.8400 - val_loss: 0.4609 - learning_rate: 2.5000e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9674 - loss: 0.1029 - val_accuracy: 0.9000 - val_loss: 0.3370 - learning_rate: 2.5000e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9805 - loss: 0.0913 - val_accuracy: 0.9200 - val_loss: 0.2871 - learning_rate: 2.5000e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9825 - loss: 0.0665 - val_accuracy: 0.9200 - val_loss: 0.2723 - learning_rate: 2.5000e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9515 - loss: 0.1338 - val_accuracy: 0.9000 - val_loss: 0.3334 - learning_rate: 2.5000e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9747 - loss: 0.0851 - val_accuracy: 0.9200 - val_loss: 0.2202 - learning_rate: 2.5000e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9812 - loss: 0.0680 - val_accuracy: 0.9200 - val_loss: 0.2024 - learning_rate: 2.5000e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9886 - loss: 0.0704 - val_accuracy: 0.9600 - val_loss: 0.1807 - learning_rate: 2.5000e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9876 - loss: 0.0584 - val_accuracy: 0.9600 - val_loss: 0.1696 - learning_rate: 2.5000e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9851 - loss: 0.0617 - val_accuracy: 0.9600 - val_loss: 0.1265 - learning_rate: 2.5000e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9958 - loss: 0.0368 - val_accuracy: 0.9800 - val_loss: 0.0642 - learning_rate: 2.5000e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9917 - loss: 0.0407 - val_accuracy: 0.9600 - val_loss: 0.1234 - learning_rate: 2.5000e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9809 - loss: 0.0799 - val_accuracy: 0.9600 - val_loss: 0.1612 - learning_rate: 2.5000e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9576 - loss: 0.1252 - val_accuracy: 0.8400 - val_loss: 0.2424 - learning_rate: 2.5000e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9597 - loss: 0.1515 - val_accuracy: 0.9400 - val_loss: 0.2044 - learning_rate: 2.5000e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9732 - loss: 0.1347 - val_accuracy: 0.9400 - val_loss: 0.1724 - learning_rate: 2.5000e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9684 - loss: 0.1071 - val_accuracy: 0.8200 - val_loss: 0.4678 - learning_rate: 2.5000e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9071 - loss: 0.2583 - val_accuracy: 0.8800 - val_loss: 0.3770 - learning_rate: 2.5000e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9311 - loss: 0.2634 - val_accuracy: 0.8600 - val_loss: 0.4350 - learning_rate: 2.5000e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9434 - loss: 0.1941 - val_accuracy: 0.9200 - val_loss: 0.2784 - learning_rate: 2.5000e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9756 - loss: 0.1018 - val_accuracy: 0.9400 - val_loss: 0.2644 - learning_rate: 2.5000e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9767 - loss: 0.0910 - val_accuracy: 0.9400 - val_loss: 0.2737 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 89ms/step - accuracy: 0.9860 - loss: 0.0805 - val_accuracy: 0.9400 - val_loss: 0.2802 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9880 - loss: 0.0602 - val_accuracy: 0.9400 - val_loss: 0.2768 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9870 - loss: 0.0622 - val_accuracy: 0.9400 - val_loss: 0.2577 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9911 - loss: 0.0566 - val_accuracy: 0.9400 - val_loss: 0.2536 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9864 - loss: 0.0588 - val_accuracy: 0.9400 - val_loss: 0.2569 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9932 - loss: 0.0409 - val_accuracy: 0.9400 - val_loss: 0.2346 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9840 - loss: 0.0491 - val_accuracy: 0.9400 - val_loss: 0.2427 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9865 - loss: 0.0593 - val_accuracy: 0.9400 - val_loss: 0.2466 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9961 - loss: 0.0428 - val_accuracy: 0.9400 - val_loss: 0.2484 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9927 - loss: 0.0381 - val_accuracy: 0.9400 - val_loss: 0.2527 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9974 - loss: 0.0296 - val_accuracy: 0.9400 - val_loss: 0.2567 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9941 - loss: 0.0348 - val_accuracy: 0.9400 - val_loss: 0.2565 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9991 - loss: 0.0277 - val_accuracy: 0.9400 - val_loss: 0.2516 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9951 - loss: 0.0379 - val_accuracy: 0.9400 - val_loss: 0.2556 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9952 - loss: 0.0304 - val_accuracy: 0.9400 - val_loss: 0.2534 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9991 - loss: 0.0223 - val_accuracy: 0.9400 - val_loss: 0.2530 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9978 - loss: 0.0297 - val_accuracy: 0.9400 - val_loss: 0.2523 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0388 - val_accuracy: 0.9400 - val_loss: 0.2514 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9954 - loss: 0.0528 - val_accuracy: 0.9400 - val_loss: 0.2586 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9967 - loss: 0.0309 - val_accuracy: 0.9400 - val_loss: 0.2584 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9954 - loss: 0.0272 - val_accuracy: 0.9400 - val_loss: 0.2406 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.9963 - loss: 0.0371 - val_accuracy: 0.9400 - val_loss: 0.2430 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9960 - loss: 0.0316 - val_accuracy: 0.9600 - val_loss: 0.2444 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9987 - loss: 0.0249 - val_accuracy: 0.9400 - val_loss: 0.2455 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9949 - loss: 0.0346 - val_accuracy: 0.9400 - val_loss: 0.2460 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 1.0000 - loss: 0.0245 - val_accuracy: 0.9400 - val_loss: 0.2467 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9946 - loss: 0.0301 - val_accuracy: 0.9400 - val_loss: 0.2473 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9994 - loss: 0.0195 - val_accuracy: 0.9400 - val_loss: 0.2471 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0275 - val_accuracy: 0.9400 - val_loss: 0.2491 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9963 - loss: 0.0254 - val_accuracy: 0.9400 - val_loss: 0.2494 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9972 - loss: 0.0227 - val_accuracy: 0.9400 - val_loss: 0.2495 - learning_rate: 1.5625e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9994 - loss: 0.0235 - val_accuracy: 0.9400 - val_loss: 0.2444 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0381 - val_accuracy: 0.9400 - val_loss: 0.2440 - learning_rate: 1.5625e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9991 - loss: 0.0259 - val_accuracy: 0.9400 - val_loss: 0.2444 - learning_rate: 1.5625e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9963 - loss: 0.0283 - val_accuracy: 0.9400 - val_loss: 0.2468 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9925 - loss: 0.0356 - val_accuracy: 0.9400 - val_loss: 0.2451 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9984 - loss: 0.0262 - val_accuracy: 0.9400 - val_loss: 0.2438 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9934 - loss: 0.0283 - val_accuracy: 0.9400 - val_loss: 0.2452 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9961 - loss: 0.0314 - val_accuracy: 0.9400 - val_loss: 0.2448 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9929 - loss: 0.0362 - val_accuracy: 0.9600 - val_loss: 0.2428 - learning_rate: 7.8125e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9930 - loss: 0.0268 - val_accuracy: 0.9600 - val_loss: 0.2433 - learning_rate: 7.8125e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9974 - loss: 0.0231 - val_accuracy: 0.9600 - val_loss: 0.2407 - learning_rate: 7.8125e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9941 - loss: 0.0255 - val_accuracy: 0.9600 - val_loss: 0.2342 - learning_rate: 7.8125e-06\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 365ms/step\n",
            "Fold 5 Accuracy: 0.9600\n",
            "\n",
            "Training Fold 6/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.4938 - loss: 0.9914 - val_accuracy: 0.2600 - val_loss: 1.0839 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.7708 - loss: 0.7465 - val_accuracy: 0.2600 - val_loss: 1.3506 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8495 - loss: 0.5863 - val_accuracy: 0.2600 - val_loss: 1.6750 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.8509 - loss: 0.5137 - val_accuracy: 0.2600 - val_loss: 2.1051 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.8304 - loss: 0.5573 - val_accuracy: 0.2600 - val_loss: 2.3922 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8860 - loss: 0.4069 - val_accuracy: 0.2600 - val_loss: 2.9910 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9318 - loss: 0.2504 - val_accuracy: 0.2600 - val_loss: 3.3867 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9180 - loss: 0.3552 - val_accuracy: 0.2600 - val_loss: 3.0400 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9130 - loss: 0.2858 - val_accuracy: 0.2600 - val_loss: 3.6019 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8529 - loss: 0.4557 - val_accuracy: 0.2600 - val_loss: 2.8820 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8684 - loss: 0.3478 - val_accuracy: 0.2600 - val_loss: 3.2355 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9358 - loss: 0.2649 - val_accuracy: 0.2600 - val_loss: 3.3657 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8590 - loss: 0.5749 - val_accuracy: 0.2600 - val_loss: 3.1450 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.8832 - loss: 0.3970 - val_accuracy: 0.2600 - val_loss: 2.8964 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 75ms/step - accuracy: 0.9051 - loss: 0.3373 - val_accuracy: 0.2600 - val_loss: 3.1052 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9402 - loss: 0.2668 - val_accuracy: 0.2600 - val_loss: 3.3809 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9181 - loss: 0.2634 - val_accuracy: 0.2600 - val_loss: 3.5278 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9681 - loss: 0.1489 - val_accuracy: 0.2600 - val_loss: 3.6628 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9727 - loss: 0.1394 - val_accuracy: 0.2600 - val_loss: 3.8671 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9344 - loss: 0.1736 - val_accuracy: 0.2600 - val_loss: 3.9968 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9704 - loss: 0.1164 - val_accuracy: 0.2600 - val_loss: 4.0706 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9875 - loss: 0.0804 - val_accuracy: 0.2600 - val_loss: 4.1067 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9729 - loss: 0.0830 - val_accuracy: 0.2600 - val_loss: 4.1174 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9784 - loss: 0.0812 - val_accuracy: 0.2600 - val_loss: 4.1235 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9865 - loss: 0.0678 - val_accuracy: 0.2600 - val_loss: 4.0868 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9862 - loss: 0.0605 - val_accuracy: 0.2600 - val_loss: 4.0886 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9782 - loss: 0.0939 - val_accuracy: 0.2600 - val_loss: 3.9841 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9883 - loss: 0.0495 - val_accuracy: 0.3000 - val_loss: 3.6781 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9719 - loss: 0.0867 - val_accuracy: 0.3200 - val_loss: 3.6155 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9885 - loss: 0.0490 - val_accuracy: 0.3600 - val_loss: 3.4367 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9648 - loss: 0.1353 - val_accuracy: 0.3800 - val_loss: 3.2345 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9769 - loss: 0.0911 - val_accuracy: 0.3800 - val_loss: 3.0986 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9808 - loss: 0.0723 - val_accuracy: 0.4800 - val_loss: 2.4927 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9911 - loss: 0.0419 - val_accuracy: 0.5800 - val_loss: 2.0749 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9763 - loss: 0.0756 - val_accuracy: 0.5600 - val_loss: 2.1174 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9847 - loss: 0.0607 - val_accuracy: 0.6400 - val_loss: 1.7381 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9902 - loss: 0.0597 - val_accuracy: 0.6800 - val_loss: 1.4060 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9926 - loss: 0.0443 - val_accuracy: 0.7600 - val_loss: 1.1654 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9912 - loss: 0.0480 - val_accuracy: 0.7600 - val_loss: 1.0422 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9927 - loss: 0.0377 - val_accuracy: 0.7600 - val_loss: 0.9149 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9928 - loss: 0.0354 - val_accuracy: 0.7800 - val_loss: 0.7915 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9958 - loss: 0.0294 - val_accuracy: 0.7800 - val_loss: 0.7049 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9932 - loss: 0.0298 - val_accuracy: 0.8000 - val_loss: 0.6066 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9987 - loss: 0.0272 - val_accuracy: 0.8200 - val_loss: 0.5949 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9857 - loss: 0.0733 - val_accuracy: 0.8000 - val_loss: 0.6585 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9977 - loss: 0.0287 - val_accuracy: 0.8600 - val_loss: 0.3879 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 0.9936 - loss: 0.0405 - val_accuracy: 0.8800 - val_loss: 0.3280 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9849 - loss: 0.0850 - val_accuracy: 0.9200 - val_loss: 0.2870 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9884 - loss: 0.0804 - val_accuracy: 0.9000 - val_loss: 0.2316 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9945 - loss: 0.0399 - val_accuracy: 0.9400 - val_loss: 0.2026 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9898 - loss: 0.0497 - val_accuracy: 0.9200 - val_loss: 0.2398 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9857 - loss: 0.0609 - val_accuracy: 0.9200 - val_loss: 0.2634 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9873 - loss: 0.0464 - val_accuracy: 0.9400 - val_loss: 0.2178 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9946 - loss: 0.0278 - val_accuracy: 0.9400 - val_loss: 0.2127 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0322 - val_accuracy: 0.9400 - val_loss: 0.2180 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9954 - loss: 0.0329 - val_accuracy: 0.9400 - val_loss: 0.2084 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0257 - val_accuracy: 0.9400 - val_loss: 0.2081 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9978 - loss: 0.0234 - val_accuracy: 0.9400 - val_loss: 0.2077 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0200 - val_accuracy: 0.9400 - val_loss: 0.2096 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.9400 - val_loss: 0.2130 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9932 - loss: 0.0292 - val_accuracy: 0.9400 - val_loss: 0.2205 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9894 - loss: 0.0329 - val_accuracy: 0.9400 - val_loss: 0.2220 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9950 - loss: 0.0228 - val_accuracy: 0.9400 - val_loss: 0.2162 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9963 - loss: 0.0364 - val_accuracy: 0.9400 - val_loss: 0.2144 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9993 - loss: 0.0181 - val_accuracy: 0.9400 - val_loss: 0.2138 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9954 - loss: 0.0287 - val_accuracy: 0.9400 - val_loss: 0.2145 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9953 - loss: 0.0223 - val_accuracy: 0.9400 - val_loss: 0.2198 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9934 - loss: 0.0213 - val_accuracy: 0.9400 - val_loss: 0.2199 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9984 - loss: 0.0210 - val_accuracy: 0.9400 - val_loss: 0.2166 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9991 - loss: 0.0169 - val_accuracy: 0.9400 - val_loss: 0.2134 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9852 - loss: 0.0300 - val_accuracy: 0.9400 - val_loss: 0.2108 - learning_rate: 3.1250e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9964 - loss: 0.0169 - val_accuracy: 0.9400 - val_loss: 0.2088 - learning_rate: 3.1250e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9994 - loss: 0.0177 - val_accuracy: 0.9200 - val_loss: 0.2102 - learning_rate: 3.1250e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9967 - loss: 0.0167 - val_accuracy: 0.9200 - val_loss: 0.2473 - learning_rate: 3.1250e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9982 - loss: 0.0196 - val_accuracy: 0.9200 - val_loss: 0.2550 - learning_rate: 3.1250e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 76ms/step - accuracy: 0.9906 - loss: 0.0578 - val_accuracy: 0.9200 - val_loss: 0.2468 - learning_rate: 3.1250e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9980 - loss: 0.0219 - val_accuracy: 0.9400 - val_loss: 0.2364 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9969 - loss: 0.0186 - val_accuracy: 0.9400 - val_loss: 0.2232 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9932 - loss: 0.0210 - val_accuracy: 0.9400 - val_loss: 0.2242 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9953 - loss: 0.0240 - val_accuracy: 0.9400 - val_loss: 0.2246 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9962 - loss: 0.0198 - val_accuracy: 0.9400 - val_loss: 0.2309 - learning_rate: 1.5625e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9953 - loss: 0.0200 - val_accuracy: 0.9400 - val_loss: 0.2278 - learning_rate: 1.5625e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9993 - loss: 0.0188 - val_accuracy: 0.9400 - val_loss: 0.2229 - learning_rate: 1.5625e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9957 - loss: 0.0316 - val_accuracy: 0.9400 - val_loss: 0.2209 - learning_rate: 1.5625e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9963 - loss: 0.0244 - val_accuracy: 0.9400 - val_loss: 0.2219 - learning_rate: 1.5625e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0160 - val_accuracy: 0.9400 - val_loss: 0.2224 - learning_rate: 1.5625e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9984 - loss: 0.0154 - val_accuracy: 0.9400 - val_loss: 0.2231 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9996 - loss: 0.0207 - val_accuracy: 0.9400 - val_loss: 0.2223 - learning_rate: 1.5625e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9931 - loss: 0.0210 - val_accuracy: 0.9400 - val_loss: 0.2229 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9992 - loss: 0.0195 - val_accuracy: 0.9400 - val_loss: 0.2243 - learning_rate: 1.5625e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9925 - loss: 0.0262 - val_accuracy: 0.9400 - val_loss: 0.2215 - learning_rate: 7.8125e-06\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9997 - loss: 0.0150 - val_accuracy: 0.9400 - val_loss: 0.2241 - learning_rate: 7.8125e-06\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9935 - loss: 0.0202 - val_accuracy: 0.9400 - val_loss: 0.2363 - learning_rate: 7.8125e-06\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0201 - val_accuracy: 0.9400 - val_loss: 0.2361 - learning_rate: 7.8125e-06\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9993 - loss: 0.0151 - val_accuracy: 0.9400 - val_loss: 0.2347 - learning_rate: 7.8125e-06\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.9400 - val_loss: 0.2341 - learning_rate: 7.8125e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9994 - loss: 0.0148 - val_accuracy: 0.9400 - val_loss: 0.2358 - learning_rate: 7.8125e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9949 - loss: 0.0245 - val_accuracy: 0.9400 - val_loss: 0.2342 - learning_rate: 7.8125e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9989 - loss: 0.0142 - val_accuracy: 0.9400 - val_loss: 0.2344 - learning_rate: 7.8125e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0127 - val_accuracy: 0.9400 - val_loss: 0.2338 - learning_rate: 7.8125e-06\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 324ms/step\n",
            "Fold 6 Accuracy: 0.9400\n",
            "\n",
            "Training Fold 7/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 140ms/step - accuracy: 0.5093 - loss: 0.9849 - val_accuracy: 0.5000 - val_loss: 1.0634 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.7402 - loss: 0.7653 - val_accuracy: 0.4400 - val_loss: 1.0977 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.7561 - loss: 0.6733 - val_accuracy: 0.4400 - val_loss: 1.3131 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8099 - loss: 0.5618 - val_accuracy: 0.4400 - val_loss: 1.7523 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.8823 - loss: 0.4460 - val_accuracy: 0.4400 - val_loss: 2.1612 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9215 - loss: 0.2864 - val_accuracy: 0.4400 - val_loss: 2.0289 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 70ms/step - accuracy: 0.8879 - loss: 0.3653 - val_accuracy: 0.4400 - val_loss: 2.4965 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9008 - loss: 0.3350 - val_accuracy: 0.4400 - val_loss: 2.3223 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9251 - loss: 0.2412 - val_accuracy: 0.4400 - val_loss: 2.1740 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9267 - loss: 0.3212 - val_accuracy: 0.4400 - val_loss: 1.8693 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9142 - loss: 0.3164 - val_accuracy: 0.4400 - val_loss: 2.1879 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9443 - loss: 0.2446 - val_accuracy: 0.4400 - val_loss: 2.4420 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9589 - loss: 0.1860 - val_accuracy: 0.4400 - val_loss: 2.7765 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9702 - loss: 0.1223 - val_accuracy: 0.4400 - val_loss: 2.8293 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9791 - loss: 0.1103 - val_accuracy: 0.4400 - val_loss: 2.5934 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9893 - loss: 0.0810 - val_accuracy: 0.4400 - val_loss: 2.8594 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9842 - loss: 0.0710 - val_accuracy: 0.4600 - val_loss: 3.0073 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9611 - loss: 0.1883 - val_accuracy: 0.4600 - val_loss: 2.6797 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9402 - loss: 0.1515 - val_accuracy: 0.4400 - val_loss: 2.7534 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9637 - loss: 0.1911 - val_accuracy: 0.4600 - val_loss: 3.0317 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9650 - loss: 0.1458 - val_accuracy: 0.4400 - val_loss: 3.5646 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9360 - loss: 0.2936 - val_accuracy: 0.4400 - val_loss: 2.9256 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9525 - loss: 0.1429 - val_accuracy: 0.4600 - val_loss: 2.5266 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9735 - loss: 0.1009 - val_accuracy: 0.4800 - val_loss: 2.5543 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9840 - loss: 0.0778 - val_accuracy: 0.4800 - val_loss: 2.6137 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9792 - loss: 0.0957 - val_accuracy: 0.5000 - val_loss: 2.3501 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9828 - loss: 0.0634 - val_accuracy: 0.5400 - val_loss: 2.1728 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9815 - loss: 0.0759 - val_accuracy: 0.6400 - val_loss: 1.7275 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9787 - loss: 0.0879 - val_accuracy: 0.6600 - val_loss: 1.2644 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9756 - loss: 0.1020 - val_accuracy: 0.6200 - val_loss: 1.3856 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9827 - loss: 0.0715 - val_accuracy: 0.6600 - val_loss: 1.2170 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9790 - loss: 0.0629 - val_accuracy: 0.7200 - val_loss: 1.0190 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9717 - loss: 0.0765 - val_accuracy: 0.7400 - val_loss: 0.7889 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9973 - loss: 0.0417 - val_accuracy: 0.8200 - val_loss: 0.6581 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9976 - loss: 0.0421 - val_accuracy: 0.8400 - val_loss: 0.4638 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9964 - loss: 0.0370 - val_accuracy: 0.8600 - val_loss: 0.3497 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9886 - loss: 0.0516 - val_accuracy: 0.8800 - val_loss: 0.3506 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9953 - loss: 0.0370 - val_accuracy: 0.9000 - val_loss: 0.3432 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0294 - val_accuracy: 0.9000 - val_loss: 0.3218 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9955 - loss: 0.0387 - val_accuracy: 0.9000 - val_loss: 0.3157 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9908 - loss: 0.0430 - val_accuracy: 0.9000 - val_loss: 0.3187 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9881 - loss: 0.0411 - val_accuracy: 0.9200 - val_loss: 0.3361 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9950 - loss: 0.0337 - val_accuracy: 0.9200 - val_loss: 0.3219 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9877 - loss: 0.0563 - val_accuracy: 0.9200 - val_loss: 0.3148 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.9914 - loss: 0.0363 - val_accuracy: 0.9200 - val_loss: 0.2592 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9993 - loss: 0.0288 - val_accuracy: 0.9200 - val_loss: 0.2196 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9963 - loss: 0.0261 - val_accuracy: 0.9200 - val_loss: 0.2222 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9973 - loss: 0.0262 - val_accuracy: 0.9200 - val_loss: 0.2157 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9972 - loss: 0.0237 - val_accuracy: 0.9400 - val_loss: 0.1985 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9934 - loss: 0.0304 - val_accuracy: 0.9400 - val_loss: 0.1865 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9987 - loss: 0.0214 - val_accuracy: 0.9400 - val_loss: 0.1734 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9988 - loss: 0.0193 - val_accuracy: 0.9400 - val_loss: 0.1574 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0262 - val_accuracy: 0.9600 - val_loss: 0.1267 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9991 - loss: 0.0232 - val_accuracy: 0.9400 - val_loss: 0.1311 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9916 - loss: 0.0331 - val_accuracy: 0.9400 - val_loss: 0.1469 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9989 - loss: 0.0186 - val_accuracy: 0.9400 - val_loss: 0.1403 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9959 - loss: 0.0247 - val_accuracy: 0.9600 - val_loss: 0.1131 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9873 - loss: 0.0383 - val_accuracy: 0.9200 - val_loss: 0.2556 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9936 - loss: 0.0255 - val_accuracy: 0.9400 - val_loss: 0.1812 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9973 - loss: 0.0207 - val_accuracy: 0.9400 - val_loss: 0.1900 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9837 - loss: 0.0561 - val_accuracy: 0.8800 - val_loss: 0.5016 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9720 - loss: 0.0914 - val_accuracy: 0.9200 - val_loss: 0.2473 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9887 - loss: 0.0420 - val_accuracy: 0.9800 - val_loss: 0.0695 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9804 - loss: 0.0575 - val_accuracy: 0.9600 - val_loss: 0.1508 - learning_rate: 1.2500e-04\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9887 - loss: 0.0372 - val_accuracy: 0.9400 - val_loss: 0.1803 - learning_rate: 1.2500e-04\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9987 - loss: 0.0215 - val_accuracy: 0.9400 - val_loss: 0.1758 - learning_rate: 1.2500e-04\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9906 - loss: 0.0344 - val_accuracy: 0.9400 - val_loss: 0.1801 - learning_rate: 1.2500e-04\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0203 - val_accuracy: 0.9400 - val_loss: 0.1768 - learning_rate: 1.2500e-04\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9991 - loss: 0.0200 - val_accuracy: 0.9400 - val_loss: 0.1891 - learning_rate: 1.2500e-04\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9982 - loss: 0.0207 - val_accuracy: 0.9400 - val_loss: 0.1785 - learning_rate: 1.2500e-04\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9996 - loss: 0.0191 - val_accuracy: 0.9400 - val_loss: 0.1681 - learning_rate: 1.2500e-04\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9400 - val_loss: 0.1592 - learning_rate: 1.2500e-04\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9974 - loss: 0.0207 - val_accuracy: 0.9400 - val_loss: 0.1653 - learning_rate: 1.2500e-04\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9972 - loss: 0.0176 - val_accuracy: 0.9400 - val_loss: 0.1708 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0179 - val_accuracy: 0.9400 - val_loss: 0.1830 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.9400 - val_loss: 0.1885 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0158 - val_accuracy: 0.9400 - val_loss: 0.1926 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9400 - val_loss: 0.1811 - learning_rate: 6.2500e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9990 - loss: 0.0152 - val_accuracy: 0.9400 - val_loss: 0.1889 - learning_rate: 6.2500e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9200 - val_loss: 0.2873 - learning_rate: 6.2500e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9967 - loss: 0.0235 - val_accuracy: 0.9200 - val_loss: 0.2604 - learning_rate: 6.2500e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9970 - loss: 0.0144 - val_accuracy: 0.9400 - val_loss: 0.2253 - learning_rate: 6.2500e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9916 - loss: 0.0475 - val_accuracy: 0.9200 - val_loss: 0.3879 - learning_rate: 6.2500e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9763 - loss: 0.1743 - val_accuracy: 0.9200 - val_loss: 0.3700 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9677 - loss: 0.1791 - val_accuracy: 0.9200 - val_loss: 0.3473 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9912 - loss: 0.0632 - val_accuracy: 0.9200 - val_loss: 0.3348 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9922 - loss: 0.0965 - val_accuracy: 0.9200 - val_loss: 0.3341 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9987 - loss: 0.0276 - val_accuracy: 0.9200 - val_loss: 0.3285 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9941 - loss: 0.0417 - val_accuracy: 0.9200 - val_loss: 0.3221 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9984 - loss: 0.0226 - val_accuracy: 0.9400 - val_loss: 0.2830 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9871 - loss: 0.0729 - val_accuracy: 0.9200 - val_loss: 0.2865 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9873 - loss: 0.0899 - val_accuracy: 0.9200 - val_loss: 0.2941 - learning_rate: 3.1250e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9964 - loss: 0.0350 - val_accuracy: 0.9200 - val_loss: 0.3054 - learning_rate: 3.1250e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0254 - val_accuracy: 0.9200 - val_loss: 0.3068 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9982 - loss: 0.0193 - val_accuracy: 0.9200 - val_loss: 0.3033 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9953 - loss: 0.0321 - val_accuracy: 0.9200 - val_loss: 0.3068 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9965 - loss: 0.0323 - val_accuracy: 0.9200 - val_loss: 0.3089 - learning_rate: 1.5625e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9993 - loss: 0.0209 - val_accuracy: 0.9200 - val_loss: 0.3118 - learning_rate: 1.5625e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0143 - val_accuracy: 0.9200 - val_loss: 0.3105 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9993 - loss: 0.0170 - val_accuracy: 0.9200 - val_loss: 0.3125 - learning_rate: 1.5625e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 447ms/step\n",
            "Fold 7 Accuracy: 0.9200\n",
            "\n",
            "Training Fold 8/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.5216 - loss: 0.9777 - val_accuracy: 0.4200 - val_loss: 1.0670 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 79ms/step - accuracy: 0.7206 - loss: 0.7502 - val_accuracy: 0.3600 - val_loss: 1.3779 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8137 - loss: 0.6429 - val_accuracy: 0.3600 - val_loss: 1.7396 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8809 - loss: 0.3967 - val_accuracy: 0.3600 - val_loss: 2.1591 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8710 - loss: 0.4503 - val_accuracy: 0.3600 - val_loss: 2.5513 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.8777 - loss: 0.3384 - val_accuracy: 0.3600 - val_loss: 2.6666 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.7725 - loss: 0.4705 - val_accuracy: 0.3600 - val_loss: 2.7507 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9172 - loss: 0.3103 - val_accuracy: 0.3600 - val_loss: 3.0527 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9018 - loss: 0.3427 - val_accuracy: 0.3800 - val_loss: 2.7064 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8614 - loss: 0.4514 - val_accuracy: 0.2400 - val_loss: 2.4927 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9044 - loss: 0.3174 - val_accuracy: 0.3600 - val_loss: 3.1437 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9460 - loss: 0.2287 - val_accuracy: 0.3600 - val_loss: 3.0189 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8980 - loss: 0.2593 - val_accuracy: 0.3600 - val_loss: 3.3069 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9479 - loss: 0.1845 - val_accuracy: 0.3600 - val_loss: 3.3641 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9443 - loss: 0.2325 - val_accuracy: 0.3600 - val_loss: 3.2078 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9205 - loss: 0.2879 - val_accuracy: 0.3600 - val_loss: 3.1244 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9400 - loss: 0.2009 - val_accuracy: 0.1600 - val_loss: 3.0579 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.7463 - loss: 0.5449 - val_accuracy: 0.3600 - val_loss: 3.1449 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9110 - loss: 0.2923 - val_accuracy: 0.4000 - val_loss: 3.1413 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9621 - loss: 0.1586 - val_accuracy: 0.4000 - val_loss: 3.2891 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9548 - loss: 0.1585 - val_accuracy: 0.4000 - val_loss: 3.2419 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9541 - loss: 0.1738 - val_accuracy: 0.4200 - val_loss: 3.1396 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9534 - loss: 0.1421 - val_accuracy: 0.4200 - val_loss: 3.1656 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9682 - loss: 0.1055 - val_accuracy: 0.4200 - val_loss: 3.2210 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9825 - loss: 0.0970 - val_accuracy: 0.4200 - val_loss: 3.1613 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 85ms/step - accuracy: 0.9791 - loss: 0.0681 - val_accuracy: 0.4400 - val_loss: 3.0094 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9784 - loss: 0.0845 - val_accuracy: 0.4600 - val_loss: 2.7475 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9742 - loss: 0.1044 - val_accuracy: 0.4800 - val_loss: 2.5710 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9761 - loss: 0.0808 - val_accuracy: 0.5000 - val_loss: 2.2172 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9856 - loss: 0.0673 - val_accuracy: 0.5200 - val_loss: 1.9501 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9848 - loss: 0.0696 - val_accuracy: 0.6200 - val_loss: 1.6558 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9850 - loss: 0.0609 - val_accuracy: 0.6400 - val_loss: 1.3438 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9905 - loss: 0.0448 - val_accuracy: 0.6600 - val_loss: 1.0645 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9948 - loss: 0.0528 - val_accuracy: 0.8000 - val_loss: 0.7563 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9828 - loss: 0.0673 - val_accuracy: 0.7800 - val_loss: 0.9153 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9735 - loss: 0.1088 - val_accuracy: 0.8200 - val_loss: 0.8014 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 92ms/step - accuracy: 0.9903 - loss: 0.0653 - val_accuracy: 0.8200 - val_loss: 0.7356 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9885 - loss: 0.0647 - val_accuracy: 0.8400 - val_loss: 0.6645 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9818 - loss: 0.0544 - val_accuracy: 0.8800 - val_loss: 0.4785 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9801 - loss: 0.0908 - val_accuracy: 0.8800 - val_loss: 0.4940 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9953 - loss: 0.0442 - val_accuracy: 0.9000 - val_loss: 0.4239 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9835 - loss: 0.0571 - val_accuracy: 0.9000 - val_loss: 0.4050 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9930 - loss: 0.0486 - val_accuracy: 0.9000 - val_loss: 0.3245 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9947 - loss: 0.0352 - val_accuracy: 0.8600 - val_loss: 0.3566 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9925 - loss: 0.0500 - val_accuracy: 0.9000 - val_loss: 0.2807 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9971 - loss: 0.0447 - val_accuracy: 0.9200 - val_loss: 0.2578 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9879 - loss: 0.0417 - val_accuracy: 0.9200 - val_loss: 0.2471 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9950 - loss: 0.0402 - val_accuracy: 0.9200 - val_loss: 0.2520 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9877 - loss: 0.0425 - val_accuracy: 0.8800 - val_loss: 0.3452 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9987 - loss: 0.0326 - val_accuracy: 0.9000 - val_loss: 0.2967 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9982 - loss: 0.0317 - val_accuracy: 0.9400 - val_loss: 0.1988 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9956 - loss: 0.0376 - val_accuracy: 0.9400 - val_loss: 0.1849 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9974 - loss: 0.0251 - val_accuracy: 0.9400 - val_loss: 0.1693 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9980 - loss: 0.0264 - val_accuracy: 0.9400 - val_loss: 0.1743 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9907 - loss: 0.0455 - val_accuracy: 0.9200 - val_loss: 0.2787 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 77ms/step - accuracy: 0.9941 - loss: 0.0381 - val_accuracy: 0.9200 - val_loss: 0.2667 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9898 - loss: 0.0484 - val_accuracy: 0.9400 - val_loss: 0.2300 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9911 - loss: 0.0323 - val_accuracy: 0.9400 - val_loss: 0.2065 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9967 - loss: 0.0265 - val_accuracy: 0.9400 - val_loss: 0.2084 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9925 - loss: 0.0354 - val_accuracy: 0.9200 - val_loss: 0.2607 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0254 - val_accuracy: 0.9200 - val_loss: 0.2382 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9933 - loss: 0.0306 - val_accuracy: 0.9400 - val_loss: 0.1786 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9938 - loss: 0.0218 - val_accuracy: 0.9400 - val_loss: 0.1721 - learning_rate: 1.2500e-04\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9959 - loss: 0.0273 - val_accuracy: 0.9400 - val_loss: 0.1771 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 80ms/step - accuracy: 0.9942 - loss: 0.0256 - val_accuracy: 0.9400 - val_loss: 0.1824 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9978 - loss: 0.0208 - val_accuracy: 0.9200 - val_loss: 0.2337 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0216 - val_accuracy: 0.9200 - val_loss: 0.2333 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9993 - loss: 0.0193 - val_accuracy: 0.9400 - val_loss: 0.2197 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9837 - loss: 0.0459 - val_accuracy: 0.9400 - val_loss: 0.2074 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9906 - loss: 0.0268 - val_accuracy: 0.9400 - val_loss: 0.1959 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9965 - loss: 0.0257 - val_accuracy: 0.9400 - val_loss: 0.1905 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9957 - loss: 0.0336 - val_accuracy: 0.9400 - val_loss: 0.1927 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9400 - val_loss: 0.1963 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.9400 - val_loss: 0.1976 - learning_rate: 3.1250e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 84ms/step - accuracy: 0.9987 - loss: 0.0203 - val_accuracy: 0.9400 - val_loss: 0.1956 - learning_rate: 3.1250e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9974 - loss: 0.0195 - val_accuracy: 0.9400 - val_loss: 0.1973 - learning_rate: 3.1250e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0206 - val_accuracy: 0.9400 - val_loss: 0.1979 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9953 - loss: 0.0174 - val_accuracy: 0.9400 - val_loss: 0.1980 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9996 - loss: 0.0243 - val_accuracy: 0.9400 - val_loss: 0.1981 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9990 - loss: 0.0164 - val_accuracy: 0.9400 - val_loss: 0.1957 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9970 - loss: 0.0190 - val_accuracy: 0.9600 - val_loss: 0.1595 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9967 - loss: 0.0246 - val_accuracy: 0.9600 - val_loss: 0.1595 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9980 - loss: 0.0197 - val_accuracy: 0.9600 - val_loss: 0.1696 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9957 - loss: 0.0238 - val_accuracy: 0.9200 - val_loss: 0.2495 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9940 - loss: 0.0237 - val_accuracy: 0.9200 - val_loss: 0.3094 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9934 - loss: 0.0246 - val_accuracy: 0.9000 - val_loss: 0.3590 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9943 - loss: 0.0208 - val_accuracy: 0.9000 - val_loss: 0.3491 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9931 - loss: 0.0330 - val_accuracy: 0.9000 - val_loss: 0.3256 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9926 - loss: 0.0267 - val_accuracy: 0.9200 - val_loss: 0.3131 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9970 - loss: 0.0189 - val_accuracy: 0.9200 - val_loss: 0.2908 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9887 - loss: 0.0293 - val_accuracy: 0.9200 - val_loss: 0.2707 - learning_rate: 3.1250e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9941 - loss: 0.0203 - val_accuracy: 0.9200 - val_loss: 0.2667 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9991 - loss: 0.0200 - val_accuracy: 0.9200 - val_loss: 0.2885 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9970 - loss: 0.0227 - val_accuracy: 0.9200 - val_loss: 0.2897 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9934 - loss: 0.0261 - val_accuracy: 0.9200 - val_loss: 0.2920 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9920 - loss: 0.0276 - val_accuracy: 0.9200 - val_loss: 0.2882 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 0.9912 - loss: 0.0248 - val_accuracy: 0.9200 - val_loss: 0.2780 - learning_rate: 1.5625e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9865 - loss: 0.0319 - val_accuracy: 0.9200 - val_loss: 0.2839 - learning_rate: 1.5625e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0207 - val_accuracy: 0.9200 - val_loss: 0.2675 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9935 - loss: 0.0209 - val_accuracy: 0.9200 - val_loss: 0.2655 - learning_rate: 1.5625e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 336ms/step\n",
            "Fold 8 Accuracy: 0.9200\n",
            "\n",
            "Training Fold 9/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 147ms/step - accuracy: 0.4315 - loss: 1.0092 - val_accuracy: 0.3800 - val_loss: 1.0798 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.7709 - loss: 0.6718 - val_accuracy: 0.3200 - val_loss: 1.2374 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8264 - loss: 0.5949 - val_accuracy: 0.3200 - val_loss: 1.2900 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8436 - loss: 0.4927 - val_accuracy: 0.3200 - val_loss: 1.3507 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9140 - loss: 0.3487 - val_accuracy: 0.3000 - val_loss: 1.5673 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9246 - loss: 0.2830 - val_accuracy: 0.3000 - val_loss: 1.8953 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9196 - loss: 0.2201 - val_accuracy: 0.3000 - val_loss: 2.4017 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9410 - loss: 0.2184 - val_accuracy: 0.3000 - val_loss: 2.6209 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9554 - loss: 0.1790 - val_accuracy: 0.3200 - val_loss: 2.7493 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9456 - loss: 0.2299 - val_accuracy: 0.3200 - val_loss: 3.0456 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9670 - loss: 0.1431 - val_accuracy: 0.3000 - val_loss: 3.4656 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 0.9119 - loss: 0.3364 - val_accuracy: 0.3000 - val_loss: 3.0922 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9507 - loss: 0.1872 - val_accuracy: 0.3000 - val_loss: 3.1218 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9432 - loss: 0.1494 - val_accuracy: 0.3000 - val_loss: 3.3846 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9482 - loss: 0.1927 - val_accuracy: 0.3200 - val_loss: 3.3163 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9620 - loss: 0.0962 - val_accuracy: 0.3200 - val_loss: 3.4085 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9628 - loss: 0.1019 - val_accuracy: 0.3600 - val_loss: 3.2230 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9617 - loss: 0.0987 - val_accuracy: 0.3600 - val_loss: 3.3765 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9784 - loss: 0.0981 - val_accuracy: 0.3200 - val_loss: 3.5599 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9753 - loss: 0.0930 - val_accuracy: 0.3200 - val_loss: 3.3585 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9182 - loss: 0.2419 - val_accuracy: 0.3400 - val_loss: 3.6110 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9392 - loss: 0.2612 - val_accuracy: 0.3600 - val_loss: 3.1685 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 87ms/step - accuracy: 0.9496 - loss: 0.1599 - val_accuracy: 0.4000 - val_loss: 2.8235 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9644 - loss: 0.1425 - val_accuracy: 0.3800 - val_loss: 2.7521 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9278 - loss: 0.2196 - val_accuracy: 0.4000 - val_loss: 2.7884 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9878 - loss: 0.0589 - val_accuracy: 0.4200 - val_loss: 2.6390 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9820 - loss: 0.0768 - val_accuracy: 0.4400 - val_loss: 2.3419 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9686 - loss: 0.0651 - val_accuracy: 0.4600 - val_loss: 2.3591 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9817 - loss: 0.0637 - val_accuracy: 0.5800 - val_loss: 1.8496 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9840 - loss: 0.0612 - val_accuracy: 0.7200 - val_loss: 1.3126 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 79ms/step - accuracy: 0.9725 - loss: 0.0804 - val_accuracy: 0.7200 - val_loss: 1.2869 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 84ms/step - accuracy: 0.9824 - loss: 0.0737 - val_accuracy: 0.7400 - val_loss: 1.1950 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9921 - loss: 0.0567 - val_accuracy: 0.7400 - val_loss: 1.1728 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9698 - loss: 0.0945 - val_accuracy: 0.7200 - val_loss: 1.3263 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9820 - loss: 0.0780 - val_accuracy: 0.8000 - val_loss: 1.0930 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9950 - loss: 0.0424 - val_accuracy: 0.8200 - val_loss: 0.8140 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9954 - loss: 0.0286 - val_accuracy: 0.8200 - val_loss: 0.7129 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9932 - loss: 0.0345 - val_accuracy: 0.8400 - val_loss: 0.6431 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9980 - loss: 0.0339 - val_accuracy: 0.8600 - val_loss: 0.5719 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9850 - loss: 0.0516 - val_accuracy: 0.8600 - val_loss: 0.5097 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9961 - loss: 0.0409 - val_accuracy: 0.8800 - val_loss: 0.4764 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9937 - loss: 0.0333 - val_accuracy: 0.8800 - val_loss: 0.4688 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 83ms/step - accuracy: 0.9898 - loss: 0.0491 - val_accuracy: 0.8600 - val_loss: 0.5580 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 0.9866 - loss: 0.0842 - val_accuracy: 0.8600 - val_loss: 0.5081 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9838 - loss: 0.0504 - val_accuracy: 0.8200 - val_loss: 0.5685 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9863 - loss: 0.0399 - val_accuracy: 0.9000 - val_loss: 0.4346 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9896 - loss: 0.0418 - val_accuracy: 0.8600 - val_loss: 0.4516 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9767 - loss: 0.1173 - val_accuracy: 0.8800 - val_loss: 0.4608 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9821 - loss: 0.1038 - val_accuracy: 0.9000 - val_loss: 0.3969 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9865 - loss: 0.0870 - val_accuracy: 0.8800 - val_loss: 0.3236 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9963 - loss: 0.0297 - val_accuracy: 0.9400 - val_loss: 0.2157 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9959 - loss: 0.0310 - val_accuracy: 0.9200 - val_loss: 0.1971 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 82ms/step - accuracy: 0.9970 - loss: 0.0266 - val_accuracy: 0.9400 - val_loss: 0.2013 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.9950 - loss: 0.0275 - val_accuracy: 0.9400 - val_loss: 0.1996 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9965 - loss: 0.0235 - val_accuracy: 0.9400 - val_loss: 0.1992 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9983 - loss: 0.0212 - val_accuracy: 0.9400 - val_loss: 0.1998 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 0.9929 - loss: 0.0248 - val_accuracy: 0.9400 - val_loss: 0.2067 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9953 - loss: 0.0255 - val_accuracy: 0.9400 - val_loss: 0.2144 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9970 - loss: 0.0261 - val_accuracy: 0.9400 - val_loss: 0.2031 - learning_rate: 1.2500e-04\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9962 - loss: 0.0240 - val_accuracy: 0.9400 - val_loss: 0.2033 - learning_rate: 1.2500e-04\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9977 - loss: 0.0173 - val_accuracy: 0.9400 - val_loss: 0.2071 - learning_rate: 1.2500e-04\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9994 - loss: 0.0161 - val_accuracy: 0.9400 - val_loss: 0.2011 - learning_rate: 1.2500e-04\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9925 - loss: 0.0239 - val_accuracy: 0.9400 - val_loss: 0.2015 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 0.9951 - loss: 0.0198 - val_accuracy: 0.9400 - val_loss: 0.2058 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9984 - loss: 0.0218 - val_accuracy: 0.9400 - val_loss: 0.2008 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9967 - loss: 0.0172 - val_accuracy: 0.9400 - val_loss: 0.1963 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9978 - loss: 0.0175 - val_accuracy: 0.9400 - val_loss: 0.2140 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9997 - loss: 0.0207 - val_accuracy: 0.9400 - val_loss: 0.2118 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0150 - val_accuracy: 0.9400 - val_loss: 0.1632 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9980 - loss: 0.0131 - val_accuracy: 0.9400 - val_loss: 0.1522 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9976 - loss: 0.0217 - val_accuracy: 0.9400 - val_loss: 0.1625 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9400 - val_loss: 0.1633 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9987 - loss: 0.0153 - val_accuracy: 0.9400 - val_loss: 0.1660 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9908 - loss: 0.0311 - val_accuracy: 0.9400 - val_loss: 0.1859 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.9976 - loss: 0.0162 - val_accuracy: 0.9400 - val_loss: 0.1922 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9943 - loss: 0.0214 - val_accuracy: 0.9400 - val_loss: 0.1864 - learning_rate: 6.2500e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9934 - loss: 0.0246 - val_accuracy: 0.9000 - val_loss: 0.2289 - learning_rate: 6.2500e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9948 - loss: 0.0234 - val_accuracy: 0.9200 - val_loss: 0.2119 - learning_rate: 6.2500e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9934 - loss: 0.0189 - val_accuracy: 0.9200 - val_loss: 0.1890 - learning_rate: 6.2500e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0181 - val_accuracy: 0.9400 - val_loss: 0.1776 - learning_rate: 6.2500e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9979 - loss: 0.0162 - val_accuracy: 0.9600 - val_loss: 0.1735 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9993 - loss: 0.0141 - val_accuracy: 0.9600 - val_loss: 0.1775 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9934 - loss: 0.0197 - val_accuracy: 0.9600 - val_loss: 0.1889 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 90ms/step - accuracy: 0.9982 - loss: 0.0198 - val_accuracy: 0.9600 - val_loss: 0.1904 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0180 - val_accuracy: 0.9600 - val_loss: 0.1895 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0124 - val_accuracy: 0.9600 - val_loss: 0.1856 - learning_rate: 3.1250e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9950 - loss: 0.0163 - val_accuracy: 0.9600 - val_loss: 0.1842 - learning_rate: 3.1250e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0149 - val_accuracy: 0.9600 - val_loss: 0.1883 - learning_rate: 3.1250e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9934 - loss: 0.0254 - val_accuracy: 0.9600 - val_loss: 0.1912 - learning_rate: 3.1250e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9934 - loss: 0.0249 - val_accuracy: 0.9600 - val_loss: 0.1909 - learning_rate: 3.1250e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9992 - loss: 0.0108 - val_accuracy: 0.9600 - val_loss: 0.1915 - learning_rate: 1.5625e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0142 - val_accuracy: 0.9600 - val_loss: 0.1876 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 1.0000 - loss: 0.0145 - val_accuracy: 0.9600 - val_loss: 0.1890 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 85ms/step - accuracy: 1.0000 - loss: 0.0144 - val_accuracy: 0.9600 - val_loss: 0.1894 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9987 - loss: 0.0251 - val_accuracy: 0.9600 - val_loss: 0.1883 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9953 - loss: 0.0179 - val_accuracy: 0.9600 - val_loss: 0.1874 - learning_rate: 1.5625e-05\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0188 - val_accuracy: 0.9600 - val_loss: 0.1870 - learning_rate: 1.5625e-05\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9600 - val_loss: 0.1870 - learning_rate: 1.5625e-05\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0194 - val_accuracy: 0.9600 - val_loss: 0.1868 - learning_rate: 1.5625e-05\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0147 - val_accuracy: 0.9600 - val_loss: 0.1866 - learning_rate: 1.5625e-05\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 334ms/step\n",
            "Fold 9 Accuracy: 0.9600\n",
            "\n",
            "Training Fold 10/10...\n",
            "Epoch 1/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 142ms/step - accuracy: 0.3656 - loss: 1.0449 - val_accuracy: 0.5000 - val_loss: 1.0497 - learning_rate: 0.0010\n",
            "Epoch 2/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.6579 - loss: 0.8518 - val_accuracy: 0.4400 - val_loss: 1.1407 - learning_rate: 0.0010\n",
            "Epoch 3/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.7779 - loss: 0.7060 - val_accuracy: 0.4400 - val_loss: 1.4033 - learning_rate: 0.0010\n",
            "Epoch 4/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8546 - loss: 0.5128 - val_accuracy: 0.4400 - val_loss: 1.4808 - learning_rate: 0.0010\n",
            "Epoch 5/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8632 - loss: 0.4632 - val_accuracy: 0.4400 - val_loss: 1.9435 - learning_rate: 0.0010\n",
            "Epoch 6/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8838 - loss: 0.4713 - val_accuracy: 0.4400 - val_loss: 2.1271 - learning_rate: 0.0010\n",
            "Epoch 7/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.8722 - loss: 0.5008 - val_accuracy: 0.4400 - val_loss: 2.0861 - learning_rate: 0.0010\n",
            "Epoch 8/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.8868 - loss: 0.4055 - val_accuracy: 0.4400 - val_loss: 2.1603 - learning_rate: 0.0010\n",
            "Epoch 9/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.8800 - loss: 0.3346 - val_accuracy: 0.4400 - val_loss: 2.1872 - learning_rate: 0.0010\n",
            "Epoch 10/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 80ms/step - accuracy: 0.8594 - loss: 0.3658 - val_accuracy: 0.4400 - val_loss: 2.1309 - learning_rate: 0.0010\n",
            "Epoch 11/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 0.9252 - loss: 0.2697 - val_accuracy: 0.4400 - val_loss: 2.3441 - learning_rate: 0.0010\n",
            "Epoch 12/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9467 - loss: 0.2062 - val_accuracy: 0.4400 - val_loss: 2.4831 - learning_rate: 5.0000e-04\n",
            "Epoch 13/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9472 - loss: 0.2054 - val_accuracy: 0.4400 - val_loss: 2.5429 - learning_rate: 5.0000e-04\n",
            "Epoch 14/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9273 - loss: 0.2066 - val_accuracy: 0.4400 - val_loss: 2.5811 - learning_rate: 5.0000e-04\n",
            "Epoch 15/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9040 - loss: 0.4217 - val_accuracy: 0.4400 - val_loss: 2.4914 - learning_rate: 5.0000e-04\n",
            "Epoch 16/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9177 - loss: 0.2582 - val_accuracy: 0.4400 - val_loss: 2.4366 - learning_rate: 5.0000e-04\n",
            "Epoch 17/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9608 - loss: 0.1554 - val_accuracy: 0.4400 - val_loss: 2.5260 - learning_rate: 5.0000e-04\n",
            "Epoch 18/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9684 - loss: 0.1298 - val_accuracy: 0.4400 - val_loss: 2.6107 - learning_rate: 5.0000e-04\n",
            "Epoch 19/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9762 - loss: 0.1222 - val_accuracy: 0.4400 - val_loss: 2.8089 - learning_rate: 5.0000e-04\n",
            "Epoch 20/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 91ms/step - accuracy: 0.9718 - loss: 0.1056 - val_accuracy: 0.4400 - val_loss: 2.8690 - learning_rate: 5.0000e-04\n",
            "Epoch 21/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9751 - loss: 0.0937 - val_accuracy: 0.4400 - val_loss: 3.0111 - learning_rate: 5.0000e-04\n",
            "Epoch 22/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9825 - loss: 0.0614 - val_accuracy: 0.4400 - val_loss: 3.0339 - learning_rate: 2.5000e-04\n",
            "Epoch 23/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9817 - loss: 0.0815 - val_accuracy: 0.4400 - val_loss: 3.0481 - learning_rate: 2.5000e-04\n",
            "Epoch 24/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9909 - loss: 0.0630 - val_accuracy: 0.4400 - val_loss: 2.9733 - learning_rate: 2.5000e-04\n",
            "Epoch 25/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9894 - loss: 0.0605 - val_accuracy: 0.4600 - val_loss: 2.8424 - learning_rate: 2.5000e-04\n",
            "Epoch 26/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9944 - loss: 0.0431 - val_accuracy: 0.4800 - val_loss: 2.7395 - learning_rate: 2.5000e-04\n",
            "Epoch 27/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9930 - loss: 0.0418 - val_accuracy: 0.5000 - val_loss: 2.5569 - learning_rate: 2.5000e-04\n",
            "Epoch 28/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9987 - loss: 0.0314 - val_accuracy: 0.5000 - val_loss: 2.4638 - learning_rate: 2.5000e-04\n",
            "Epoch 29/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 78ms/step - accuracy: 0.9886 - loss: 0.0571 - val_accuracy: 0.5400 - val_loss: 2.2789 - learning_rate: 2.5000e-04\n",
            "Epoch 30/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9895 - loss: 0.0476 - val_accuracy: 0.6000 - val_loss: 2.0617 - learning_rate: 2.5000e-04\n",
            "Epoch 31/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9914 - loss: 0.0412 - val_accuracy: 0.6400 - val_loss: 1.8492 - learning_rate: 2.5000e-04\n",
            "Epoch 32/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 81ms/step - accuracy: 0.9955 - loss: 0.0335 - val_accuracy: 0.6800 - val_loss: 1.6472 - learning_rate: 1.2500e-04\n",
            "Epoch 33/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9987 - loss: 0.0278 - val_accuracy: 0.7400 - val_loss: 1.4642 - learning_rate: 1.2500e-04\n",
            "Epoch 34/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9839 - loss: 0.0738 - val_accuracy: 0.7800 - val_loss: 1.2592 - learning_rate: 1.2500e-04\n",
            "Epoch 35/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9988 - loss: 0.0284 - val_accuracy: 0.8000 - val_loss: 1.1283 - learning_rate: 1.2500e-04\n",
            "Epoch 36/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 0.9994 - loss: 0.0250 - val_accuracy: 0.7800 - val_loss: 1.0898 - learning_rate: 1.2500e-04\n",
            "Epoch 37/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9978 - loss: 0.0318 - val_accuracy: 0.8400 - val_loss: 0.7594 - learning_rate: 1.2500e-04\n",
            "Epoch 38/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9978 - loss: 0.0277 - val_accuracy: 0.8600 - val_loss: 0.6392 - learning_rate: 1.2500e-04\n",
            "Epoch 39/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9743 - loss: 0.0708 - val_accuracy: 0.8800 - val_loss: 0.5446 - learning_rate: 1.2500e-04\n",
            "Epoch 40/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9673 - loss: 0.0829 - val_accuracy: 0.9000 - val_loss: 0.5216 - learning_rate: 1.2500e-04\n",
            "Epoch 41/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 0.9987 - loss: 0.0271 - val_accuracy: 0.9200 - val_loss: 0.4879 - learning_rate: 1.2500e-04\n",
            "Epoch 42/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 93ms/step - accuracy: 0.9930 - loss: 0.0361 - val_accuracy: 0.9200 - val_loss: 0.4620 - learning_rate: 1.2500e-04\n",
            "Epoch 43/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9951 - loss: 0.0288 - val_accuracy: 0.9400 - val_loss: 0.3923 - learning_rate: 1.2500e-04\n",
            "Epoch 44/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0282 - val_accuracy: 0.9600 - val_loss: 0.2869 - learning_rate: 1.2500e-04\n",
            "Epoch 45/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9968 - loss: 0.0199 - val_accuracy: 0.9600 - val_loss: 0.2820 - learning_rate: 1.2500e-04\n",
            "Epoch 46/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9954 - loss: 0.0281 - val_accuracy: 0.9600 - val_loss: 0.2793 - learning_rate: 1.2500e-04\n",
            "Epoch 47/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0222 - val_accuracy: 0.9600 - val_loss: 0.2775 - learning_rate: 1.2500e-04\n",
            "Epoch 48/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9600 - val_loss: 0.2770 - learning_rate: 1.2500e-04\n",
            "Epoch 49/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9969 - loss: 0.0171 - val_accuracy: 0.9600 - val_loss: 0.2773 - learning_rate: 1.2500e-04\n",
            "Epoch 50/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0169 - val_accuracy: 0.9600 - val_loss: 0.2805 - learning_rate: 1.2500e-04\n",
            "Epoch 51/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 1.0000 - loss: 0.0191 - val_accuracy: 0.9600 - val_loss: 0.2805 - learning_rate: 1.2500e-04\n",
            "Epoch 52/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9982 - loss: 0.0164 - val_accuracy: 0.9600 - val_loss: 0.2829 - learning_rate: 1.2500e-04\n",
            "Epoch 53/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0198 - val_accuracy: 0.9400 - val_loss: 0.3283 - learning_rate: 1.2500e-04\n",
            "Epoch 54/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9948 - loss: 0.0268 - val_accuracy: 0.9400 - val_loss: 0.3433 - learning_rate: 1.2500e-04\n",
            "Epoch 55/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0175 - val_accuracy: 0.9400 - val_loss: 0.3346 - learning_rate: 1.2500e-04\n",
            "Epoch 56/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9982 - loss: 0.0166 - val_accuracy: 0.9400 - val_loss: 0.2915 - learning_rate: 1.2500e-04\n",
            "Epoch 57/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9978 - loss: 0.0187 - val_accuracy: 0.9400 - val_loss: 0.2809 - learning_rate: 1.2500e-04\n",
            "Epoch 58/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9945 - loss: 0.0166 - val_accuracy: 0.9200 - val_loss: 0.3148 - learning_rate: 1.2500e-04\n",
            "Epoch 59/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0254 - val_accuracy: 0.9400 - val_loss: 0.2776 - learning_rate: 6.2500e-05\n",
            "Epoch 60/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 71ms/step - accuracy: 0.9970 - loss: 0.0156 - val_accuracy: 0.9400 - val_loss: 0.2820 - learning_rate: 6.2500e-05\n",
            "Epoch 61/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0154 - val_accuracy: 0.9400 - val_loss: 0.2870 - learning_rate: 6.2500e-05\n",
            "Epoch 62/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9400 - val_loss: 0.2951 - learning_rate: 6.2500e-05\n",
            "Epoch 63/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0125 - val_accuracy: 0.9200 - val_loss: 0.3206 - learning_rate: 6.2500e-05\n",
            "Epoch 64/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9997 - loss: 0.0153 - val_accuracy: 0.9200 - val_loss: 0.2978 - learning_rate: 6.2500e-05\n",
            "Epoch 65/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0131 - val_accuracy: 0.9600 - val_loss: 0.2640 - learning_rate: 6.2500e-05\n",
            "Epoch 66/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9935 - loss: 0.0295 - val_accuracy: 0.9400 - val_loss: 0.2935 - learning_rate: 6.2500e-05\n",
            "Epoch 67/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9994 - loss: 0.0141 - val_accuracy: 0.9200 - val_loss: 0.3123 - learning_rate: 6.2500e-05\n",
            "Epoch 68/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9200 - val_loss: 0.3273 - learning_rate: 6.2500e-05\n",
            "Epoch 69/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0141 - val_accuracy: 0.9200 - val_loss: 0.3555 - learning_rate: 6.2500e-05\n",
            "Epoch 70/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9990 - loss: 0.0166 - val_accuracy: 0.9000 - val_loss: 0.4962 - learning_rate: 6.2500e-05\n",
            "Epoch 71/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 91ms/step - accuracy: 0.9730 - loss: 0.0645 - val_accuracy: 0.9000 - val_loss: 0.4637 - learning_rate: 6.2500e-05\n",
            "Epoch 72/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 89ms/step - accuracy: 0.9931 - loss: 0.0224 - val_accuracy: 0.9000 - val_loss: 0.4158 - learning_rate: 6.2500e-05\n",
            "Epoch 73/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 78ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9400 - val_loss: 0.2888 - learning_rate: 6.2500e-05\n",
            "Epoch 74/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9959 - loss: 0.0132 - val_accuracy: 0.9400 - val_loss: 0.2880 - learning_rate: 6.2500e-05\n",
            "Epoch 75/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0115 - val_accuracy: 0.9400 - val_loss: 0.2896 - learning_rate: 6.2500e-05\n",
            "Epoch 76/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9994 - loss: 0.0111 - val_accuracy: 0.9400 - val_loss: 0.2902 - learning_rate: 3.1250e-05\n",
            "Epoch 77/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0162 - val_accuracy: 0.9400 - val_loss: 0.2905 - learning_rate: 3.1250e-05\n",
            "Epoch 78/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9953 - loss: 0.0203 - val_accuracy: 0.9400 - val_loss: 0.2934 - learning_rate: 3.1250e-05\n",
            "Epoch 79/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0140 - val_accuracy: 0.9400 - val_loss: 0.2959 - learning_rate: 3.1250e-05\n",
            "Epoch 80/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 76ms/step - accuracy: 0.9963 - loss: 0.0143 - val_accuracy: 0.9400 - val_loss: 0.2958 - learning_rate: 3.1250e-05\n",
            "Epoch 81/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 94ms/step - accuracy: 0.9997 - loss: 0.0127 - val_accuracy: 0.9400 - val_loss: 0.2965 - learning_rate: 3.1250e-05\n",
            "Epoch 82/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0166 - val_accuracy: 0.9400 - val_loss: 0.3004 - learning_rate: 3.1250e-05\n",
            "Epoch 83/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 0.9974 - loss: 0.0184 - val_accuracy: 0.9200 - val_loss: 0.3038 - learning_rate: 3.1250e-05\n",
            "Epoch 84/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0132 - val_accuracy: 0.9200 - val_loss: 0.3089 - learning_rate: 3.1250e-05\n",
            "Epoch 85/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9953 - loss: 0.0175 - val_accuracy: 0.9200 - val_loss: 0.3064 - learning_rate: 3.1250e-05\n",
            "Epoch 86/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9200 - val_loss: 0.3126 - learning_rate: 1.5625e-05\n",
            "Epoch 87/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9963 - loss: 0.0283 - val_accuracy: 0.9200 - val_loss: 0.3171 - learning_rate: 1.5625e-05\n",
            "Epoch 88/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0108 - val_accuracy: 0.9200 - val_loss: 0.3180 - learning_rate: 1.5625e-05\n",
            "Epoch 89/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 74ms/step - accuracy: 1.0000 - loss: 0.0110 - val_accuracy: 0.9200 - val_loss: 0.3210 - learning_rate: 1.5625e-05\n",
            "Epoch 90/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 77ms/step - accuracy: 0.9997 - loss: 0.0140 - val_accuracy: 0.9200 - val_loss: 0.3145 - learning_rate: 1.5625e-05\n",
            "Epoch 91/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 86ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9400 - val_loss: 0.2770 - learning_rate: 1.5625e-05\n",
            "Epoch 92/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 90ms/step - accuracy: 1.0000 - loss: 0.0139 - val_accuracy: 0.9400 - val_loss: 0.2757 - learning_rate: 1.5625e-05\n",
            "Epoch 93/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0093 - val_accuracy: 0.9400 - val_loss: 0.2753 - learning_rate: 1.5625e-05\n",
            "Epoch 94/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0111 - val_accuracy: 0.9400 - val_loss: 0.2767 - learning_rate: 1.5625e-05\n",
            "Epoch 95/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9970 - loss: 0.0146 - val_accuracy: 0.9400 - val_loss: 0.2777 - learning_rate: 1.5625e-05\n",
            "Epoch 96/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0089 - val_accuracy: 0.9400 - val_loss: 0.2794 - learning_rate: 7.8125e-06\n",
            "Epoch 97/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 0.9974 - loss: 0.0148 - val_accuracy: 0.9400 - val_loss: 0.2812 - learning_rate: 7.8125e-06\n",
            "Epoch 98/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 0.9997 - loss: 0.0114 - val_accuracy: 0.9400 - val_loss: 0.2818 - learning_rate: 7.8125e-06\n",
            "Epoch 99/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 72ms/step - accuracy: 1.0000 - loss: 0.0105 - val_accuracy: 0.9200 - val_loss: 0.2749 - learning_rate: 7.8125e-06\n",
            "Epoch 100/100\n",
            "\u001b[1m15/15\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0101 - val_accuracy: 0.9200 - val_loss: 0.2714 - learning_rate: 7.8125e-06\n",
            "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 438ms/step\n",
            "Fold 10 Accuracy: 0.9200\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute AUC Score\n",
        "y_probs = model.predict(X)  # Get probabilities for each class\n",
        "\n",
        "# Check the shape of y_probs\n",
        "print(\"Shape of y_probs:\", y_probs.shape)\n",
        "\n",
        "# Calculate AUC using predicted probabilities\n",
        "auc = roc_auc_score(y, y_probs, multi_class='ovr')\n",
        "print(f\"\\nAUC Score: {auc:.4f}\")\n",
        "\n",
        "# Print final classification report\n",
        "print(\"\\nFinal Classification Report:\")\n",
        "print(classification_report(all_y_true, all_y_pred, target_names=[\"Intermittent Epilepsy\", \"Healthy\", \"Continuous Epilepsy\"]))\n",
        "\n",
        "# Save trained model\n",
        "model.save(\"/content/drive/MyDrive/cnn_lstm_trained_model_2.h5\")\n",
        "print(\"CNN-LSTM model trained, evaluated, and saved with 10-fold cross-validation.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qcaImkKoDTBE",
        "outputId": "f92ce05f-0e2d-4e92-b818-9a9772116e04"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of y_probs: (500, 3)\n",
            "\n",
            "AUC Score: 0.9995\n",
            "\n",
            "Final Classification Report:\n",
            "                       precision    recall  f1-score   support\n",
            "\n",
            "Intermittent Epilepsy       0.95      0.95      0.95       200\n",
            "              Healthy       0.94      0.96      0.95       200\n",
            "  Continuous Epilepsy       0.96      0.92      0.94       100\n",
            "\n",
            "             accuracy                           0.95       500\n",
            "            macro avg       0.95      0.94      0.95       500\n",
            "         weighted avg       0.95      0.95      0.95       500\n",
            "\n",
            "CNN-LSTM model trained, evaluated, and saved with 10-fold cross-validation.\n"
          ]
        }
      ]
    }
  ]
}